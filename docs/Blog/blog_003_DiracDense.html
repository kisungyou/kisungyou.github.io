<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kisung You">
<meta name="dcterms.date" content="2025-05-17">

<title>KY-Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-YRWM5FEPWV"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-YRWM5FEPWV', { 'anonymize_ip': true});
</script>

<link href="../site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="../site_libs/pagedtable-1.1/js/pagedtable.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="KY-Blog">
<meta property="og:description" content="">
<meta property="og:site-name" content="Kisung You">
<meta name="twitter:title" content="KY-Blog">
<meta name="twitter:description" content="">
<meta name="twitter:creator" content="@kisung_you">
<meta name="twitter:site" content="@kisung_you">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Kisung You</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../publication.html" rel="" target="">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../teaching.html" rel="" target="">
 <span class="menu-text">Teaching</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../software.html" rel="" target="">
 <span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#preliminaries-the-wasserstein-space" id="toc-preliminaries-the-wasserstein-space" class="nav-link" data-scroll-target="#preliminaries-the-wasserstein-space"><span class="header-section-number">2</span> Preliminaries: The Wasserstein Space</a></li>
  <li><a href="#what-does-dense-mean-in-wasserstein-geometry" id="toc-what-does-dense-mean-in-wasserstein-geometry" class="nav-link" data-scroll-target="#what-does-dense-mean-in-wasserstein-geometry"><span class="header-section-number">3</span> What Does “Dense” Mean in Wasserstein Geometry?</a></li>
  <li><a href="#proof" id="toc-proof" class="nav-link" data-scroll-target="#proof"><span class="header-section-number">4</span> Proof</a>
  <ul class="collapse">
  <li><a href="#truncation-to-compact-support" id="toc-truncation-to-compact-support" class="nav-link" data-scroll-target="#truncation-to-compact-support"><span class="header-section-number">4.1</span> Truncation to Compact Support</a></li>
  <li><a href="#quantization-to-finitely-supported-measures" id="toc-quantization-to-finitely-supported-measures" class="nav-link" data-scroll-target="#quantization-to-finitely-supported-measures"><span class="header-section-number">4.2</span> Quantization to Finitely Supported Measures</a></li>
  <li><a href="#convergence-via-triangle-inequality" id="toc-convergence-via-triangle-inequality" class="nav-link" data-scroll-target="#convergence-via-triangle-inequality"><span class="header-section-number">4.3</span> Convergence via Triangle Inequality</a></li>
  </ul></li>
  <li><a href="#why-this-matters-in-bayesian-inference" id="toc-why-this-matters-in-bayesian-inference" class="nav-link" data-scroll-target="#why-this-matters-in-bayesian-inference"><span class="header-section-number">5</span> Why This Matters in Bayesian Inference</a>
  <ul class="collapse">
  <li><a href="#empirical-posteriors-are-dirac-mixtures" id="toc-empirical-posteriors-are-dirac-mixtures" class="nav-link" data-scroll-target="#empirical-posteriors-are-dirac-mixtures"><span class="header-section-number">5.1</span> Empirical Posteriors Are Dirac Mixtures</a></li>
  <li><a href="#why-this-matters-practically" id="toc-why-this-matters-practically" class="nav-link" data-scroll-target="#why-this-matters-practically"><span class="header-section-number">5.2</span> Why This Matters Practically</a></li>
  </ul></li>
  <li><a href="#broader-implications" id="toc-broader-implications" class="nav-link" data-scroll-target="#broader-implications"><span class="header-section-number">6</span> Broader Implications</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">7</span> Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">The space of Dirac measures is dense in Wasserstein space</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Optimal Transport</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Kisung You </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 17, 2025</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="hidden">
<p><span class="math display">\[
\newcommand{\bbR}{\mathbb{R}}
\newcommand{\calD}{\mathcal{D}}
\newcommand{\calP}{\mathcal{P}}
\DeclareMathOperator{\argmin}{argmin}
\]</span></p>
</div>
<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In the study of probability distributions, the 2-Wasserstein space of measures, often denoted as <span class="math inline">\(\mathcal{P}_2(\mathbb{R}^d)\)</span>, has emerged as a foundational structure in optimal transport and statistical inference <span class="citation" data-cites="villani_2003_TopicsOptimalTransportation">(<a href="#ref-villani_2003_TopicsOptimalTransportation" role="doc-biblioref">Villani 2003</a>)</span>. This space supports notion of distance, geometry, and convergence that are both theoretically robust and computationally relevant.</p>
<p>A particularly deep yet accessible fact about this space is the following:</p>
<blockquote class="blockquote">
<p>The set of all finitely supported probability measures (i.e., finite mixture of point masses) is <strong>dense</strong> under the 2-Wasserstein metric.</p>
</blockquote>
<p>This statement has substantial consequences for both theory and practice. It legitimizes the use of discrete approximations such as empirical distributions generated by MCMC in high-level statistical tasks such as Bayesian inference, model aggregation, and distributional optimization. This note offers a comprehensive explanation of what this density means, how to prove it, and why it is consequential.</p>
</section>
<section id="preliminaries-the-wasserstein-space" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="preliminaries-the-wasserstein-space"><span class="header-section-number">2</span> Preliminaries: The Wasserstein Space</h2>
<p>Let <span class="math inline">\(\calP_2 (\bbR^d)\)</span> denote the set of all <a href="https://en.wikipedia.org/wiki/Borel_measure">Borel probability measures</a> <span class="math inline">\(\mu\)</span> supported on <span class="math inline">\(\bbR^d\)</span> with finite second moments <span class="math display">\[
\int_{\bbR^d} \|x\|^2 d\mu(x) &lt; \infty.
\]</span> The 2-Wasserstein distance between two measures <span class="math inline">\(\mu, \nu \in \calP_2(\bbR^d)\)</span> is defined by <span class="math display">\[\begin{equation}
W_2^2 (\mu,\nu):= \underset{\gamma \in \Gamma(\mu, \nu)}{\inf}~ \int_{\bbR^d \times \bbR^d} \|x-y\|^2 d\gamma(x,y),
\end{equation}\]</span> where <span class="math inline">\(\Gamma(\mu, \nu)\)</span> is the set of all joint distributions, also known as couplings, with marginals <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\nu\)</span>. Intuitively, <span class="math inline">\(W_2\)</span> measures the optimal cost of transporting one distribution into the other when cost is quadratic in displacement.</p>
<p>This space is not only a complete and separable metric space, but it also carries a Riemannian-like geometry that underpins interpolation, gradient flow, and barycenter constructions <span class="citation" data-cites="otto_2001_GeometryDissipativeEvolution">(<a href="#ref-otto_2001_GeometryDissipativeEvolution" role="doc-biblioref">Otto 2001</a>)</span>.</p>
</section>
<section id="what-does-dense-mean-in-wasserstein-geometry" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="what-does-dense-mean-in-wasserstein-geometry"><span class="header-section-number">3</span> What Does “Dense” Mean in Wasserstein Geometry?</h2>
<p>In general topology, a subset <span class="math inline">\(A\)</span> of a metric space <span class="math inline">\((X,d)\)</span> is called <strong>dense</strong> if for all <span class="math inline">\(x \in X\)</span> and any <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists <span class="math inline">\(a \in A\)</span> such that <span class="math inline">\(d(x,a) &lt; \epsilon\)</span>. In our context, we consider the set <span class="math display">\[
\calD := \left\lbrace
\sum_{i=1}^n \lambda_i \delta_{x_i}\mid \lambda_i &gt; 0, ~\sum_{i=1}^n \lambda_i = 1,~x_i\in\bbR^d,~ n\in \mathbb{N}
\right\rbrace,
\]</span> which consists of finite convex combinations of <a href="https://en.wikipedia.org/wiki/Dirac_measure">Dirac measures</a>.</p>
<p>The notion of <strong>density</strong> (not to be confused with the density of a measure) is understood in terms of the Wasserstein metric, not in terms of weak convergence or total variation. To understand the distinction, consider the following example. Think of the true distribution as a smooth landscape and discrete point masses as piles of sand. Wasserstein distance measures the work needed to move the sand to match the landscape, capturing both <em>where</em> the mass lies (location) and <em>how much</em> lies there (moment). <a href="https://en.wikipedia.org/wiki/Convergence_of_measures#Weak_convergence_of_measures">Weak convergence</a> is like viewing the scene from far away. You see whether piles are roughly in the correct places but ignore how tall they are. That means, moments may diverge. <a href="https://en.wikipedia.org/wiki/Total_variation_distance_of_probability_measures">Total variation</a> demands every grain be placed exactly right, which can be far too strict for sample-based approximation.</p>
<p>Positioned between those extremes, <span class="math inline">\(W_2\)</span> guarantees (1) weak convergence plus convergence of second moments, and (2) expectations for functions with quadratic growth. These make it an ideal notion for statistical applications where second-moment behavior is central. With this clarified, now let’s prove that <span class="math inline">\(\calD\)</span> is dense in <span class="math inline">\((\calP_2, W_2)\)</span>.</p>
</section>
<section id="proof" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="proof"><span class="header-section-number">4</span> Proof</h2>
<p>The proof consists of three parts for easy understanding.</p>
<section id="truncation-to-compact-support" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="truncation-to-compact-support"><span class="header-section-number">4.1</span> Truncation to Compact Support</h3>
<p>We want to show that dirac measures can approximate any measure <span class="math inline">\(\mu \in \calP_2(\bbR^d)\)</span>. For each <span class="math inline">\(R &gt; 0\)</span>, define the closed ball of radius <span class="math inline">\(R\)</span> centered at the origin as <span class="math display">\[
B(0,R):=\lbrace x\in\bbR^d \mid \|x\| \leq R \rbrace.
\]</span> We construct a truncated version of <span class="math inline">\(\mu\)</span> supported on this ball. Define the measure <span class="math inline">\(\mu_R\)</span> by <span class="math display">\[\begin{equation}
\mu_R(A) = \frac{\mu(A\cap B(0,R))}{\mu(B(0,R))},
\end{equation}\]</span> for all Borel sets <span class="math inline">\(A \subset \bbR^d\)</span>. This is a probability measure supported on <span class="math inline">\(B(0,R)\)</span>, provided <span class="math inline">\(\mu(B(0,R))&gt;0\)</span>. Since <span class="math inline">\(\mu \in \calP_2\)</span>, we have <span class="math inline">\(\mu(B(0,R)) \to 1\)</span> as <span class="math inline">\(R \to \infty\)</span>.</p>
<p>We now verify that <span class="math inline">\(W_2(\mu_R, \mu) \to 0\)</span> as <span class="math inline">\(R \to \infty\)</span>. To do this, define a coupling <span class="math inline">\(\gamma_R \in \Gamma(\mu,\mu_R)\)</span> by setting <span class="math display">\[
\gamma_R := \frac{1}{\mu(B(0,R))}\cdot \mu\vert_{B(0,R)}(x) \otimes \delta_x (y) \in \calP_2(\bbR^d \times \bbR^d).
\]</span> This coupling transports mass inside <span class="math inline">\(B(0,R)\)</span> directly to itself while the mass outside the ball is ignored. Then, <span class="math display">\[
\int \|x-y\|^2 d \gamma_R (x,y) = \frac{1}{\mu(B(0,R))} \int_{B(0,R)} \|x - x\|^2 d\mu(x) = 0.
\]</span> Therefore, the transport cost under this coupling is zero inside the ball, but there is unmatched mass outside, which we account for.</p>
<p>Now consider the decomposition <span class="math display">\[
W_2^2(\mu,\mu_R) \leq \int_{\bbR^d \backslash B(0,R)} \|x\|^2 d\mu(x) + (1-\mu(B(0,R)))\cdot R^2.
\]</span> The first term represents contribution of tail mass and the second term is cost of reallocating mass. As <span class="math inline">\(R\to\infty\)</span>, the first term vanishes because of integrability of <span class="math inline">\(\|x\|^2\)</span>. We also know that the second term vanishes as well since <span class="math inline">\(\mu(B(0,R)) \rightarrow 1\)</span>. Therefore, <span class="math display">\[
\lim_{R\to \infty} W_2 (\mu, \mu_R)  = 0.
\]</span></p>
</section>
<section id="quantization-to-finitely-supported-measures" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="quantization-to-finitely-supported-measures"><span class="header-section-number">4.2</span> Quantization to Finitely Supported Measures</h3>
Fix <span class="math inline">\(R&gt;0\)</span> and let <span class="math inline">\(\mu_R\)</span> be the compactly supported measure we just constructed. Since <span class="math inline">\(\mu_R\)</span> is supported on a compact set <span class="math inline">\(K = B(0,R)\)</span>, we can apply a canonical quantization argument. Partition the set <span class="math inline">\(K\)</span> into a finite number of disjoint Borel sets <span class="math inline">\(Q_1, \ldots, Q_k\)</span> such that:
<p>For each <span class="math inline">\(i=1,\ldots,k\)</span>, choose a representative point <span class="math inline">\(x_i \in Q_i\)</span> and define the finitely supported measure <span class="math display">\[
\mu_R^\epsilon := \sum_{i=1}^k \mu_R (Q_i) \delta_{x_i} \in \calD.
\]</span> We can construct a coupling <span class="math inline">\(\gamma \in \Gamma(\mu_R, \mu_R^\epsilon)\)</span> by pushing the entire mass from <span class="math inline">\(Q_i\)</span> to <span class="math inline">\(x_i\)</span>. Then, <span class="math display">\[
W_2^2(\mu_R, \mu_R^\epsilon) \leq \sum_{i=1}^k \int_{Q_i}  \|x - x_i\|^2 d\mu_R(x) \leq \epsilon^2.
\]</span> Hence, <span class="math inline">\(W_2 (\mu_R, \mu_R^\epsilon) \leq \epsilon\)</span>.</p>
</section>
<section id="convergence-via-triangle-inequality" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="convergence-via-triangle-inequality"><span class="header-section-number">4.3</span> Convergence via Triangle Inequality</h3>
<p>Now fix an arbitrary <span class="math inline">\(\delta &gt; 0\)</span>. From the first step, one can choose <span class="math inline">\(R\)</span> large enough so that <span class="math display">\[
W_2(\mu,\mu_R) &lt; \frac{\delta}{2}.
\]</span> From the second step, <span class="math inline">\(\epsilon\)</span> can be chosen small enough so that <span class="math display">\[
W_2 (\mu_R, \mu_R^\epsilon) &lt; \frac{\delta}{2}.
\]</span> By the triangle inequality, we arrive at the following result: <span class="math display">\[
W_2(\mu,\mu_R^\epsilon) \leq W_2(\mu,\mu_R) + W_2 (\mu_R, \mu_R^\epsilon) &lt; \frac{\delta}{2}+\frac{\delta}{2} = \delta.
\]</span> Since <span class="math inline">\(\mu_R^\epsilon \in \calD\)</span>, we have shown that for any <span class="math inline">\(\mu \in \calP_2(\bbR^d)\)</span> and any <span class="math inline">\(\delta &gt; 0\)</span>, there exists a finitely supported measure <span class="math inline">\(\nu \in \calD\)</span> such that <span class="math inline">\(W_2(\mu, \nu) &lt; \delta\)</span>.</p>
<p>Thus, the set <span class="math inline">\(\calD\)</span> is dense in <span class="math inline">\((\calP_2(\bbR^d), W_2)\)</span>.</p>
</section>
</section>
<section id="why-this-matters-in-bayesian-inference" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="why-this-matters-in-bayesian-inference"><span class="header-section-number">5</span> Why This Matters in Bayesian Inference</h2>
<p>The density of Dirac mixtures in Wasserstein space is not just a geometric curiosity. Indeed, it plays a foundational role in the theory and computation of Bayesian inference.</p>
<section id="empirical-posteriors-are-dirac-mixtures" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="empirical-posteriors-are-dirac-mixtures"><span class="header-section-number">5.1</span> Empirical Posteriors Are Dirac Mixtures</h3>
<p>In Bayesian analysis, the posterior distribution <span class="math inline">\(\pi(\theta\mid x)\)</span> encodes all inferential information about the parameter <span class="math inline">\(\theta\)</span> given the data <span class="math inline">\(x\)</span>. In most real-world problems, <span class="math inline">\(\pi(\theta\mid x)\)</span> is analytically intractable. As a result, we approximate it using samples from methods like <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">Markov chain Monte Carlo (MCMC)</a>, producing a sequence <span class="math inline">\(\theta_1, \ldots, \theta_N \sim \pi(\theta\mid x)\)</span>.</p>
<p>Once a run is done, this gives rise to the empirical posterior distribution <span class="math display">\[
\hat{\pi}_N = \frac{1}{N}\sum_{i=1}^N \delta_{\theta_i} \in \calD,
\]</span> which is a discrete measure (a Dirac mixture) and lies in the dense subset <span class="math inline">\(\calD \subset \calP_2 (\bbR^d)\)</span>. Thanks to the <strong>density</strong> result, under very mild regularity conditions, i.e., <span class="math inline">\(\pi(\theta\mid x) \in \calP_2(\bbR^d)\)</span>, we know: <span class="math display">\[
W_2(\hat{\pi}_N, \pi) \longrightarrow 0\quad\text{as }N\to \infty.
\]</span></p>
<p>This implies that the convergence of the empirical posterior <span class="math inline">\(\hat{\pi}_N\)</span> to the true posterior <span class="math inline">\(\pi(\theta\mid x)\)</span> is not just in distribution but also in terms of second moments, which is crucial for many statistical applications<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
</section>
<section id="why-this-matters-practically" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="why-this-matters-practically"><span class="header-section-number">5.2</span> Why This Matters Practically</h3>
<p>This convergence has powerful consequences.</p>
<ol type="1">
<li><em>Consistency of posterior expectations</em>: For many function classes such as Lipschitz or quadratic-growth functions, expectations under <span class="math inline">\(\hat{\pi}_N\)</span> converge to expectations under <span class="math inline">\(\pi\)</span>. This ensures reliable estimation of posterior summaries including means, variances, and credible intervals.</li>
<li><em>Stability of statistical functionals</em>: Quantities like credible regions, predictive distributions, Bayes factors, and risk functionals are well-approximated by their empirical analogs.</li>
<li><em>Foundation for resampling and ensembling</em>: The theoretical legitimacy of sampling-based posterior approximations ensures that tools like posterior bootstrap, weighted resampling, and kernel density estimation on <span class="math inline">\(\hat{\pi}_N\)</span> can be interpreted rigorously.</li>
</ol>
</section>
</section>
<section id="broader-implications" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="broader-implications"><span class="header-section-number">6</span> Broader Implications</h2>
<p>The density of finitely supported measures in Wasserstein space has far-reaching implications that extend well beyond Bayesian computation. At its core, this result gives us permission to treat discrete, empirical approximations as valid proxies for continuous distributions not only heuristically, but with full mathematical justification. This has become increasingly important as modern statistics moves into spaces where distributions are themselves the objects of inference, optimization, or learning.</p>
<p>For instance, a wide range of statistical and machine learning tasks now involve minimizing functionals over probability distributions. Examples include optimal transport-based clustering, distributional regression, and geometric learning in Wasserstein space. These problems are naturally infinite-dimensional, yet thanks to the density of point masses, we can safely approximate them using discrete measures. Algorithms that work with samples or particles, such as those in variational inference, particle filtering, or Wasserstein generative modeling, operate entirely within this discrete subset, and the density result assures us that they remain close, in a precise metric sense, to the true solution.</p>
<p>Moreover, this result forms the basis for understanding the behavior of empirical distributions in a quantitative way. In high-dimensional settings, we care not just about whether empirical averages converge, but about how distributions themselves behave under finite sampling. Rate of convergence results like <span class="citation" data-cites="fournier_2015_RateConvergenceWasserstein">Fournier and Guillin (<a href="#ref-fournier_2015_RateConvergenceWasserstein" role="doc-biblioref">2015</a>)</span>, which provide non-asymptotic convergence rates for empirical measures in Wasserstein distance, rely on the fact that empirical distributions belong to a dense subset of the space. Without such a density property, these convergence rates would lack grounding.</p>
<p>It also enables the practical use of geometric concepts such as Wasserstein barycenters, Fréchet means, and transport-based medians. These objects, while defined over general distributions, are often computed from discrete empirical measures. That this is not just a computational shortcut but a theoretically valid procedure is precisely because of this density: the geometric structure of Wasserstein space remains stable under approximation by point masses.</p>
<p>Perhaps most importantly, the result builds a conceptual bridge between infinite-dimensional theory and finite-sample practice. In probability, statistics, and machine learning, we often formulate problems in terms of idealized objects - true distributions, functional risk, geometric flows - but ultimately implement solutions with finite data. The density of Dirac mixtures in Wasserstein space assures us that this transition from the infinite to the finite is not a compromise, but a convergence.</p>
</section>
<section id="conclusion" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">7</span> Conclusion</h2>
<p>The fact that Dirac mixtures are dense in the Wasserstein space <span class="math inline">\(\calP_2(\bbR^d)\)</span> is more than a technical result. It is a cornerstone of modern computational probability. It tells us that empirical approximations, such as those arising from MCMC, live in the same geometric space as the distributions they seek to estimate. It validates our use of discrete measures in place of continuous ones, not only for computing expectations or variances, but for solving full distributional problems.</p>
<p>This result is what allows us to define geometric estimators on sampled data, aggregate distributions across models or machines, and design optimization algorithms that operate directly on measures. It is what ensures that Wasserstein gradient flows, barycenters, and interpolation paths remain meaningful when applied to empirical distributions. It is what gives us the confidence to work with particles, while knowing we are still faithfully navigating the geometry of probability.</p>
</section>
<section id="references" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-fournier_2015_RateConvergenceWasserstein" class="csl-entry" role="listitem">
Fournier, Nicolas, and Arnaud Guillin. 2015. <span>“On the Rate of Convergence in <span>Wasserstein</span> Distance of the Empirical Measure.”</span> <em>Probability Theory and Related Fields</em> 162 (3-4): 707–38. <a href="https://doi.org/10.1007/s00440-014-0583-7">https://doi.org/10.1007/s00440-014-0583-7</a>.
</div>
<div id="ref-otto_2001_GeometryDissipativeEvolution" class="csl-entry" role="listitem">
Otto, Felix. 2001. <span>“The Geometry of Dissipative Evolution Equations: The Porous Medium Equation.”</span> <em>Communications in Partial Differential Equations</em> 26 (1-2): 101–74. <a href="https://doi.org/10.1081/PDE-100002243">https://doi.org/10.1081/PDE-100002243</a>.
</div>
<div id="ref-villani_2003_TopicsOptimalTransportation" class="csl-entry" role="listitem">
Villani, Cédric. 2003. <em>Topics in <span>Optimal Transportation</span></em>. Vol. 58. Graduate <span>Studies</span> in <span>Mathematics</span>. S.l.: American Mathematical Society.
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Let’s be honest, skewness and kurtosis, really?<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{you2025,
  author = {You, Kisung},
  title = {The Space of {Dirac} Measures Is Dense in {Wasserstein}
    Space},
  date = {2025-05-17},
  url = {https://kisungyou.com/Blog/blog_003_DiracDense.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-you2025" class="csl-entry quarto-appendix-citeas" role="listitem">
You, Kisung. 2025. <span>“The Space of Dirac Measures Is Dense in
Wasserstein Space.”</span> May 17, 2025. <a href="https://kisungyou.com/Blog/blog_003_DiracDense.html">https://kisungyou.com/Blog/blog_003_DiracDense.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">© Kisung You 2021-2025</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>