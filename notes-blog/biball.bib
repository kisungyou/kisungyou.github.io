@article{abbas_2021_GeodesicDistanceOptimally,
  title = {Geodesic {{Distance}} on {{Optimally Regularized Functional Connectomes Uncovers Individual Fingerprints}}},
  author = {Abbas, Kausar and Liu, Mintao and Venkatesh, Manasij and Amico, Enrico and Kaplan, Alan David and Ventresca, Mario and Pessoa, Luiz and Harezlak, Jaroslaw and Go{\~n}i, Joaqu{\'i}n},
  year = {2021},
  month = jun,
  journal = {Brain Connectivity},
  volume = {11},
  number = {5},
  pages = {333--348},
  issn = {2158-0014, 2158-0022},
  doi = {10.1089/brain.2020.0881},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Abbas_2021_Geodesic Distance on Optimally Regularized Functional Connectomes Uncovers.pdf}
}

@article{abraham_2022_AmericanCollegeGastroenterologyCanadian,
  title = {American {{College}} of {{Gastroenterology-Canadian Association}} of {{Gastroenterology Clinical Practice Guideline}}: {{Management}} of {{Anticoagulants}} and {{Antiplatelets During Acute Gastrointestinal Bleeding}} and the {{Periendoscopic Period}}},
  shorttitle = {American {{College}} of {{Gastroenterology-Canadian Association}} of {{Gastroenterology Clinical Practice Guideline}}},
  author = {Abraham, Neena S. and Barkun, Alan N. and Sauer, Bryan G. and Douketis, James and Laine, Loren and Noseworthy, Peter A. and Telford, Jennifer J. and Leontiadis, Grigorios I.},
  year = {2022},
  month = apr,
  journal = {American Journal of Gastroenterology},
  volume = {117},
  number = {4},
  pages = {542--558},
  issn = {0002-9270, 1572-0241},
  doi = {10.14309/ajg.0000000000001627},
  urldate = {2024-06-30},
  abstract = {We conducted systematic reviews of predefined clinical questions and used the Grading of Recommendations, Assessment, Development and Evaluations approach to develop recommendations for the periendoscopic management of anticoagulant and antiplatelet drugs during acute gastrointestinal (GI) bleeding and the elective endoscopic setting. The following recommendations target patients presenting with acute GI bleeding: For patients on warfarin, we suggest against giving fresh frozen plasma or vitamin K; if needed, we suggest prothrombin complex concentrate (PCC) compared with fresh frozen plasma administration; for patients on direct oral anticoagulants (DOACs), we suggest against PCC administration; if on dabigatran, we suggest against the administration of idarucizumab, and if on rivaroxaban or apixaban, we suggest against andexanet alfa administration; for patients on antiplatelet agents, we suggest against platelet transfusions; and for patients on cardiac acetylsalicylic acid (ASA) for secondary prevention, we suggest against holding it, but if the ASA has been interrupted, we suggest resumption on the day hemostasis is endoscopically confirmed. The following recommendations target patients in the elective (planned) endoscopy setting: For patients on warfarin, we suggest continuation as opposed to temporary interruption (1--7 days), but if it is held for procedures with high risk of GI bleeding, we suggest against bridging anticoagulation unless the patient has a mechanical heart valve; for patients on DOACs, we suggest temporarily interrupting rather than continuing these; for patients on dual antiplatelet therapy for secondary prevention, we suggest temporary interruption of the P2Y               12               receptor inhibitor while continuing ASA; and if on cardiac ASA monotherapy for secondary prevention, we suggest against its interruption. Evidence was insufficient in the following settings to permit recommendations. With acute GI bleeding in patients on warfarin, we could not recommend for or against PCC administration when compared with placebo. In the elective periprocedural endoscopy setting, we could not recommend for or against temporary interruption of the P2Y               12               receptor inhibitor for patients on a single P2Y               12               inhibiting agent. We were also unable to make a recommendation regarding same-day resumption of the drug vs 1--7 days after the procedure among patients prescribed anticoagulants (warfarin or DOACs) or P2Y               12               receptor inhibitor drugs because of insufficient evidence.},
  copyright = {http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english}
}

@book{abramowitz_1972_HandbookMathematicalFunctions,
  title = {Handbook of {{Mathematical Functions}}: With {{Formulas}}, {{Graphs}}, and {{Mathematical Tables}}},
  shorttitle = {Handbook of Mathematical Functions},
  author = {Abramowitz, Milton and Stegun, Irene A.},
  year = {1972},
  series = {Dover Books on Advanced Mathematics},
  edition = {Unabridged, unaltered and corr. republ. of the 1964 ed},
  publisher = {Dover publ},
  address = {New York},
  collaborator = {{Conference on mathematical tables} and {National science foundation} and {Massachusetts institute of technology}},
  isbn = {978-0-486-61272-0},
  langid = {english},
  lccn = {515}
}

@book{absil_2008_OptimizationAlgorithmsMatrix,
  title = {Optimization Algorithms on Matrix Manifolds},
  author = {Absil, P.-A. and Mahony, R. and Sepulchre, R.},
  year = {2008},
  publisher = {Princeton University Press},
  address = {Princeton, N.J. ; Woodstock},
  isbn = {978-0-691-13298-3},
  lccn = {QA402.5 .A27 2008},
  keywords = {Algorithms,Mathematical optimization,Matrices},
  annotation = {OCLC: ocn174129993}
}

@article{adragni_2012_GrassmannOptimPackageGrassmann,
  title = {{{GrassmannOptim}} : {{An R Package}} for {{Grassmann Manifold Optimization}}},
  shorttitle = {{{{\textbf{GrassmannOptim}}}}},
  author = {Adragni, Kofi P. and Cook, R. Dennis and Wu, Seongho},
  year = {2012},
  journal = {Journal of Statistical Software},
  volume = {50},
  number = {5},
  issn = {1548-7660},
  doi = {10.18637/jss.v050.i05},
  urldate = {2021-10-29},
  langid = {english},
  file = {../../Bibliography/Adragni_2012_GrassmannOptim.pdf}
}

@article{afsari_2011_Riemannian$L_p$Center,
  title = {Riemannian \$\{\vphantom\}{{L}}\vphantom\{\}\_p\$ Center of Mass: {{Existence}}, Uniqueness, and Convexity},
  shorttitle = {Riemannian \${{L}}{\textasciicircum}\{p\}\$ Center of Mass},
  author = {Afsari, Bijan},
  year = {2011},
  month = feb,
  journal = {Proceedings of the American Mathematical Society},
  volume = {139},
  number = {02},
  pages = {655--655},
  issn = {0002-9939},
  doi = {10.1090/S0002-9939-2010-10541-5},
  urldate = {2021-09-27},
  langid = {english},
  file = {../../Bibliography/Afsari_2011_Riemannian $ L _p$ center of mass.pdf}
}

@article{afsari_2013_ConvergenceGradientDescent,
  title = {On the {{Convergence}} of {{Gradient Descent}} for {{Finding}} the {{Riemannian Center}} of {{Mass}}},
  author = {Afsari, Bijan and Tron, Roberto and Vidal, Ren{\'e}},
  year = {2013},
  month = jan,
  journal = {SIAM Journal on Control and Optimization},
  volume = {51},
  number = {3},
  pages = {2230--2260},
  issn = {0363-0129, 1095-7138},
  doi = {10.1137/12086282X},
  urldate = {2021-10-08},
  langid = {english}
}

@article{aftab_2015_GeneralizedWeiszfeldAlgorithms,
  title = {Generalized {{Weiszfeld Algorithms}} for {{Lq Optimization}}},
  author = {Aftab, Khurrum and Hartley, Richard and Trumpf, Jochen},
  year = {2015},
  month = apr,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {37},
  number = {4},
  pages = {728--745},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/TPAMI.2014.2353625},
  urldate = {2021-10-02},
  file = {../../Bibliography/Aftab_2015_Generalized Weiszfeld Algorithms for Lq Optimization.pdf}
}

@inproceedings{aggarwal_2004_SystemIdentificationApproach,
  title = {A System Identification Approach for Video-Based Face Recognition},
  booktitle = {Proceedings of the 17th {{International Conference}} on {{Pattern Recognition}}, 2004. {{ICPR}} 2004.},
  author = {Aggarwal, G. and Chowdhury, A.K.R. and Chellappa, R.},
  year = {2004},
  pages = {175-178 Vol.4},
  publisher = {IEEE},
  address = {Cambridge, UK},
  doi = {10.1109/ICPR.2004.1333732},
  urldate = {2021-10-29},
  isbn = {978-0-7695-2128-2},
  file = {../../Bibliography/Aggarwal_2004_A system identification approach for video-based face recognition.pdf}
}

@article{agueh_2011_BarycentersWassersteinSpace,
  title = {Barycenters in the {{Wasserstein Space}}},
  author = {Agueh, Martial and Carlier, Guillaume},
  year = {2011},
  month = jan,
  journal = {SIAM Journal on Mathematical Analysis},
  volume = {43},
  number = {2},
  pages = {904--924},
  issn = {0036-1410, 1095-7154},
  doi = {10.1137/100805741},
  urldate = {2021-11-18},
  langid = {english},
  file = {../../Bibliography/Agueh_2011_Barycenters in the Wasserstein Space.pdf}
}

@article{allen_2014_TrackingWholeBrainConnectivity,
  title = {Tracking {{Whole-Brain Connectivity Dynamics}} in the {{Resting State}}},
  author = {Allen, Elena A. and Damaraju, Eswar and Plis, Sergey M. and Erhardt, Erik B. and Eichele, Tom and Calhoun, Vince D.},
  year = {2014},
  month = mar,
  journal = {Cerebral Cortex},
  volume = {24},
  number = {3},
  pages = {663--676},
  issn = {1460-2199, 1047-3211},
  doi = {10.1093/cercor/bhs352},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Allen_2014_Tracking Whole-Brain Connectivity Dynamics in the Resting State.pdf}
}

@inproceedings{altschuler_2021_AveragingBuresWassersteinManifold,
  title = {Averaging on the {{Bures-Wasserstein}} Manifold: Dimension-Free Convergence of Gradient Descent},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Altschuler, Jason and Chewi, Sinho and Gerber, Patrik R and Stromme, Austin},
  editor = {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P.S. and Vaughan, J. Wortman},
  year = {2021},
  volume = {34},
  pages = {22132--22145},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Altschuler_2021_Averaging on the Bures-Wasserstein manifold.pdf}
}

@article{altschuler_2021_WassersteinBarycentersCan,
  title = {Wasserstein Barycenters Can Be Computed in Polynomial Time in Fixed Dimension},
  author = {Altschuler, Jason M and {Boix-Adsera}, Enric},
  year = {2021},
  journal = {Journal of Machine Learning Research},
  volume = {22},
  number = {44},
  pages = {1--19},
  file = {../../Bibliography/Altschuler_2021_Wasserstein barycenters can be computed in polynomial time in fixed dimension.pdf}
}

@article{alvarez-esteban_2016_FixedpointApproachBarycenters,
  title = {A Fixed-Point Approach to Barycenters in {{Wasserstein}} Space},
  author = {{\'A}lvarez-Esteban, Pedro C. and {del Barrio}, E. and {Cuesta-Albertos}, J.A. and Matr{\'a}n, C.},
  year = {2016},
  month = sep,
  journal = {Journal of Mathematical Analysis and Applications},
  volume = {441},
  number = {2},
  pages = {744--762},
  issn = {0022247X},
  doi = {10.1016/j.jmaa.2016.04.045},
  urldate = {2021-11-07},
  langid = {english},
  file = {../../Bibliography/Álvarez-Esteban_2016_A fixed-point approach to barycenters in Wasserstein space.pdf}
}

@book{amari_2007_MethodsInformationGeometry,
  title = {Methods of Information Geometry},
  author = {Amari, Shun'ichi and Nagaoka, Hiroshi and Amari, Shun'ichi and Amari, Shun'ichi},
  translator = {Harada, Daishi},
  year = {2007},
  series = {Translations of Mathematical Monographs},
  edition = {Nachdruck},
  number = {191},
  publisher = {American Mathematical Society},
  address = {Providence, Rhode Island},
  isbn = {978-0-8218-4302-4 978-0-8218-0531-2},
  langid = {english}
}

@book{ambrosio_2003_OptimalTransportationApplications,
  title = {Optimal Transportation and Applications: Lectures given at the {{C}}.{{I}}.{{M}}.{{E}}. Summer School Held in {{Martina Franca}}, {{Italy}}, {{September}} 2-8, 2001},
  shorttitle = {Optimal Transportation and Applications},
  editor = {Ambrosio, Luigi and Caffarelli, Luis A. and Salsa, S.},
  year = {2003},
  series = {Lecture Notes in Mathematics},
  number = {1813},
  publisher = {Springer},
  address = {Berlin ; New York},
  isbn = {978-3-540-40192-6},
  lccn = {QA3 QA402.6 .L28 no. 1813},
  keywords = {Congresses,Mathematical optimization,Transportation problems (Programming)}
}

@book{ambrosio_2005_GradientFlowsMetric,
  title = {Gradient Flows: In Metric Spaces and in the Space of Probability Measures},
  shorttitle = {Gradient Flows},
  author = {Ambrosio, Luigi and Gigli, Nicola and Savar{\'e}, Giuseppe},
  year = {2005},
  series = {Lectures in Mathematics {{ETH Z{\"u}rich}}},
  publisher = {Birkh{\"a}user},
  address = {Boston},
  abstract = {"This book is devoted to a theory of gradient flows in spaces which are not necessarily endowed with a natural linear or differentiable structure. It consists of two parts, the first one concerning gradient flows in metric spaces and the second one devoted to gradient flows in the space of probability measures on a separable Hilbert space, endowed with the Kantorovich-Rubinstein-Wasserstein distance."--Jacket},
  isbn = {978-3-7643-7309-2},
  langid = {english},
  lccn = {515.42},
  file = {../../Bibliography/Ambrosio_2005_Gradient flows.pdf}
}

@book{ambrosio_2021_LecturesOptimalTransport,
  title = {Lectures on Optimal Transport},
  author = {Ambrosio, Luigi and Bru{\'e}, Elia and Semola, Daniele},
  year = {2021},
  series = {Unitext - {{La}} Matematica per Il 3 + 2},
  number = {volume 130},
  publisher = {Springer},
  address = {Cham},
  doi = {10.1007/978-3-72162-6},
  isbn = {978-3-030-72161-9},
  langid = {english},
  file = {../../Bibliography/Ambrosio_2021_Lectures on optimal transport.pdf}
}

@article{amico_2018_QuestIdentifiabilityHuman,
  title = {The Quest for Identifiability in Human Functional Connectomes},
  author = {Amico, Enrico and Go{\~n}i, Joaqu{\'i}n},
  year = {2018},
  month = may,
  journal = {Scientific Reports},
  volume = {8},
  number = {1},
  pages = {8254},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-25089-1},
  urldate = {2024-04-22},
  abstract = {Abstract             The evaluation of the individual ``fingerprint'' of a human functional connectome (FC) is becoming a promising avenue for neuroscientific research, due to its enormous potential inherent to drawing single subject inferences from functional connectivity profiles. Here we show that the individual fingerprint of a human functional connectome can be maximized from a reconstruction procedure based on group-wise decomposition in a finite number of brain connectivity modes. We use data from the Human Connectome Project to demonstrate that the optimal reconstruction of the individual FCs through connectivity eigenmodes maximizes subject identifiability across resting-state and all seven tasks evaluated. The identifiability of the optimally reconstructed individual connectivity profiles increases both at the global and edgewise level, also when the reconstruction is imposed on additional functional data of the subjects. Furthermore, reconstructed FC data provide more robust associations with task-behavioral measurements. Finally, we extend this approach to also map the most task-sensitive functional connections. Results show that is possible to maximize individual fingerprinting in the functional connectivity domain regardless of the task, a crucial next step in the area of brain connectivity towards individualized connectomics.},
  langid = {english},
  file = {../../Bibliography/Amico_2018_The quest for identifiability in human functional connectomes.pdf}
}

@inproceedings{amos_2017_InputConvexNeural,
  title = {Input Convex Neural Networks},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  author = {Amos, Brandon and Xu, Lei and Kolter, J. Zico},
  editor = {Precup, Doina and Teh, Yee Whye},
  year = {2017-08-06/2017-08-11},
  series = {Proceedings of Machine Learning Research},
  volume = {70},
  pages = {146--155},
  publisher = {PMLR},
  file = {../../Bibliography/Amos_2017_Input convex neural networks.pdf}
}

@article{amsaleg_2018_ExtremevaluetheoreticEstimationLocal,
  title = {Extreme-Value-Theoretic Estimation of Local Intrinsic Dimensionality},
  author = {Amsaleg, Laurent and Chelly, Oussama and Furon, Teddy and Girard, St{\'e}phane and Houle, Michael E. and Kawarabayashi, Ken-ichi and Nett, Michael},
  year = {2018},
  month = nov,
  journal = {Data Mining and Knowledge Discovery},
  volume = {32},
  number = {6},
  pages = {1768--1805},
  issn = {1384-5810, 1573-756X},
  doi = {10.1007/s10618-018-0578-6},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Amsaleg_2018_Extreme-value-theoretic estimation of local intrinsic dimensionality.pdf}
}

@article{anderson_1936_SpeciesProblemIris,
  title = {The {{Species Problem}} in {{Iris}}},
  author = {Anderson, Edgar},
  year = {1936},
  month = sep,
  journal = {Annals of the Missouri Botanical Garden},
  volume = {23},
  number = {3},
  eprint = {2394164},
  eprinttype = {jstor},
  pages = {457},
  issn = {00266493},
  doi = {10.2307/2394164},
  urldate = {2023-06-10},
  file = {../../Bibliography/Anderson_1936_The Species Problem in Iris.pdf}
}

@article{angenent_2003_MinimizingFlowsMongeKantorovich,
  title = {Minimizing {{Flows}} for the {{Monge--Kantorovich Problem}}},
  author = {Angenent, Sigurd and Haker, Steven and Tannenbaum, Allen},
  year = {2003},
  month = jan,
  journal = {SIAM Journal on Mathematical Analysis},
  volume = {35},
  number = {1},
  pages = {61--97},
  issn = {0036-1410, 1095-7154},
  doi = {10.1137/S0036141002410927},
  urldate = {2022-09-06},
  langid = {english},
  file = {../../Bibliography/Angenent_2003_Minimizing Flows for the Monge--Kantorovich Problem.pdf}
}

@article{anselin_2019_LocalIndicatorMultivariate,
  title = {A {{Local Indicator}} of {{Multivariate Spatial Association}}: {{Extending Geary}}'s {\emph{c}}},
  shorttitle = {A {{Local Indicator}} of {{Multivariate Spatial Association}}},
  author = {Anselin, Luc},
  year = {2019},
  month = apr,
  journal = {Geographical Analysis},
  volume = {51},
  number = {2},
  pages = {133--150},
  issn = {0016-7363, 1538-4632},
  doi = {10.1111/gean.12164},
  urldate = {2022-07-27},
  langid = {english},
  file = {../../Bibliography/Anselin_2019_A Local Indicator of Multivariate Spatial Association.pdf}
}

@article{anselin_2020_ToblersLawMultivariate,
  title = {Tobler's {{Law}} in a {{Multivariate World}}},
  author = {Anselin, Luc and Li, Xun},
  year = {2020},
  month = oct,
  journal = {Geographical Analysis},
  volume = {52},
  number = {4},
  pages = {494--510},
  issn = {0016-7363, 1538-4632},
  doi = {10.1111/gean.12237},
  urldate = {2022-07-31},
  langid = {english},
  file = {../../Bibliography/Anselin_2020_Tobler’s Law in a Multivariate World.pdf}
}

@article{arbelaitz_2013_ExtensiveComparativeStudy,
  title = {An Extensive Comparative Study of Cluster Validity Indices},
  author = {Arbelaitz, Olatz and Gurrutxaga, Ibai and Muguerza, Javier and P{\'e}rez, Jes{\'u}s M. and Perona, I{\~n}igo},
  year = {2013},
  month = jan,
  journal = {Pattern Recognition},
  volume = {46},
  number = {1},
  pages = {243--256},
  issn = {00313203},
  doi = {10.1016/j.patcog.2012.07.021},
  urldate = {2021-10-02},
  langid = {english},
  file = {../../Bibliography/Arbelaitz_2013_An extensive comparative study of cluster validity indices.pdf}
}

@inproceedings{arjovsky_2017_WassersteinGenerativeAdversarial,
  title = {Wasserstein Generative Adversarial Networks},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  author = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  editor = {Precup, Doina and Teh, Yee Whye},
  year = {2017-08-06/2017-08-11},
  series = {Proceedings of Machine Learning Research},
  volume = {70},
  pages = {214--223},
  publisher = {PMLR},
  abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.},
  pdf = {http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf},
  file = {../../Bibliography/Arjovsky_2017_Wasserstein generative adversarial networks.pdf}
}

@incollection{arnaudon_2013_MediansMeansRiemannian,
  title = {Medians and {{Means}} in {{Riemannian Geometry}}: {{Existence}}, {{Uniqueness}} and {{Computation}}},
  shorttitle = {Medians and {{Means}} in {{Riemannian Geometry}}},
  booktitle = {Matrix {{Information Geometry}}},
  author = {Arnaudon, Marc and Barbaresco, Fr{\'e}d{\'e}ric and Yang, Le},
  editor = {Nielsen, Frank and Bhatia, Rajendra},
  year = {2013},
  pages = {169--197},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-30232-9_8},
  urldate = {2021-09-29},
  isbn = {978-3-642-30231-2 978-3-642-30232-9},
  langid = {english}
}

@article{arsigny_2007_GeometricMeansNovel,
  title = {Geometric {{Means}} in a {{Novel Vector Space Structure}} on {{Symmetric Positive}}-{{Definite Matrices}}},
  author = {Arsigny, Vincent and Fillard, Pierre and Pennec, Xavier and Ayache, Nicholas},
  year = {2007},
  month = jan,
  journal = {SIAM Journal on Matrix Analysis and Applications},
  volume = {29},
  number = {1},
  pages = {328--347},
  issn = {0895-4798, 1095-7162},
  doi = {10.1137/050637996},
  urldate = {2021-09-27},
  langid = {english},
  file = {../../Bibliography/Arsigny_2007_Geometric Means in a Novel Vector Space Structure on Symmetric.pdf}
}

@article{assa_2018_WassersteinDistanceBasedGaussianMixture,
  title = {Wasserstein-{{Distance-Based Gaussian Mixture Reduction}}},
  author = {Assa, Akbar and Plataniotis, Konstantinos N.},
  year = {2018},
  month = oct,
  journal = {IEEE Signal Processing Letters},
  volume = {25},
  number = {10},
  pages = {1465--1469},
  issn = {1070-9908, 1558-2361},
  doi = {10.1109/LSP.2018.2865829},
  urldate = {2021-08-17},
  file = {../../Bibliography/Assa_2018_Wasserstein-Distance-Based Gaussian Mixture Reduction.pdf}
}

@article{astrom_2017_ImageLabelingAssignment,
  title = {Image {{Labeling}} by {{Assignment}}},
  author = {{\AA}str{\"o}m, Freddie and Petra, Stefania and Schmitzer, Bernhard and Schn{\"o}rr, Christoph},
  year = {2017},
  month = jun,
  journal = {Journal of Mathematical Imaging and Vision},
  volume = {58},
  number = {2},
  pages = {211--238},
  issn = {0924-9907, 1573-7683},
  doi = {10.1007/s10851-016-0702-4},
  urldate = {2022-08-16},
  langid = {english},
  file = {../../Bibliography/Åström_2017_Image Labeling by Assignment.pdf}
}

@article{bai_1996_EFFECTHIGHDIMENSION,
  title = {{{EFFECT OF HIGH DIMENSION}}: {{BY AN EXAMPLE OF A TWO SAMPLE PROBLEM}}},
  author = {Bai, Zhidong and Saranadasa, Hewa},
  year = {1996},
  journal = {Statistica Sinica},
  volume = {6},
  number = {2},
  eprint = {24306018},
  eprinttype = {jstor},
  pages = {311--329},
  publisher = {Institute of Statistical Science, Academia Sinica},
  issn = {10170405, 19968507},
  urldate = {2022-07-26},
  file = {../../Bibliography/Bai_1996_EFFECT OF HIGH DIMENSION.pdf}
}

@article{baldi_1989_NeuralNetworksPrincipal,
  title = {Neural Networks and Principal Component Analysis: {{Learning}} from Examples without Local Minima},
  shorttitle = {Neural Networks and Principal Component Analysis},
  author = {Baldi, Pierre and Hornik, Kurt},
  year = {1989},
  month = jan,
  journal = {Neural Networks},
  volume = {2},
  number = {1},
  pages = {53--58},
  issn = {08936080},
  doi = {10.1016/0893-6080(89)90014-2},
  urldate = {2024-12-28},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english}
}

@article{banerjee_2005_ClusteringUnitHypersphere,
  title = {Clustering on the Unit Hypersphere Using von Mises-Fisher Distributions},
  author = {Banerjee, Arindam and Dhillon, Inderjit S. and Ghosh, Joydeep and Sra, Suvrit},
  year = {2005},
  journal = {Journal of Machine Learning Research},
  volume = {6},
  number = {46},
  pages = {1345--1382},
  file = {../../Bibliography/Banerjee_2005_Clustering on the unit hypersphere using von mises-fisher distributions.pdf}
}

@article{banerjee_2012_StructuralDistanceEvolutionary,
  title = {Structural Distance and Evolutionary Relationship of Networks},
  author = {Banerjee, Anirban},
  year = {2012},
  month = mar,
  journal = {Biosystems},
  volume = {107},
  number = {3},
  pages = {186--196},
  issn = {03032647},
  doi = {10.1016/j.biosystems.2011.11.004},
  urldate = {2022-08-28},
  langid = {english},
  file = {../../Bibliography/Banerjee_2012_Structural distance and evolutionary relationship of networks.pdf}
}

@inproceedings{bao_2022_NetworkDistanceBased,
  title = {Network {{Distance}} Based on {{Laplacian Flows}} on {{Graphs}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Bao, Dianbin and You, Kisung and Lin, Lizhen},
  year = {2022},
  month = dec,
  pages = {715--720},
  publisher = {IEEE},
  address = {Osaka, Japan},
  doi = {10.1109/BigData55660.2022.10020500},
  urldate = {2023-04-18},
  copyright = {All rights reserved},
  isbn = {978-1-66548-045-1},
  file = {../../Bibliography/Bao_2022_Network Distance based on Laplacian Flows on Graphs.pdf}
}

@article{barachant_2013_ClassificationCovarianceMatrices,
  title = {Classification of Covariance Matrices Using a {{Riemannian-based}} Kernel for {{BCI}} Applications},
  author = {Barachant, Alexandre and Bonnet, St{\'e}phane and Congedo, Marco and Jutten, Christian},
  year = {2013},
  month = jul,
  journal = {Neurocomputing},
  volume = {112},
  pages = {172--178},
  issn = {09252312},
  doi = {10.1016/j.neucom.2012.12.039},
  urldate = {2024-01-06},
  langid = {english},
  file = {../../Bibliography/Barachant_2013_Classification of covariance matrices using a Riemannian-based kernel for BCI.pdf}
}

@misc{barachant_2015_PyRiemannV022,
  title = {{{pyRiemann V0}}.2.2},
  author = {Barachant, Alexandre},
  year = {2015},
  month = jun,
  doi = {10.5281/ZENODO.18982},
  urldate = {2021-10-29},
  copyright = {BSD licenses (New and Simplified), Open Access},
  howpublished = {Zenodo}
}

@article{bari_2019_UncoveringMultisiteIdentifiability,
  title = {Uncovering Multi-Site Identifiability Based on Resting-State Functional Connectomes},
  author = {Bari, Sumra and Amico, Enrico and Vike, Nicole and Talavage, Thomas M. and Go{\~n}i, Joaqu{\'i}n},
  year = {2019},
  month = nov,
  journal = {NeuroImage},
  volume = {202},
  pages = {115967},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2019.06.045},
  urldate = {2022-06-18},
  langid = {english},
  file = {../../Bibliography/Bari_2019_Uncovering multi-site identifiability based on resting-state functional.pdf}
}

@article{barnett_2016_ChangePointDetection,
  title = {Change {{Point Detection}} in {{Correlation Networks}}},
  author = {Barnett, Ian and Onnela, Jukka-Pekka},
  year = {2016},
  month = may,
  journal = {Scientific Reports},
  volume = {6},
  number = {1},
  pages = {18893},
  issn = {2045-2322},
  doi = {10.1038/srep18893},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Barnett_2016_Change Point Detection in Correlation Networks.pdf}
}

@article{barraclough_2004_PrefrontalCortexDecision,
  title = {Prefrontal Cortex and Decision Making in a Mixed-Strategy Game},
  author = {Barraclough, Dominic J and Conroy, Michelle L and Lee, Daeyeol},
  year = {2004},
  month = apr,
  journal = {Nature Neuroscience},
  volume = {7},
  number = {4},
  pages = {404--410},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn1209},
  urldate = {2024-01-03},
  langid = {english},
  file = {../../Bibliography/Barraclough_2004_Prefrontal cortex and decision making in a mixed-strategy game.pdf}
}

@article{barrett_2019_AnalyzingBiologicalArtificial,
  title = {Analyzing Biological and Artificial Neural Networks: Challenges with Opportunities for Synergy?},
  shorttitle = {Analyzing Biological and Artificial Neural Networks},
  author = {Barrett, David GT and Morcos, Ari S and Macke, Jakob H},
  year = {2019},
  month = apr,
  journal = {Current Opinion in Neurobiology},
  volume = {55},
  pages = {55--64},
  issn = {09594388},
  doi = {10.1016/j.conb.2019.01.007},
  urldate = {2022-08-16},
  langid = {english},
  file = {../../Bibliography/Barrett_2019_Analyzing biological and artificial neural networks.pdf}
}

@article{barton_1992_COMPUTINGFORWARDDIFFERENCE,
  title = {{{COMPUTING FORWARD DIFFERENCE DERIVATIVES IN ENGINEERING OPTIMIZATION}}},
  author = {Barton, Russell R.},
  year = {1992},
  month = dec,
  journal = {Engineering Optimization},
  volume = {20},
  number = {3},
  pages = {205--224},
  issn = {0305-215X, 1029-0273},
  doi = {10.1080/03052159208941281},
  urldate = {2022-02-08},
  langid = {english},
  file = {../../Bibliography/Barton_1992_COMPUTING FORWARD DIFFERENCE DERIVATIVES IN ENGINEERING OPTIMIZATION.pdf}
}

@article{basu_2018_IterativeRandomForests,
  title = {Iterative Random Forests to Discover Predictive and Stable High-Order Interactions},
  author = {Basu, Sumanta and Kumbier, Karl and Brown, James B. and Yu, Bin},
  year = {2018},
  month = feb,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {8},
  pages = {1943--1948},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1711236115},
  urldate = {2023-02-12},
  abstract = {Significance             We developed a predictive, stable, and interpretable tool: the iterative random forest algorithm (iRF). iRF discovers high-order interactions among biomolecules with the same order of computational cost as random forests. We demonstrate the efficacy of iRF by finding known and promising interactions among biomolecules, of up to fifth and sixth order, in two data examples in transcriptional regulation and alternative splicing.           ,                             Genomics has revolutionized biology, enabling the interrogation of whole transcriptomes, genome-wide binding sites for proteins, and many other molecular processes. However, individual genomic assays measure elements that interact in vivo as components of larger molecular machines. Understanding how these high-order interactions drive gene expression presents a substantial statistical challenge. Building on random forests (RFs) and random intersection trees (RITs) and through extensive, biologically inspired simulations, we developed the iterative random forest algorithm (iRF). iRF trains a feature-weighted ensemble of decision trees to detect stable, high-order interactions with the same order of computational cost as the RF. We demonstrate the utility of iRF for high-order interaction discovery in two prediction problems: enhancer activity in the early               Drosophila               embryo and alternative splicing of primary transcripts in human-derived cell lines. In               Drosophila               , among the 20 pairwise transcription factor interactions iRF identifies as stable (returned in more than half of bootstrap replicates), 80\% have been previously reported as physical interactions. Moreover, third-order interactions, e.g., between               Zelda               (               Zld               ),               Giant               (               Gt               ), and               Twist               (               Twi               ), suggest high-order relationships that are candidates for follow-up experiments. In human-derived cells, iRF rediscovered a central role of H3K36me3 in chromatin-mediated splicing regulation and identified interesting fifth- and sixth-order interactions, indicative of multivalent nucleosomes with specific roles in splicing regulation. By decoupling the order of interactions from the computational cost of identification, iRF opens additional avenues of inquiry into the molecular mechanisms underlying genome biology.},
  langid = {english},
  file = {../../Bibliography/Basu_2018_Iterative random forests to discover predictive and stable high-order.pdf}
}

@article{battiti_1994_UsingMutualInformation,
  title = {Using Mutual Information for Selecting Features in Supervised Neural Net Learning},
  author = {Battiti, R.},
  year = {1994},
  month = jul,
  journal = {IEEE Transactions on Neural Networks},
  volume = {5},
  number = {4},
  pages = {537--550},
  issn = {10459227},
  doi = {10.1109/72.298224},
  urldate = {2022-07-26},
  file = {../../Bibliography/Battiti_1994_Using mutual information for selecting features in supervised neural net.pdf}
}

@article{bavaud_2011_SchoenbergTransformationsData,
  title = {On the {{Schoenberg Transformations}} in {{Data Analysis}}: {{Theory}} and {{Illustrations}}},
  shorttitle = {On the {{Schoenberg Transformations}} in {{Data Analysis}}},
  author = {Bavaud, Fran{\c c}ois},
  year = {2011},
  month = oct,
  journal = {Journal of Classification},
  volume = {28},
  number = {3},
  pages = {297--314},
  issn = {0176-4268, 1432-1343},
  doi = {10.1007/s00357-011-9092-x},
  urldate = {2022-08-31},
  langid = {english},
  file = {../../Bibliography/Bavaud_2011_On the Schoenberg Transformations in Data Analysis.pdf}
}

@article{beaumont_2019_ApproximateBayesianComputation,
  title = {Approximate {{Bayesian Computation}}},
  author = {Beaumont, Mark A.},
  year = {2019},
  month = mar,
  journal = {Annual Review of Statistics and Its Application},
  volume = {6},
  number = {1},
  pages = {379--403},
  issn = {2326-8298, 2326-831X},
  doi = {10.1146/annurev-statistics-030718-105212},
  urldate = {2021-11-18},
  abstract = {Many of the statistical models that could provide an accurate, interesting, and testable explanation for the structure of a data set turn out to have intractable likelihood functions. The method of approximate Bayesian computation (ABC) has become a popular approach for tackling such models. This review gives an overview of the method and the main issues and challenges that are the subject of current research.},
  langid = {english},
  file = {../../Bibliography/Beaumont_2019_Approximate Bayesian Computation.pdf}
}

@inproceedings{belkin_2001_LaplacianEigenmapsSpectral,
  title = {Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Belkin, Mikhail and Niyogi, Partha},
  editor = {Dietterich, T. and Becker, S. and Ghahramani, Z.},
  year = {2001},
  volume = {14},
  publisher = {MIT Press},
  file = {../../Bibliography/Belkin_2001_Laplacian eigenmaps and spectral techniques for embedding and clustering.pdf}
}

@inproceedings{belkin_2007_ConvergenceLaplacianEigenmaps,
  title = {Convergence of Laplacian Eigenmaps},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Belkin, Mikhail and Niyogi, Partha},
  editor = {Sch{\"o}lkopf, B. and Platt, J. and Hoffman, T.},
  year = {2007},
  volume = {19},
  publisher = {MIT Press},
  file = {../../Bibliography/Belkin_2007_Convergence of laplacian eigenmaps.pdf}
}

@article{bell_2024_NovelEstimatorEarths,
  title = {A Novel Estimator of {{Earth}}'s Curvature ({{Allowing}} for Inference as Well)},
  author = {Bell, David R. and Ledoit, Olivier and Wolf, Michael},
  year = {2024},
  month = mar,
  journal = {The Annals of Applied Statistics},
  volume = {18},
  number = {1},
  issn = {1932-6157},
  doi = {10.1214/23-AOAS1802},
  urldate = {2024-05-21},
  file = {../../Bibliography/Bell_2024_A novel estimator of Earth’s curvature (Allowing for inference as well).pdf}
}

@article{benamou_2015_IterativeBregmanProjections,
  title = {Iterative {{Bregman Projections}} for {{Regularized Transportation Problems}}},
  author = {Benamou, Jean-David and Carlier, Guillaume and Cuturi, Marco and Nenna, Luca and Peyr{\'e}, Gabriel},
  year = {2015},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {37},
  number = {2},
  pages = {A1111-A1138},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/141000439},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Benamou_2015_Iterative Bregman Projections for Regularized Transportation Problems.pdf}
}

@misc{bendokat_2023_GrassmannManifoldHandbook,
  title = {A {{Grassmann Manifold Handbook}}: {{Basic Geometry}} and {{Computational Aspects}}},
  shorttitle = {A {{Grassmann Manifold Handbook}}},
  author = {Bendokat, Thomas and Zimmermann, Ralf and Absil, P.-A.},
  year = {2023},
  month = nov,
  number = {arXiv:2011.13699},
  eprint = {2011.13699},
  primaryclass = {cs, math},
  publisher = {arXiv},
  urldate = {2023-12-19},
  archiveprefix = {arXiv},
  keywords = {15-02 15A16 15A18 15B10 22E70 51F25 53C80 53Z99,Mathematics - Differential Geometry,Mathematics - Numerical Analysis},
  file = {../../Bibliography/Bendokat_2023_A Grassmann Manifold Handbook.pdf;../../../../../Zotero/storage/2KCW73VC/2011.html}
}

@inproceedings{benhamza_2003_JensenrenyiDivergenceMeasure,
  title = {Jensen-Renyi Divergence Measure: Theoretical and Computational Perspectives},
  shorttitle = {Jensen-Renyi Divergence Measure},
  booktitle = {{{IEEE International Symposium}} on {{Information Theory}}, 2003. {{Proceedings}}.},
  author = {Ben Hamza, A. and Krim, H.},
  year = {2003},
  pages = {257--257},
  publisher = {IEEE},
  address = {Yokohama, Japan},
  doi = {10.1109/ISIT.2003.1228271},
  urldate = {2025-01-02},
  isbn = {978-0-7803-7728-8}
}

@book{berg_1984_HarmonicAnalysisSemigroups,
  title = {Harmonic {{Analysis}} on {{Semigroups}}},
  author = {Berg, Christian and Christensen, Jens Peter Reus and Ressel, Paul},
  year = {1984},
  series = {Graduate {{Texts}} in {{Mathematics}}},
  volume = {100},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4612-1128-0},
  urldate = {2024-09-12},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-1-4612-7017-1 978-1-4612-1128-0},
  file = {../../../../../Zotero/storage/6F7DZ8NZ/Berg et al. - 1984 - Harmonic Analysis on Semigroups.pdf}
}

@article{bergmann_2021_FenchelDualityTheory,
  title = {Fenchel {{Duality Theory}} and a {{Primal-Dual Algorithm}} on {{Riemannian Manifolds}}},
  author = {Bergmann, Ronny and Herzog, Roland and Silva Louzeiro, Maur{\'i}cio and Tenbrinck, Daniel and {Vidal-N{\'u}{\~n}ez}, Jos{\'e}},
  year = {2021},
  month = dec,
  journal = {Foundations of Computational Mathematics},
  volume = {21},
  number = {6},
  pages = {1465--1504},
  issn = {1615-3375, 1615-3383},
  doi = {10.1007/s10208-020-09486-5},
  urldate = {2024-08-30},
  abstract = {Abstract             This paper introduces a new notion of a Fenchel conjugate, which generalizes the classical Fenchel conjugation to functions defined on Riemannian manifolds. We investigate its properties, e.g.,~the Fenchel--Young inequality and the characterization of the convex subdifferential using the analogue of the Fenchel--Moreau Theorem. These properties of the Fenchel conjugate are employed to derive a Riemannian primal-dual optimization algorithm and to prove its convergence for the case of Hadamard manifolds under appropriate assumptions. Numerical results illustrate the performance of the algorithm, which competes with the recently derived Douglas--Rachford algorithm on manifolds of nonpositive curvature. Furthermore, we show numerically that our novel algorithm may even converge on manifolds of positive curvature.},
  langid = {english},
  file = {../../Bibliography/Bergmann_2021_Fenchel Duality Theory and a Primal-Dual Algorithm on Riemannian Manifolds.pdf}
}

@misc{bergmannronny_2021_Manoptjl,
  title = {Manopt.Jl},
  author = {Bergmann, Ronny},
  year = {2021},
  month = oct,
  doi = {10.5281/ZENODO.4290905},
  urldate = {2021-10-29},
  abstract = {Manopt.jl is a Julia package for optimization on manifolds.},
  copyright = {MIT License, Open Access},
  howpublished = {Zenodo},
  keywords = {Julia,manifolds,optimization,Programming,Riemannian manifolds}
}

@article{bernton_2019_ApproximateBayesianComputation,
  title = {Approximate {{Bayesian}} Computation with the {{Wasserstein}} Distance},
  author = {Bernton, Espen and Jacob, Pierre E. and Gerber, Mathieu and Robert, Christian P.},
  year = {2019},
  month = apr,
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {81},
  number = {2},
  pages = {235--269},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/rssb.12312},
  urldate = {2022-09-07},
  langid = {english},
  file = {../../Bibliography/Bernton_2019_Approximate Bayesian computation with the Wasserstein distance.pdf}
}

@article{bernton_2019_ParameterEstimationWasserstein,
  title = {On Parameter Estimation with the {{Wasserstein}} Distance},
  author = {Bernton, Espen and Jacob, Pierre E and Gerber, Mathieu and Robert, Christian P},
  year = {2019},
  month = dec,
  journal = {Information and Inference: A Journal of the IMA},
  volume = {8},
  number = {4},
  pages = {657--676},
  issn = {2049-8764, 2049-8772},
  doi = {10.1093/imaiai/iaz003},
  urldate = {2022-09-07},
  abstract = {Abstract             Statistical inference can be performed by minimizing, over the parameter space, the Wasserstein distance between model distributions and the empirical distribution of the data. We study asymptotic properties of such minimum Wasserstein distance estimators, complementing results derived by Bassetti, Bodini and Regazzini in 2006. In particular, our results cover the misspecified setting, in which the data-generating process is not assumed to be part of the family of distributions described by the model. Our results are motivated by recent applications of minimum Wasserstein estimators to complex generative models. We discuss some difficulties arising in the numerical approximation of these estimators. Two of our numerical examples (\$g\$-and-\${\textbackslash}kappa\$ and sum of log-normals) are taken from the literature on approximate Bayesian computation and have likelihood functions that are not analytically tractable. Two other examples involve misspecified models.},
  langid = {english},
  file = {../../Bibliography/Bernton_2019_On parameter estimation with the Wasserstein distance.pdf}
}

@article{bezanson_2017_JuliaFreshApproach,
  title = {Julia: {{A}} Fresh Approach to Numerical Computing},
  author = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B},
  year = {2017},
  journal = {SIAM review},
  volume = {59},
  number = {1},
  pages = {65--98},
  publisher = {SIAM}
}

@book{bhatia_2009_PositiveDefiniteMatrices,
  title = {Positive {{Definite Matrices}}},
  shorttitle = {Positive {{Definite Matrices}}},
  author = {Bhatia, Rajendra},
  year = {2009},
  month = dec,
  publisher = {Princeton University Press},
  doi = {10.1515/9781400827787},
  urldate = {2021-09-27},
  isbn = {978-1-4008-2778-7}
}

@article{bhattacharya_2012_NonparametricBayesClassification,
  title = {Nonparametric {{Bayes}} Classification and Hypothesis Testing on Manifolds},
  author = {Bhattacharya, Abhishek and Dunson, David},
  year = {2012},
  month = oct,
  journal = {Journal of Multivariate Analysis},
  volume = {111},
  pages = {1--19},
  issn = {0047259X},
  doi = {10.1016/j.jmva.2012.02.020},
  urldate = {2022-08-16},
  langid = {english},
  file = {../../Bibliography/Bhattacharya_2012_Nonparametric Bayes classification and hypothesis testing on manifolds.pdf}
}

@book{bhattacharya_2012_NonparametricInferenceManifolds,
  title = {Nonparametric {{Inference}} on {{Manifolds}}: {{With Applications}} to {{Shape Spaces}}},
  shorttitle = {Nonparametric {{Inference}} on {{Manifolds}}},
  author = {Bhattacharya, Abhishek and Bhattacharya, Rabi},
  year = {2012},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9781139094764},
  urldate = {2021-06-11},
  isbn = {978-1-139-09476-4}
}

@article{bhattacharya_2016_OmnibusCLTsFrechet,
  title = {Omnibus {{CLTs}} for {{Fr{\'e}chet}} Means and Nonparametric Inference on Non-{{Euclidean}} Spaces},
  author = {Bhattacharya, Rabi and Lin, Lizhen},
  year = {2016},
  month = jul,
  journal = {Proceedings of the American Mathematical Society},
  volume = {145},
  number = {1},
  pages = {413--428},
  issn = {0002-9939, 1088-6826},
  doi = {10.1090/proc/13216},
  urldate = {2022-08-28},
  langid = {english},
  file = {../../Bibliography/Bhattacharya_2016_Omnibus CLTs for Fréchet means and nonparametric inference on non-Euclidean.pdf}
}

@article{bhattacharyya_1946_MeasureDivergenceTwo,
  title = {On a Measure of Divergence between Two Multinomial Populations},
  author = {Bhattacharyya, Anil},
  year = {1946},
  journal = {Sankhy{\=a}: the indian journal of statistics},
  pages = {401--406},
  publisher = {JSTOR},
  file = {../../Bibliography/Bhattacharyya_1946_On a measure of divergence between two multinomial populations.pdf}
}

@article{bickel_2008_RegularizedEstimationLarge,
  title = {Regularized Estimation of Large Covariance Matrices},
  author = {Bickel, Peter J. and Levina, Elizaveta},
  year = {2008},
  month = feb,
  journal = {The Annals of Statistics},
  volume = {36},
  number = {1},
  issn = {0090-5364},
  doi = {10.1214/009053607000000758},
  urldate = {2024-03-04},
  file = {../../Bibliography/Bickel_2008_Regularized estimation of large covariance matrices.pdf}
}

@article{bigot_2017_GeodesicPCAWasserstein,
  title = {Geodesic {{PCA}} in the {{Wasserstein}} Space by Convex {{PCA}}},
  author = {Bigot, J{\'e}r{\'e}mie and Gouet, Ra{\'u}l and Klein, Thierry and L{\'o}pez, Alfredo},
  year = {2017},
  month = feb,
  journal = {Annales de l'Institut Henri Poincar{\'e}, Probabilit{\'e}s et Statistiques},
  volume = {53},
  number = {1},
  issn = {0246-0203},
  doi = {10.1214/15-AIHP706},
  urldate = {2022-09-07},
  file = {../../Bibliography/Bigot_2017_Geodesic PCA in the Wasserstein space by convex PCA.pdf}
}

@article{bigot_2018_CharacterizationBarycentersWasserstein,
  title = {Characterization of Barycenters in the {{Wasserstein}} Space by Averaging Optimal Transport Maps},
  author = {Bigot, J{\'e}r{\'e}mie and Klein, Thierry},
  year = {2018},
  journal = {ESAIM: Probability and Statistics},
  volume = {22},
  pages = {35--57},
  issn = {1262-3318},
  doi = {10.1051/ps/2017020},
  urldate = {2021-11-06},
  abstract = {This paper is concerned by the study of barycenters for random probability measures in the Wasserstein space. Using a duality argument, we give a precise characterization of the population barycenter for various parametric classes of random probability measures with compact support. In particular, we make a connection between averaging in the Wasserstein space as introduced in Agueh and Carlier [               SIAM J. Math. Anal.               43               (2011) 904--924], and taking the expectation of optimal transport maps with respect to a fixed reference measure. We also discuss the usefulness of this approach in statistics for the analysis of deformable models in signal and image processing. In this setting, the problem of estimating a population barycenter from               n               independent and identically distributed random probability measures is also considered.},
  file = {../../Bibliography/Bigot_2018_Characterization of barycenters in the Wasserstein space by averaging optimal.pdf}
}

@article{bilker_2012_DevelopmentAbbreviatedNineItem,
  title = {Development of {{Abbreviated Nine-Item Forms}} of the {{Raven}}'s {{Standard Progressive Matrices Test}}},
  author = {Bilker, Warren B. and Hansen, John A. and Brensinger, Colleen M. and Richard, Jan and Gur, Raquel E. and Gur, Ruben C.},
  year = {2012},
  month = sep,
  journal = {Assessment},
  volume = {19},
  number = {3},
  pages = {354--369},
  issn = {1073-1911, 1552-3489},
  doi = {10.1177/1073191112446655},
  urldate = {2024-08-14},
  abstract = {The Raven's Standard Progressive Matrices (RSPM) is a 60-item test for measuring abstract reasoning, considered a nonverbal estimate of fluid intelligence, and often included in clinical assessment batteries and research on patients with cognitive deficits. The goal was to develop and apply a predictive model approach to reduce the number of items necessary to yield a score equivalent to that derived from the full scale. The approach is based on a Poisson predictive model. A parsimonious subset of items that accurately predicts the total score was sought, as was a second nonoverlapping alternate form for repeated administrations. A split sample was used for model fitting and validation, with cross-validation to verify results. Using nine RSPM items as predictors, correlations of .9836 and .9782 were achieved for the reduced forms and .9063 and .8978 for the validation data. Thus, a 9-item subset of RSPM predicts the total score for the 60-item scale with good accuracy. A comparison of psychometric properties between 9-item forms, a published 30-item form, and the 60-item set is presented. The two 9-item forms provide a 75\% administration time savings compared with the 30-item form, while achieving similar item- and test-level characteristics and equal correlations to 60-item based scores.},
  langid = {english},
  file = {../../Bibliography/Bilker_2012_Development of Abbreviated Nine-Item Forms of the Raven’s Standard Progressive.pdf}
}

@article{billera_2001_GeometrySpacePhylogenetic,
  title = {Geometry of the {{Space}} of {{Phylogenetic Trees}}},
  author = {Billera, Louis J. and Holmes, Susan P. and Vogtmann, Karen},
  year = {2001},
  month = nov,
  journal = {Advances in Applied Mathematics},
  volume = {27},
  number = {4},
  pages = {733--767},
  issn = {01968858},
  doi = {10.1006/aama.2001.0759},
  urldate = {2021-10-29},
  langid = {english},
  file = {../../Bibliography/Billera_2001_Geometry of the Space of Phylogenetic Trees.pdf}
}

@book{billingsley_1999_ConvergenceProbabilityMeasures,
  title = {Convergence of Probability Measures},
  author = {Billingsley, Patrick},
  year = {1999},
  series = {Wiley Series in Probability and Statistics. {{Probability}} and Statistics Section},
  edition = {2nd ed},
  publisher = {Wiley},
  address = {New York},
  isbn = {978-0-471-19745-4},
  lccn = {QA273.6 .B55 1999},
  keywords = {Convergence,Metric spaces,Probability measures}
}

@book{bishop_1995_NeuralNetworksPattern,
  title = {Neural Networks for Pattern Recognition},
  author = {Bishop, Christopher M.},
  year = {1995},
  publisher = {Clarendon Press ; Oxford University Press},
  address = {Oxford : New York},
  isbn = {978-0-19-853849-3 978-0-19-853864-6},
  lccn = {QA76.87 .B574 1995},
  keywords = {Neural networks (Computer science),Pattern recognition systems}
}

@book{bishop_2006_PatternRecognitionMachine,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  year = {2006},
  series = {Information Science and Statistics},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-31073-2},
  lccn = {Q327 .B52 2006},
  keywords = {Machine learning,Pattern perception}
}

@inproceedings{bissacco_2001_RecognitionHumanGaits,
  title = {Recognition of Human Gaits},
  booktitle = {Proceedings of the 2001 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}. {{CVPR}} 2001},
  author = {Bissacco, A. and Chiuso, A. and Ma, Yi and Soatto, S.},
  year = {2001},
  volume = {2},
  pages = {II-52-II-57},
  publisher = {IEEE Comput. Soc},
  address = {Kauai, HI, USA},
  doi = {10.1109/CVPR.2001.990924},
  urldate = {2021-10-29},
  isbn = {978-0-7695-1272-3},
  file = {../../Bibliography/Bissacco_2001_Recognition of human gaits.pdf}
}

@article{bissiri_2016_GeneralFrameworkUpdating,
  title = {A {{General Framework}} for {{Updating Belief Distributions}}},
  author = {Bissiri, P. G. and Holmes, C. C. and Walker, S. G.},
  year = {2016},
  month = nov,
  journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {78},
  number = {5},
  pages = {1103--1130},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/rssb.12158},
  urldate = {2023-12-20},
  abstract = {Summary             We propose a framework for general Bayesian inference. We argue that a valid update of a prior belief distribution to a posterior can be made for parameters which are connected to observations through a loss function rather than the traditional likelihood function, which is recovered as a special case. Modern application areas make it increasingly challenging for Bayesians to attempt to model the true data-generating mechanism. For instance, when the object of interest is low dimensional, such as a mean or median, it is cumbersome to have to achieve this via a complete model for the whole data distribution. More importantly, there are settings where the parameter of interest does not directly index a family of density functions and thus the Bayesian approach to learning about such parameters is currently regarded as problematic. Our framework uses loss functions to connect information in the data to functionals of interest. The updating of beliefs then follows from a decision theoretic approach involving cumulative loss functions. Importantly, the procedure coincides with Bayesian updating when a true likelihood is known yet provides coherent subjective inference in much more general settings. Connections to other inference frameworks are highlighted.},
  langid = {english},
  file = {../../Bibliography/Bissiri_2016_A General Framework for Updating Belief Distributions.pdf}
}

@article{biswal_1995_FunctionalConnectivityMotor,
  title = {Functional Connectivity in the Motor Cortex of Resting Human Brain Using Echo-Planar Mri},
  author = {Biswal, Bharat and Zerrin Yetkin, F. and Haughton, Victor M. and Hyde, James S.},
  year = {1995},
  month = oct,
  journal = {Magnetic Resonance in Medicine},
  volume = {34},
  number = {4},
  pages = {537--541},
  issn = {07403194, 15222594},
  doi = {10.1002/mrm.1910340409},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Biswal_1995_Functional connectivity in the motor cortex of resting human brain using.pdf}
}

@article{biswas_2014_NonparametricTwosampleTest,
  title = {A Nonparametric Two-Sample Test Applicable to High Dimensional Data},
  author = {Biswas, Munmun and Ghosh, Anil K.},
  year = {2014},
  month = jan,
  journal = {Journal of Multivariate Analysis},
  volume = {123},
  pages = {160--171},
  issn = {0047259X},
  doi = {10.1016/j.jmva.2013.09.004},
  urldate = {2021-10-02},
  langid = {english},
  file = {../../Bibliography/Biswas_2014_A nonparametric two-sample test applicable to high dimensional data.pdf}
}

@misc{blumberg_2018_TestingDistinguishMeasures,
  title = {Testing to Distinguish Measures on Metric Spaces},
  author = {Blumberg, Andrew J. and Bhaumik, Prithwish and Walker, Stephen G.},
  year = {2018},
  month = feb,
  number = {arXiv:1802.01152},
  eprint = {1802.01152},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2022-07-26},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Geometry,Statistics - Machine Learning,Statistics - Methodology},
  file = {../../Bibliography/Blumberg_2018_Testing to distinguish measures on metric spaces.pdf}
}

@inproceedings{blundell_2015_WeightUncertaintyNeural,
  title = {Weight Uncertainty in Neural Networks},
  booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
  author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  year = {2015},
  series = {{{ICML}}'15},
  pages = {1613--1622},
  publisher = {JMLR.org},
  address = {Lille, France},
  file = {../../Bibliography/Blundell_2015_Weight uncertainty in neural networks.pdf}
}

@article{bonanno_2003_TopologyCorrelationbasedMinimal,
  title = {Topology of Correlation-Based Minimal Spanning Trees in Real and Model Markets},
  author = {Bonanno, Giovanni and Caldarelli, Guido and Lillo, Fabrizio and Mantegna, Rosario N.},
  year = {2003},
  month = oct,
  journal = {Physical Review E},
  volume = {68},
  number = {4},
  pages = {046130},
  issn = {1063-651X, 1095-3787},
  doi = {10.1103/PhysRevE.68.046130},
  urldate = {2022-09-12},
  langid = {english},
  file = {../../Bibliography/Bonanno_2003_Topology of correlation-based minimal spanning trees in real and model markets.pdf}
}

@misc{bonet_2023_SlicedWassersteinSymmetricPositive,
  title = {Sliced-{{Wasserstein}} on {{Symmetric Positive Definite Matrices}} for {{M}}/{{EEG Signals}}},
  author = {Bonet, Cl{\'e}ment and Mal{\'e}zieux, Beno{\^i}t and Rakotomamonjy, Alain and Drumetz, Lucas and Moreau, Thomas and Kowalski, Matthieu and Courty, Nicolas},
  year = {2023},
  month = mar,
  number = {arXiv:2303.05798},
  eprint = {2303.05798},
  primaryclass = {cs, eess, stat},
  publisher = {arXiv},
  urldate = {2023-04-12},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Signal Processing,Statistics - Machine Learning},
  file = {../../Bibliography/Bonet_2023_Sliced-Wasserstein on Symmetric Positive Definite Matrices for M-EEG Signals.pdf}
}

@book{borg_1997_ModernMultidimensionalScaling,
  title = {Modern Multidimensional Scaling: Theory and Applications},
  shorttitle = {Modern Multidimensional Scaling},
  author = {Borg, Ingwer and Groenen, Patrick J. F.},
  year = {1997},
  series = {Springer Series in Statistics},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-94845-4},
  lccn = {BF39.2.M85 B67 1997},
  keywords = {Data processing,Multidimensional scaling,Psychometrics}
}

@article{boumal_2014_ManoptMatlabToolbox,
  title = {Manopt, a {{Matlab}} Toolbox for Optimization on Manifolds},
  author = {Boumal, N. and Mishra, B. and Absil, P.-A. and Sepulchre, R.},
  year = {2014},
  journal = {Journal of Machine Learning Research},
  volume = {15},
  number = {42},
  pages = {1455--1459}
}

@book{boumal_2023_IntroductionOptimizationSmooth,
  title = {An {{Introduction}} to {{Optimization}} on {{Smooth Manifolds}}},
  author = {Boumal, Nicolas},
  year = {2023},
  month = mar,
  edition = {1},
  publisher = {Cambridge University Press},
  doi = {10.1017/9781009166164},
  urldate = {2024-06-07},
  abstract = {Optimization on Riemannian manifolds-the result of smooth geometry and optimization merging into one elegant modern framework-spans many areas of science and engineering, including machine learning, computer vision, signal processing, dynamical systems and scientific computing. This text introduces the differential geometry and Riemannian geometry concepts that will help students and researchers in applied mathematics, computer science and engineering gain a firm mathematical grounding to use these tools confidently in their research. Its charts-last approach will prove more intuitive from an optimizer's viewpoint, and all definitions and theorems are motivated to build time-tested optimization algorithms. Starting from first principles, the text goes on to cover current research on topics including worst-case complexity and geodesic convexity. Readers will appreciate the tricks of the trade for conducting research and for numerical implementations sprinkled throughout the book.},
  copyright = {https://www.cambridge.org/core/terms},
  isbn = {978-1-00-916616-4 978-1-00-916617-1 978-1-00-916615-7},
  file = {../../Bibliography/Boumal_2023_An Introduction to Optimization on Smooth Manifolds.pdf}
}

@inproceedings{boutsidis_2008_UnsupervisedFeatureSelection,
  title = {Unsupervised Feature Selection for Principal Components Analysis},
  booktitle = {Proceeding of the 14th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining - {{KDD}} 08},
  author = {Boutsidis, Christos and Mahoney, Michael W. and Drineas, Petros},
  year = {2008},
  pages = {61},
  publisher = {ACM Press},
  address = {Las Vegas, Nevada, USA},
  doi = {10.1145/1401890.1401903},
  urldate = {2022-07-05},
  isbn = {978-1-60558-193-4},
  langid = {english},
  file = {../../Bibliography/Boutsidis_2008_Unsupervised feature selection for principal components analysis.pdf}
}

@article{boutsidis_2013_DeterministicFeatureSelection,
  title = {Deterministic {{Feature Selection}} for {{K-Means Clustering}}},
  author = {Boutsidis, Christos and {Magdon-Ismail}, Malik},
  year = {2013},
  month = sep,
  journal = {IEEE Transactions on Information Theory},
  volume = {59},
  number = {9},
  pages = {6099--6110},
  issn = {0018-9448, 1557-9654},
  doi = {10.1109/TIT.2013.2255021},
  urldate = {2022-07-05},
  file = {../../Bibliography/Boutsidis_2013_Deterministic Feature Selection for K-Means Clustering.pdf}
}

@book{bouveyron_2019_ModelbasedClusteringClassification,
  title = {Model-Based Clustering and Classification for Data Science: With Applications in {{R}}},
  shorttitle = {Model-Based Clustering and Classification for Data Science},
  author = {Bouveyron, Charles and Celeux, Gilles and Murphy, Thomas Brendan and Raftery, Adrian E.},
  year = {2019},
  series = {Cambridge Series in Statistical and Probabilistic Mathematics},
  number = {50},
  publisher = {Cambridge University Press},
  address = {Cambridge, United Kingdom New York, NY},
  doi = {10.1017/9781108644181},
  isbn = {978-1-108-64418-1 978-1-108-49420-5},
  langid = {english}
}

@article{braunisch_2013_SelectingCorrelatedClimate,
  title = {Selecting from Correlated Climate Variables: A Major Source of Uncertainty for Predicting Species Distributions under Climate Change},
  shorttitle = {Selecting from Correlated Climate Variables},
  author = {Braunisch, Veronika and Coppes, Joy and Arlettaz, Rapha{\"e}l and Suchant, Rudi and Schmid, Hans and Bollmann, Kurt},
  year = {2013},
  month = sep,
  journal = {Ecography},
  volume = {36},
  number = {9},
  pages = {971--983},
  issn = {0906-7590, 1600-0587},
  doi = {10.1111/j.1600-0587.2013.00138.x},
  urldate = {2024-12-27},
  abstract = {Correlative species distribution models are frequently used to predict species' range shifts under climate change. However, climate variables often show high collinearity and most statistical approaches require the selection of one among strongly correlated variables. When causal relationships between species presence and climate parameters are unknown, variable selection is often arbitrary, or based on predictive performance under current conditions. While this should only marginally affect current range predictions, future distributions may vary considerably when climate parameters do not change in concert. We investigated this source of uncertainty using four highly correlated climate variables together with a constant set of landscape variables in order to predict current (2010) and future (2050) distributions of four mountain bird species in central Europe. Simulating different parameterization decisions, we generated a) four models including each of the climate variables singly, b) a model taking advantage of all variables simultaneously and c) an un-weighted average of the predictions of a). We compared model accuracy under current conditions, predicted distributions under four scenarios of climate change, and -- for one species -- evaluated back-projections using historical occurrence data. Although current and future variable-correlations remained constant, and the models' accuracy under contemporary conditions did not differ, future range predictions varied considerably in all climate change scenarios. Averaged models and models containing all climate variables simultaneously produced intermediate predictions; the latter, however, performed best in back-projections. This pattern, consistent across different modelling methods, indicates a benefit from including multiple climate predictors in ambiguous situations. Variable selection proved to be an important source of uncertainty for future range predictions, difficult to control using contemporary information. Small, but diverging changes of climate variables, masked by constant overall correlation patterns, can cause substantial differences between future range predictions which need to be accounted for, particularly when outcomes are intended for conservation decisions.},
  langid = {english}
}

@article{brenier_1991_PolarFactorizationMonotone,
  title = {Polar Factorization and Monotone Rearrangement of Vector-valued Functions},
  author = {Brenier, Yann},
  year = {1991},
  month = jun,
  journal = {Communications on Pure and Applied Mathematics},
  volume = {44},
  number = {4},
  pages = {375--417},
  issn = {0010-3640, 1097-0312},
  doi = {10.1002/cpa.3160440402},
  urldate = {2024-08-22},
  langid = {english}
}

@article{brier_2015_PartialCovarianceBased,
  title = {Partial Covariance Based Functional Connectivity Computation Using {{Ledoit}}--{{Wolf}} Covariance Regularization},
  author = {Brier, Matthew R. and Mitra, Anish and McCarthy, John E. and Ances, Beau M. and Snyder, Abraham Z.},
  year = {2015},
  month = nov,
  journal = {NeuroImage},
  volume = {121},
  pages = {29--38},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2015.07.039},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Brier_2015_Partial covariance based functional connectivity computation using Ledoit–Wolf.pdf}
}

@article{brookes_2011_MeasuringFunctionalConnectivity,
  title = {Measuring Functional Connectivity Using {{MEG}}: {{Methodology}} and Comparison with {{fcMRI}}},
  shorttitle = {Measuring Functional Connectivity Using {{MEG}}},
  author = {Brookes, Matthew J. and Hale, Joanne R. and Zumer, Johanna M. and Stevenson, Claire M. and Francis, Susan T. and Barnes, Gareth R. and Owen, Julia P. and Morris, Peter G. and Nagarajan, Srikantan S.},
  year = {2011},
  month = jun,
  journal = {NeuroImage},
  volume = {56},
  number = {3},
  pages = {1082--1104},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2011.02.054},
  urldate = {2022-09-12},
  langid = {english},
  file = {../../Bibliography/Brookes_2011_Measuring functional connectivity using MEG.pdf}
}

@inproceedings{brugnone_2019_CoarseGrainingData,
  title = {Coarse {{Graining}} of {{Data}} via {{Inhomogeneous Diffusion Condensation}}},
  booktitle = {2019 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Brugnone, Nathan and Gonopolskiy, Alex and Moyle, Mark W. and Kuchroo, Manik and van Dijk, David and Moon, Kevin R. and {Colon-Ramos}, Daniel and Wolf, Guy and Hirn, Matthew J. and Krishnaswamy, Smita},
  year = {2019},
  month = dec,
  pages = {2624--2633},
  publisher = {IEEE},
  address = {Los Angeles, CA, USA},
  doi = {10.1109/BigData47090.2019.9006013},
  urldate = {2021-09-02},
  isbn = {978-1-72810-858-2},
  file = {../../Bibliography/Brugnone_2019_Coarse Graining of Data via Inhomogeneous Diffusion Condensation.pdf}
}

@book{brzezniak_1999_BasicStochasticProcesses,
  title = {Basic {{Stochastic Processes}}},
  author = {Brze{\'z}niak, Zdzis{\l}aw and Zastawniak, Tomasz},
  year = {1999},
  series = {Springer {{Undergraduate Mathematics Series}}},
  publisher = {Springer London},
  address = {London},
  doi = {10.1007/978-1-4471-0533-6},
  urldate = {2023-12-19},
  isbn = {978-3-540-76175-4 978-1-4471-0533-6},
  file = {../../Bibliography/Brzeźniak_1999_Basic Stochastic Processes.pdf}
}

@book{buhlmann_2011_StatisticsHighDimensionalData,
  title = {Statistics for {{High-Dimensional Data}}: {{Methods}}, {{Theory}} and {{Applications}}},
  shorttitle = {Statistics for {{High-Dimensional Data}}},
  author = {B{\"u}hlmann, Peter and Van De Geer, Sara},
  year = {2011},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-20192-9},
  urldate = {2024-07-24},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-642-20191-2 978-3-642-20192-9},
  langid = {english},
  file = {../../Bibliography/Bühlmann_2011_Statistics for High-Dimensional Data.pdf}
}

@book{burden_2016_NumericalAnalysis,
  title = {Numerical Analysis},
  author = {Burden, Richard L. and Faires, J. Douglas and Burden, Annette M.},
  year = {2016},
  edition = {Tenth edition},
  publisher = {Cengage Learning},
  address = {Boston, MA},
  isbn = {978-1-305-25366-7},
  lccn = {QA297 .B84 2016},
  keywords = {Numerical analysis},
  annotation = {OCLC: ocn898154569}
}

@incollection{burgard_2008_DynamicCoverageVerification,
  title = {Dynamic Coverage Verification in Mobile Sensor Networks via Switched Higher Order Laplacians},
  booktitle = {Robotics: {{Science}} and Systems {{III}}},
  author = {Burgard, Wolfram and Brock, Oliver and Stachniss, Cyrill},
  year = {2008},
  pages = {305--312}
}

@article{butler_2002_LaplaceApproximationsHypergeometric,
  title = {Laplace Approximations for Hypergeometric Functions with Matrix Argument},
  author = {Butler, Roland W. and Wood, Andrew T. A.},
  year = {2002},
  month = aug,
  journal = {The Annals of Statistics},
  volume = {30},
  number = {4},
  issn = {0090-5364},
  doi = {10.1214/aos/1031689021},
  urldate = {2022-07-26},
  file = {../../Bibliography/Butler_2002_Laplace approximations for hypergeometric functions with matrix argument.pdf}
}

@article{byrne_2013_GeodesicMonteCarlo,
  title = {Geodesic {{Monte Carlo}} on {{Embedded Manifolds}}},
  author = {Byrne, Simon and Girolami, Mark},
  year = {2013},
  month = dec,
  journal = {Scandinavian Journal of Statistics},
  volume = {40},
  number = {4},
  pages = {825--845},
  issn = {0303-6898, 1467-9469},
  doi = {10.1111/sjos.12036},
  urldate = {2023-12-19},
  abstract = {ABSTRACT             Markov chain Monte Carlo methods explicitly defined on the manifold of probability distributions have recently been established. These methods are constructed from diffusions across the manifold and the solution of the equations describing geodesic flows in the Hamilton--Jacobi representation. This paper takes the differential geometric basis of Markov chain Monte Carlo further by considering methods to simulate from probability distributions that themselves are defined on a manifold, with common examples being classes of distributions describing directional statistics. Proposal mechanisms are developed based on the geodesic flows over the manifolds of support for the distributions, and illustrative examples are provided for the hypersphere and Stiefel manifold of orthonormal matrices.},
  langid = {english},
  file = {../../Bibliography/Byrne_2013_Geodesic Monte Carlo on Embedded Manifolds.pdf}
}

@inproceedings{cai_2008_SelfadaptiveSpectralClustering,
  title = {A Self-Adaptive Spectral Clustering Algorithm},
  booktitle = {2008 27th {{Chinese Control Conference}}},
  author = {Cai, Xiaoyan and Dai, Guanzhong and Yang, Libin and Zhang, Guoqing},
  year = {2008},
  month = jul,
  pages = {551--553},
  publisher = {IEEE},
  address = {Kunming, China},
  doi = {10.1109/CHICC.2008.4605517},
  urldate = {2022-07-25},
  file = {../../Bibliography/Cai_2008_A self-adaptive spectral clustering algorithm.pdf}
}

@article{cai_2013_TwoSampleCovarianceMatrix,
  title = {Two-{{Sample Covariance Matrix Testing}} and {{Support Recovery}} in {{High-Dimensional}} and {{Sparse Settings}}},
  author = {Cai, Tony and Liu, Weidong and Xia, Yin},
  year = {2013},
  month = mar,
  journal = {Journal of the American Statistical Association},
  volume = {108},
  number = {501},
  pages = {265--277},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2012.758041},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Cai_2013_Two-Sample Covariance Matrix Testing and Support Recovery in High-Dimensional.pdf}
}

@article{cai_2014_TwosampleTestHigh,
  title = {Two-Sample Test of High Dimensional Means under Dependence},
  author = {Cai, T. Tony and Liu, Weidong and Xia, Yin},
  year = {2014},
  journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
  volume = {76},
  number = {2},
  eprint = {24772460},
  eprinttype = {jstor},
  pages = {349--372},
  publisher = {[Royal Statistical Society, Wiley]},
  issn = {13697412, 14679868},
  urldate = {2022-07-26},
  file = {../../Bibliography/Cai_2014_Two-sample test of high dimensional means under dependence.pdf}
}

@article{calhoun_2014_ChronnectomeTimeVaryingConnectivity,
  title = {The {{Chronnectome}}: {{Time-Varying Connectivity Networks}} as the {{Next Frontier}} in {{fMRI Data Discovery}}},
  shorttitle = {The {{Chronnectome}}},
  author = {Calhoun, Vince~D. and Miller, Robyn and Pearlson, Godfrey and Adal{\i}, Tulay},
  year = {2014},
  month = oct,
  journal = {Neuron},
  volume = {84},
  number = {2},
  pages = {262--274},
  issn = {08966273},
  doi = {10.1016/j.neuron.2014.10.015},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Calhoun_2014_The Chronnectome.pdf}
}

@book{calin_2014_GeometricModelingProbability,
  title = {Geometric Modeling in Probability and Statistics},
  author = {Calin, Ovidiu},
  year = {2014},
  publisher = {Springer Science+Business Media, LLC},
  address = {New York, NY},
  isbn = {978-3-319-07778-9}
}

@article{calinski_1974_DendriteMethodCluster,
  title = {A Dendrite Method for Cluster Analysis},
  author = {Calinski, T. and Harabasz, J.},
  year = {1974},
  journal = {Communications in Statistics - Theory and Methods},
  volume = {3},
  number = {1},
  pages = {1--27},
  issn = {0361-0926},
  doi = {10.1080/03610927408827101},
  urldate = {2021-10-02},
  langid = {english},
  file = {../../Bibliography/Calinski_1974_A dendrite method for cluster analysis.pdf}
}

@article{cao_2019_TestSampleBehrens,
  title = {A Test for the k Sample {{Behrens}}--{{Fisher}} Problem in High Dimensional Data},
  author = {Cao, Ming-Xiang and Park, Junyong and He, Dao-Jiang},
  year = {2019},
  month = jul,
  journal = {Journal of Statistical Planning and Inference},
  volume = {201},
  pages = {86--102},
  issn = {03783758},
  doi = {10.1016/j.jspi.2018.12.002},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Cao_2019_A test for the k sample Behrens–Fisher problem in high dimensional data.pdf}
}

@article{carlsson_2004_PersistenceBarcodesShapes,
  title = {Persistence {{Barcodes}} for {{Shapes}}},
  author = {Carlsson, Gunnar and Zomorodian, Afra and Collins, Anne and Guibas, Leonidas},
  year = {2004},
  journal = {Symposium on Geometry Processing},
  pages = {12 pages},
  publisher = {The Eurographics Association},
  issn = {1727-8384},
  doi = {10.2312/SGP/SGP04/127-138},
  urldate = {2022-08-28},
  abstract = {In this paper, we initiate a study of shape description and classification via the application of persistent homology to two tangential constructions on geometric objects. Our techniques combine the differentiating power of geometry with the classifying power of topology. The homology of our first construction, the tangent complex, can distinguish between topologically identical shapes with different "sharp" features, such as corners. To capture "soft" curvature-dependent features, we define a second complex, the filtered tangent complex, obtained by parametrizing a family of increasing subcomplexes of the tangent complex. Applying persistent homology, we obtain a shape descriptor, called a barcode, that is a finite union of intervals. We define a metric over the space of such intervals, arriving at a continuous invariant that reflects the geometric properties of shapes. We illustrate the power of our methods through a number of detailed studies of parametrized families of mathematical shapes.},
  isbn = {9783905673135},
  langid = {english},
  file = {../../Bibliography/Carlsson_2004_Persistence Barcodes for Shapes.pdf}
}

@book{carmo_1992_RiemannianGeometry,
  title = {Riemannian Geometry},
  author = {do Carmo, Manfredo Perdig{\~a}o},
  year = {1992},
  series = {Mathematics. {{Theory}} \& Applications},
  publisher = {Birkh{\"a}user},
  address = {Boston},
  isbn = {978-0-8176-3490-2 978-3-7643-3490-1},
  langid = {english},
  lccn = {QA649 .C2913 1992},
  keywords = {Geometry Riemannian}
}

@article{carter_2009_FINEFisherInformation,
  title = {{{FINE}}: {{Fisher Information Nonparametric Embedding}}},
  shorttitle = {{{FINE}}},
  author = {Carter, K.M. and Raich, R. and Finn, W.G. and Hero, A.O.},
  year = {2009},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {31},
  number = {11},
  pages = {2093--2098},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2009.67},
  urldate = {2022-07-25},
  file = {../../Bibliography/Carter_2009_FINE.pdf}
}

@article{ceruti_2014_DANCoIntrinsicDimensionality,
  title = {{{DANCo}}: {{An}} Intrinsic Dimensionality Estimator Exploiting Angle and Norm Concentration},
  shorttitle = {{{DANCo}}},
  author = {Ceruti, Claudio and Bassis, Simone and Rozza, Alessandro and Lombardi, Gabriele and Casiraghi, Elena and Campadelli, Paola},
  year = {2014},
  month = aug,
  journal = {Pattern Recognition},
  volume = {47},
  number = {8},
  pages = {2569--2581},
  issn = {00313203},
  doi = {10.1016/j.patcog.2014.02.013},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Ceruti_2014_DANCo.pdf}
}

@inproceedings{cetingul_2009_IntrinsicMeanShift,
  title = {Intrinsic Mean Shift for Clustering on {{Stiefel}} and {{Grassmann}} Manifolds},
  booktitle = {2009 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Cetingul, Hasan Ertan and Vidal, Rene},
  year = {2009},
  month = jun,
  pages = {1896--1902},
  publisher = {IEEE},
  address = {Miami, FL},
  doi = {10.1109/CVPR.2009.5206806},
  urldate = {2022-07-25},
  isbn = {978-1-4244-3992-8},
  file = {../../Bibliography/Cetingul_2009_Intrinsic mean shift for clustering on Stiefel and Grassmann manifolds.pdf}
}

@article{cha_2016_VisionbasedDetectionLoosened,
  title = {Vision-Based Detection of Loosened Bolts Using the {{Hough}} Transform and Support Vector Machines},
  author = {Cha, Young-Jin and You, Kisung and Choi, Wooram},
  year = {2016},
  month = nov,
  journal = {Automation in Construction},
  volume = {71},
  pages = {181--188},
  issn = {09265805},
  doi = {10.1016/j.autcon.2016.06.008},
  urldate = {2021-10-20},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/Cha_2016_Vision-based detection of loosened bolts using the Hough transform and support.pdf}
}

@article{chambolle_2011_FirstOrderPrimalDualAlgorithm,
  title = {A {{First-Order Primal-Dual Algorithm}} for {{Convex Problems}} with {{Applications}} to {{Imaging}}},
  author = {Chambolle, Antonin and Pock, Thomas},
  year = {2011},
  month = may,
  journal = {Journal of Mathematical Imaging and Vision},
  volume = {40},
  number = {1},
  pages = {120--145},
  issn = {0924-9907, 1573-7683},
  doi = {10.1007/s10851-010-0251-1},
  urldate = {2022-03-27},
  langid = {english},
  file = {../../Bibliography/Chambolle_2011_A First-Order Primal-Dual Algorithm for Convex Problems with Applications to.pdf}
}

@article{chandra_1996_ElectricalResistanceGraph,
  title = {The Electrical Resistance of a Graph Captures Its Commute and Cover Times},
  author = {Chandra, Ashok K. and Raghavan, Prabhakar and Ruzzo, Walter L. and Smolensky, Roman and Tiwari, Prasoon},
  year = {1996},
  month = dec,
  journal = {Computational Complexity},
  volume = {6},
  number = {4},
  pages = {312--340},
  issn = {1016-3328, 1420-8954},
  doi = {10.1007/BF01270385},
  urldate = {2024-08-30},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {../../Bibliography/chandra_1996_the electrical resistance of a graph captures its commute and cover times.pdf}
}

@inproceedings{charfi_2013_BhattacharyyaMedianSymmetric,
  title = {Bhattacharyya Median of Symmetric Positive-Definite Matrices and Application to the Denoising of Diffusion-Tensor Fields},
  booktitle = {2013 {{IEEE}} 10th {{International Symposium}} on {{Biomedical Imaging}}},
  author = {Charfi, Malek and Chebbi, Zeineb and Moakher, Maher and Vemuri, Baba C.},
  year = {2013},
  month = apr,
  pages = {1227--1230},
  publisher = {IEEE},
  address = {San Francisco, CA, USA},
  doi = {10.1109/ISBI.2013.6556702},
  urldate = {2022-06-21},
  isbn = {978-1-4673-6455-3 978-1-4673-6456-0 978-1-4673-6454-6},
  file = {../../Bibliography/Charfi_2013_Bhattacharyya median of symmetric positive-definite matrices and application to.pdf}
}

@inproceedings{chartrand_2008_IterativelyReweightedAlgorithms,
  title = {Iteratively Reweighted Algorithms for Compressive Sensing},
  booktitle = {2008 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}}},
  author = {Chartrand, Rick and {Wotao Yin}},
  year = {2008},
  month = mar,
  pages = {3869--3872},
  publisher = {IEEE},
  address = {Las Vegas, NV, USA},
  issn = {1520-6149},
  doi = {10.1109/ICASSP.2008.4518498},
  urldate = {2022-09-07},
  isbn = {978-1-4244-1483-3 978-1-4244-1484-0},
  file = {../../Bibliography/Chartrand_2008_Iteratively reweighted algorithms for compressive sensing.pdf}
}

@article{chazal_2021_IntroductionTopologicalData,
  title = {An {{Introduction}} to {{Topological Data Analysis}}: {{Fundamental}} and {{Practical Aspects}} for {{Data Scientists}}},
  shorttitle = {An {{Introduction}} to {{Topological Data Analysis}}},
  author = {Chazal, Fr{\'e}d{\'e}ric and Michel, Bertrand},
  year = {2021},
  month = sep,
  journal = {Frontiers in Artificial Intelligence},
  volume = {4},
  pages = {667963},
  issn = {2624-8212},
  doi = {10.3389/frai.2021.667963},
  urldate = {2021-11-18},
  abstract = {With the recent explosion in the amount, the variety, and the dimensionality of available data, identifying, extracting, and exploiting their underlying structure has become a problem of fundamental importance for data analysis and statistical learning. Topological data analysis (               tda               ) is a recent and fast-growing field providing a set of new topological and geometric tools to infer relevant features for possibly complex data. It proposes new well-founded mathematical theories and computational tools that can be used independently or in combination with other data analysis and statistical learning techniques. This article is a brief introduction, through a few selected topics, to basic fundamental and practical aspects of               tda               for nonexperts.},
  file = {../../Bibliography/Chazal_2021_An Introduction to Topological Data Analysis.pdf}
}

@inproceedings{chen_2007_DirectedGraphEmbedding,
  title = {Directed Graph Embedding},
  booktitle = {Proceedings of the 20th International Joint Conference on Artifical Intelligence},
  author = {Chen, Mo and Yang, Qiong and Tang, Xiaoou},
  year = {2007},
  series = {{{IJCAI}}'07},
  pages = {2707--2712},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco, CA, USA},
  file = {../../Bibliography/Chen_2007_Directed graph embedding.pdf}
}

@article{chen_2010_ShrinkageAlgorithmsMMSE,
  title = {Shrinkage {{Algorithms}} for {{MMSE Covariance Estimation}}},
  author = {Chen, Yilun and Wiesel, Ami and Eldar, Yonina C. and Hero, Alfred O.},
  year = {2010},
  month = oct,
  journal = {IEEE Transactions on Signal Processing},
  volume = {58},
  number = {10},
  pages = {5016--5029},
  issn = {1053-587X, 1941-0476},
  doi = {10.1109/TSP.2010.2053029},
  urldate = {2022-07-26},
  file = {../../Bibliography/Chen_2010_Shrinkage Algorithms for MMSE Covariance Estimation.pdf}
}

@article{chen_2011_RobustShrinkageEstimation,
  title = {Robust {{Shrinkage Estimation}} of {{High-Dimensional Covariance Matrices}}},
  author = {Chen, Yilun and Wiesel, A. and Hero, A. O.},
  year = {2011},
  month = sep,
  journal = {IEEE Transactions on Signal Processing},
  volume = {59},
  number = {9},
  pages = {4097--4107},
  issn = {1053-587X, 1941-0476},
  doi = {10.1109/TSP.2011.2138698},
  urldate = {2022-07-25},
  file = {../../Bibliography/Chen_2011_Robust Shrinkage Estimation of High-Dimensional Covariance Matrices.pdf}
}

@article{chen_2015_ConvergenceConsistencyBlurring,
  title = {On the Convergence and Consistency of the Blurring Mean-Shift Process},
  author = {Chen, Ting-Li},
  year = {2015},
  month = feb,
  journal = {Annals of the Institute of Statistical Mathematics},
  volume = {67},
  number = {1},
  pages = {157--176},
  issn = {0020-3157, 1572-9052},
  doi = {10.1007/s10463-013-0443-8},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Chen_2015_On the convergence and consistency of the blurring mean-shift process.pdf}
}

@article{chen_2019_OptimalTransportGaussian,
  title = {Optimal {{Transport}} for {{Gaussian Mixture Models}}},
  author = {Chen, Yongxin and Georgiou, Tryphon T. and Tannenbaum, Allen},
  year = {2019},
  journal = {IEEE Access},
  volume = {7},
  pages = {6269--6278},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2018.2889838},
  urldate = {2021-10-01},
  file = {../../Bibliography/Chen_2019_Optimal Transport for Gaussian Mixture Models.pdf}
}

@misc{chen_2023_SlicedWassersteinRegression,
  title = {Sliced {{Wasserstein Regression}}},
  author = {Chen, Han and M{\"u}ller, Hans-Georg},
  year = {2023},
  month = jun,
  number = {arXiv:2306.10601},
  eprint = {2306.10601},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2023-09-04},
  abstract = {While statistical modeling of distributional data has gained increased attention, the case of multivariate distributions has been somewhat neglected despite its relevance in various applications. This is because the Wasserstein distance that is commonly used in distributional data analysis poses challenges for multivariate distributions. A promising alternative is the sliced Wasserstein distance, which offers a computationally simpler solution. We propose distributional regression models with multivariate distributions as responses paired with Euclidean vector predictors, working with the sliced Wasserstein distance, which is based on a slicing transform from the multivariate distribution space to the sliced distribution space. We introduce two regression approaches, one based on utilizing the sliced Wasserstein distance directly in the multivariate distribution space, and a second approach that employs a univariate distribution regression for each slice. We develop both global and local Fr{\textbackslash}'echet regression methods for these approaches and establish asymptotic convergence for sample-based estimators. The proposed regression methods are illustrated in simulations and by studying joint distributions of systolic and diastolic blood pressure as a function of age and joint distributions of excess winter death rates and winter temperature anomalies in European countries as a function of a country's base winter temperature.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Methodology},
  file = {../../Bibliography/Chen_2023_Sliced Wasserstein Regression.pdf}
}

@article{cheplygina_2015_MultipleInstanceLearning,
  title = {Multiple Instance Learning with Bag Dissimilarities},
  author = {Cheplygina, Veronika and Tax, David M.J. and Loog, Marco},
  year = {2015},
  month = jan,
  journal = {Pattern Recognition},
  volume = {48},
  number = {1},
  pages = {264--275},
  issn = {00313203},
  doi = {10.1016/j.patcog.2014.07.022},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Cheplygina_2015_Multiple instance learning with bag dissimilarities.pdf}
}

@inproceedings{cherian_2011_EfficientSimilaritySearch,
  title = {Efficient Similarity Search for Covariance Matrices via the {{Jensen-Bregman LogDet Divergence}}},
  booktitle = {2011 {{International Conference}} on {{Computer Vision}}},
  author = {Cherian, Anoop and Sra, Suvrit and Banerjee, Arindam and Papanikolopoulos, Nikolaos},
  year = {2011},
  month = nov,
  pages = {2399--2406},
  publisher = {IEEE},
  address = {Barcelona, Spain},
  doi = {10.1109/ICCV.2011.6126523},
  urldate = {2022-06-21},
  isbn = {978-1-4577-1102-2 978-1-4577-1101-5 978-1-4577-1100-8},
  file = {../../Bibliography/Cherian_2011_Efficient similarity search for covariance matrices via the Jensen-Bregman.pdf}
}

@article{cherian_2013_JensenBregmanLogDetDivergence,
  title = {Jensen-{{Bregman LogDet Divergence}} with {{Application}} to {{Efficient Similarity Search}} for {{Covariance Matrices}}},
  author = {Cherian, A. and Sra, S. and Banerjee, A. and Papanikolopoulos, N.},
  year = {2013},
  month = sep,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {35},
  number = {9},
  pages = {2161--2174},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2012.259},
  urldate = {2021-09-27},
  file = {../../Bibliography/Cherian_2013_Jensen-Bregman LogDet Divergence with Application to Efficient Similarity.pdf}
}

@article{chib_2001_MarginalLikelihoodMetropolis,
  title = {Marginal {{Likelihood From}} the {{Metropolis}}--{{Hastings Output}}},
  author = {Chib, Siddhartha and Jeliazkov, Ivan},
  year = {2001},
  month = mar,
  journal = {Journal of the American Statistical Association},
  volume = {96},
  number = {453},
  pages = {270--281},
  issn = {0162-1459, 1537-274X},
  doi = {10.1198/016214501750332848},
  urldate = {2024-01-10},
  langid = {english},
  file = {../../Bibliography/Chib_2001_Marginal Likelihood From the Metropolis–Hastings Output.pdf}
}

@book{chikuse_2003_StatisticsSpecialManifolds,
  title = {Statistics on Special Manifolds},
  author = {Chikuse, Yasuko},
  year = {2003},
  series = {Lecture Notes in Statistics},
  number = {174},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-00160-9},
  lccn = {QA613 .C48 2003},
  keywords = {Manifolds (Mathematics),Mathematical statistics}
}

@article{choudhari_2001_LikelihoodRatioTest,
  title = {Likelihood Ratio Test for Simultaneous Testing of the Mean and the Variance of a Normal Distribution},
  author = {Choudhari, Pankaj and Kundu, Debasis and Misra, Neeraj},
  year = {2001},
  month = dec,
  journal = {Journal of Statistical Computation and Simulation},
  volume = {71},
  number = {4},
  pages = {313--333},
  issn = {0094-9655, 1563-5163},
  doi = {10.1080/00949650108812151},
  urldate = {2022-07-25},
  langid = {english}
}

@book{chung_1997_SpectralGraphTheory,
  title = {Spectral Graph Theory},
  author = {Chung, Fan R. K.},
  year = {1997},
  series = {Regional Conference Series in Mathematics},
  number = {no. 92},
  publisher = {Published for the Conference Board of the mathematical sciences by the American Mathematical Society},
  address = {Providence, R.I},
  isbn = {978-0-8218-0315-8},
  lccn = {QA1 QA166 .R33 no. 92},
  keywords = {Congresses,Eigenvalues,Graph theory}
}

@misc{chung_2022_EmbeddingFunctionalHuman,
  title = {Embedding of {{Functional Human Brain Networks}} on a {{Sphere}}},
  author = {Chung, Moo K. and Chen, Zijian},
  year = {2022},
  month = may,
  number = {arXiv:2204.03653},
  eprint = {2204.03653},
  primaryclass = {q-bio},
  publisher = {arXiv},
  urldate = {2023-05-11},
  abstract = {Human brain activity is often measured using the blood-oxygen-level dependent (BOLD) signals obtained through functional magnetic resonance imaging (fMRI). The strength of connectivity between brain regions is then measured as a Pearson correlation matrix. As the number of brain regions increases, the dimension of matrix increases. It becomes extremely cumbersome to even visualize and quantify such weighted complete networks. To remedy the problem, we propose to embed brain networks onto a sphere, which is a Riemannian manifold with constant positive curvature. The Matlab code for the spherical embedding is given in https://github.com/laplcebeltrami/sphericalMDS.},
  archiveprefix = {arXiv},
  keywords = {Quantitative Biology - Other Quantitative Biology},
  file = {../../Bibliography/Chung_2022_Embedding of Functional Human Brain Networks on a Sphere.pdf}
}

@inproceedings{claici_2018_StochasticWassersteinBarycenters,
  title = {Stochastic {{Wasserstein}} Barycenters},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  author = {Claici, Sebastian and Chien, Edward and Solomon, Justin},
  editor = {Dy, Jennifer and Krause, Andreas},
  year = {2018-07-10/2018-07-15},
  series = {Proceedings of Machine Learning Research},
  volume = {80},
  pages = {999--1008},
  publisher = {PMLR},
  pdf = {http://proceedings.mlr.press/v80/claici18a/claici18a.pdf},
  file = {../../Bibliography/Claici_2018_Stochastic Wasserstein barycenters.pdf}
}

@book{cohen_2014_AnalyzingNeuralTime,
  title = {Analyzing Neural Time Series Data: Theory and Practice},
  shorttitle = {Analyzing Neural Time Series Data},
  author = {Cohen, Mike X.},
  year = {2014},
  series = {Issues in Clinical and Cognitive Neuropsychology},
  publisher = {The MIT Press},
  address = {Cambridge, Massachusetts},
  isbn = {978-0-262-01987-3},
  lccn = {QP363.3 .C633 2014},
  keywords = {Artificial intelligence,Biological applications,Computational neuroscience,Neural networks (Computer science),Neural networks (Neurobiology)}
}

@misc{cohen_2021_EstimatingBarycentersMeasures,
  title = {Estimating {{Barycenters}} of {{Measures}} in {{High Dimensions}}},
  author = {Cohen, Samuel and Arbel, Michael and Deisenroth, Marc Peter},
  year = {2021},
  month = feb,
  number = {arXiv:2007.07105},
  eprint = {2007.07105},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-03-03},
  abstract = {Barycentric averaging is a principled way of summarizing populations of measures. Existing algorithms for estimating barycenters typically parametrize them as weighted sums of Diracs and optimize their weights and/or locations. However, these approaches do not scale to high-dimensional settings due to the curse of dimensionality. In this paper, we propose a scalable and general algorithm for estimating barycenters of measures in high dimensions. The key idea is to turn the optimization over measures into an optimization over generative models, introducing inductive biases that allow the method to scale while still accurately estimating barycenters. We prove local convergence under mild assumptions on the discrepancy showing that the approach is well-posed. We demonstrate that our method is fast, achieves good performance on low-dimensional problems, and scales to high-dimensional settings. In particular, our approach is the first to be used to estimate barycenters in thousands of dimensions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {../../Bibliography/Cohen_2021_Estimating Barycenters of Measures in High Dimensions2.pdf;../../../../../Zotero/storage/NVPKP9PZ/2007.html}
}

@misc{cohen_2021_EstimatingBarycentersMeasuresa,
  title = {Estimating {{Barycenters}} of {{Measures}} in {{High Dimensions}}},
  author = {Cohen, Samuel and Arbel, Michael and Deisenroth, Marc Peter},
  year = {2021},
  month = feb,
  number = {arXiv:2007.07105},
  eprint = {2007.07105},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-03-03},
  abstract = {Barycentric averaging is a principled way of summarizing populations of measures. Existing algorithms for estimating barycenters typically parametrize them as weighted sums of Diracs and optimize their weights and/or locations. However, these approaches do not scale to high-dimensional settings due to the curse of dimensionality. In this paper, we propose a scalable and general algorithm for estimating barycenters of measures in high dimensions. The key idea is to turn the optimization over measures into an optimization over generative models, introducing inductive biases that allow the method to scale while still accurately estimating barycenters. We prove local convergence under mild assumptions on the discrepancy showing that the approach is well-posed. We demonstrate that our method is fast, achieves good performance on low-dimensional problems, and scales to high-dimensional settings. In particular, our approach is the first to be used to estimate barycenters in thousands of dimensions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {../../Bibliography/Cohen_2021_Estimating Barycenters of Measures in High Dimensions.pdf;../../../../../Zotero/storage/59HCZEG8/2007.html}
}

@misc{cohen2021estimating,
  title = {Estimating Barycenters of Measures in High Dimensions},
  author = {Cohen, Samuel and Arbel, Michael and Deisenroth, Marc Peter},
  year = {2021},
  eprint = {2007.07105},
  primaryclass = {stat.ML},
  archiveprefix = {arXiv},
  file = {../../Bibliography/Cohen_2021_Estimating barycenters of measures in high dimensions3.pdf}
}

@article{coifman_2006_DiffusionMaps,
  title = {Diffusion Maps},
  author = {Coifman, Ronald R. and Lafon, St{\'e}phane},
  year = {2006},
  month = jul,
  journal = {Applied and Computational Harmonic Analysis},
  volume = {21},
  number = {1},
  pages = {5--30},
  issn = {10635203},
  doi = {10.1016/j.acha.2006.04.006},
  urldate = {2021-11-17},
  langid = {english},
  file = {../../Bibliography/Coifman_2006_Diffusion maps.pdf}
}

@misc{collas_2023_EntropicWassersteinComponent,
  title = {Entropic {{Wasserstein Component Analysis}}},
  author = {Collas, Antoine and Vayer, Titouan and Flamary, R{\'e}mi and Breloy, Arnaud},
  year = {2023},
  month = mar,
  number = {arXiv:2303.05119},
  eprint = {2303.05119},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2023-06-08},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {../../Bibliography/Collas_2023_Entropic Wasserstein Component Analysis.pdf}
}

@misc{conci_2018_DistanceSetsSurvey,
  title = {Distance {{Between Sets}} - {{A}} Survey},
  author = {Conci, A. and Kubrusly, C. S.},
  year = {2018},
  month = aug,
  number = {arXiv:1808.02574},
  eprint = {1808.02574},
  primaryclass = {math},
  publisher = {arXiv},
  urldate = {2022-07-25},
  abstract = {The purpose of this paper is to give a survey on the notions of distance between subsets either of a metric space or of a measure space, including definitions, a classification, and a discussion of the best-known distance functions, which is followed by a review on applications used in many areas of knowledge, ranging from theoretical to practical applications.},
  archiveprefix = {arXiv},
  keywords = {28A78 54E35,Mathematics - Functional Analysis},
  file = {../../Bibliography/Conci_2018_Distance Between Sets - A survey.pdf}
}

@book{cormen_2009_IntroductionAlgorithms,
  title = {Introduction to Algorithms},
  editor = {Cormen, Thomas H.},
  year = {2009},
  edition = {3rd ed},
  publisher = {MIT Press},
  address = {Cambridge, Mass},
  isbn = {978-0-262-03384-8 978-0-262-53305-8},
  lccn = {QA76.6 .C662 2009},
  keywords = {Computer algorithms,Computer programming},
  annotation = {OCLC: ocn311310321}
}

@article{cortes_2012_AlgorithmsLearningKernels,
  title = {Algorithms for Learning Kernels Based on Centered Alignment},
  author = {Cortes, Corinna and Mohri, Mehryar and Rostamizadeh, Afshin},
  year = {2012},
  month = mar,
  journal = {Journal of Machine Learning Research},
  volume = {13},
  number = {1},
  pages = {795--828},
  publisher = {JMLR.org},
  issn = {1532-4435},
  issue_date = {January 2012},
  keywords = {feature selection,kernel methods,learning kernels},
  file = {../../Bibliography/Cortes_2012_Algorithms for learning kernels based on centered alignment.pdf}
}

@inproceedings{costa_2005_EstimatingLocalIntrinsic,
  title = {Estimating {{Local Intrinsic Dimension}} with K-{{Nearest Neighbor Graphs}}},
  booktitle = {{{IEEE}}/{{SP}} 13th {{Workshop}} on {{Statistical Signal Processing}}, 2005},
  author = {Costa, J.A. and Girotra, A. and Hero, A.O.},
  year = {2005},
  pages = {417--422},
  publisher = {IEEE},
  address = {Bordeaux, France},
  doi = {10.1109/SSP.2005.1628631},
  urldate = {2022-07-25},
  isbn = {978-0-7803-9403-2},
  file = {../../Bibliography/Costa_2005_Estimating Local Intrinsic Dimension with k-Nearest Neighbor Graphs.pdf}
}

@inproceedings{courty_2017_JointDistributionOptimal,
  title = {Joint Distribution Optimal Transportation for Domain Adaptation},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Courty, Nicolas and Flamary, R{\'e}mi and Habrard, Amaury and Rakotomamonjy, Alain},
  editor = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Courty_2017_Joint distribution optimal transportation for domain adaptation.pdf}
}

@article{courty_2017_OptimalTransportDomain,
  title = {Optimal {{Transport}} for {{Domain Adaptation}}},
  author = {Courty, Nicolas and Flamary, Remi and Tuia, Devis and Rakotomamonjy, Alain},
  year = {2017},
  month = sep,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {39},
  number = {9},
  pages = {1853--1865},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2016.2615921},
  urldate = {2022-09-07},
  file = {../../Bibliography/Courty_2017_Optimal Transport for Domain Adaptation.pdf}
}

@article{cover_1967_NearestNeighborPattern,
  title = {Nearest Neighbor Pattern Classification},
  author = {Cover, T. and Hart, P.},
  year = {1967},
  month = jan,
  journal = {IEEE Transactions on Information Theory},
  volume = {13},
  number = {1},
  pages = {21--27},
  issn = {0018-9448, 1557-9654},
  doi = {10.1109/TIT.1967.1053964},
  urldate = {2024-02-23}
}

@article{cox_1991_MultidimensionalScalingSphere,
  title = {Multidimensional Scaling on a Sphere},
  author = {Cox, Trevor F. and Cox, Michael A.A.},
  year = {1991},
  month = jan,
  journal = {Communications in Statistics - Theory and Methods},
  volume = {20},
  number = {9},
  pages = {2943--2953},
  issn = {0361-0926, 1532-415X},
  doi = {10.1080/03610929108830679},
  urldate = {2023-05-11},
  langid = {english}
}

@book{criminisi_2013_DecisionForestsComputer,
  title = {Decision Forests for Computer Vision and Medical Image Analysis},
  editor = {Criminisi, Antonio and Shotton, J.},
  year = {2013},
  series = {Advances in Computer Vision and Pattern Recognition},
  publisher = {Springer},
  address = {London ; New York},
  abstract = {This practical and easy-to-follow text explores the theoretical underpinnings of decision forests, organizing the vast existing literature on the field within a new, general-purpose forest model. Topics and features: with a foreword by Prof. Y. Amit and Prof. D. Geman, recounting their participation in the development of decision forests; introduces a flexible decision forest model, capable of addressing a large and diverse set of image and video analysis tasks; investigates both the theoretical foundations and the practical implementation of decision forests.--},
  isbn = {978-1-4471-4928-6 978-1-4471-4929-3},
  lccn = {TA1634 .D43 2013},
  keywords = {Computer vision,Decision trees,Diagnostic imaging,Digital techniques,Image processing},
  annotation = {OCLC: ocn842841944},
  file = {../../Bibliography/Criminisi_2013_Decision forests for computer vision and medical image analysis.pdf}
}

@incollection{criminisi_2013_DensityForests,
  title = {Density {{Forests}}},
  booktitle = {Decision {{Forests}} for {{Computer Vision}} and {{Medical Image Analysis}}},
  author = {Criminisi, A. and Shotton, J.},
  editor = {Criminisi, A. and Shotton, J.},
  year = {2013},
  pages = {59--77},
  publisher = {Springer London},
  address = {London},
  doi = {10.1007/978-1-4471-4929-3_6},
  urldate = {2022-07-16},
  isbn = {978-1-4471-4928-6 978-1-4471-4929-3}
}

@incollection{criminisi_2013_ManifoldForests,
  title = {Manifold {{Forests}}},
  booktitle = {Decision {{Forests}} for {{Computer Vision}} and {{Medical Image Analysis}}},
  author = {Criminisi, A. and Shotton, J.},
  editor = {Criminisi, A. and Shotton, J.},
  year = {2013},
  pages = {79--93},
  publisher = {Springer London},
  address = {London},
  doi = {10.1007/978-1-4471-4929-3_7},
  urldate = {2022-07-17},
  isbn = {978-1-4471-4928-6 978-1-4471-4929-3}
}

@inproceedings{crouse_2011_LookGaussianMixture,
  title = {A Look at {{Gaussian}} Mixture Reduction Algorithms},
  booktitle = {14th {{International Conference}} on {{Information Fusion}}},
  author = {Crouse, David F. and Willett, Peter and Pattipati, Krishna and Svensson, Lennart},
  year = {2011},
  pages = {1--8},
  keywords = {Approximation algorithms,clustering,Clustering algorithms,Context,Correlation,Gaussian mixture reduction,ISE,Merging,nonlinear optimization,Optimization,Target tracking,tracking}
}

@article{cuesta_1989_NotesWassersteinMetric,
  title = {Notes on the {{Wasserstein Metric}} in {{Hilbert Spaces}}},
  author = {Cuesta, Juan Antonio and Matran, Carlos},
  year = {1989},
  month = jul,
  journal = {The Annals of Probability},
  volume = {17},
  number = {3},
  issn = {0091-1798},
  doi = {10.1214/aop/1176991269},
  urldate = {2024-08-22},
  file = {../../Bibliography/cuesta_1989_notes on the wasserstein metric in hilbert spaces.pdf}
}

@inproceedings{cuturi_2013_SinkhornDistancesLightspeed,
  title = {Sinkhorn Distances: {{Lightspeed}} Computation of Optimal Transport},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Cuturi, Marco},
  editor = {Burges, C.J. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K.Q.},
  year = {2013},
  volume = {26},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Cuturi_2013_Sinkhorn distances.pdf}
}

@inproceedings{cuturi_2014_FastComputationWasserstein,
  title = {Fast Computation of Wasserstein Barycenters},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning},
  author = {Cuturi, Marco and Doucet, Arnaud},
  editor = {Xing, Eric P. and Jebara, Tony},
  year = {2014-06-22/2014-06-24},
  series = {Proceedings of Machine Learning Research},
  volume = {32},
  pages = {685--693},
  publisher = {PMLR},
  address = {Bejing, China},
  pdf = {http://proceedings.mlr.press/v32/cuturi14.pdf},
  file = {../../Bibliography/Cuturi_2014_Fast computation of wasserstein barycenters.pdf}
}

@article{daubechies_2010_IterativelyReweightedLeast,
  title = {Iteratively Reweighted Least Squares Minimization for Sparse Recovery},
  author = {Daubechies, Ingrid and DeVore, Ronald and Fornasier, Massimo and G{\"u}nt{\"u}rk, C. S{\.i}nan},
  year = {2010},
  month = jan,
  journal = {Communications on Pure and Applied Mathematics},
  volume = {63},
  number = {1},
  pages = {1--38},
  issn = {0010-3640, 1097-0312},
  doi = {10.1002/cpa.20303},
  urldate = {2024-03-04},
  langid = {english},
  file = {../../Bibliography/Daubechies_2010_Iteratively reweighted least squares minimization for sparse recovery.pdf}
}

@phdthesis{david_2019_RiemannianQuotientStructure,
  title = {A {{Riemannian Quotient Structure}} for {{Correlation Matrices}} with {{Applications}} to {{Data Science}}},
  author = {David, Paul},
  year = {2019},
  school = {Claremont Graduate University},
  file = {../../Bibliography/David_2019_A Riemannian Quotient Structure for Correlation Matrices with Applications to.pdf}
}

@article{david_2019_RiemannianStructureCorrelation,
  title = {A {{Riemannian}} Structure for Correlation Matrices},
  author = {David, P. and Gu, W.},
  year = {2019},
  journal = {Operators and Matrices},
  pages = {607--627}
}

@inproceedings{davis_2006_DifferentialEntropicClustering,
  title = {Differential {{Entropic Clustering}} of {{Multivariate Gaussians}}},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Davis, Jason and Dhillon, Inderjit},
  editor = {Sch{\"o}lkopf, B. and Platt, J. and Hoffman, T.},
  year = {2006},
  volume = {19},
  publisher = {MIT Press},
  file = {../../Bibliography/davis_2006_differential entropic clustering of multivariate gaussians.pdf}
}

@article{defranchis_2022_BavenoVIIRenewing,
  title = {Baveno {{VII}} -- {{Renewing}} Consensus in Portal Hypertension},
  author = {De Franchis, Roberto and Bosch, Jaime and {Garcia-Tsao}, Guadalupe and Reiberger, Thomas and Ripoll, Cristina and Abraldes, Juan G. and Albillos, Agustin and Baiges, Anna and Bajaj, Jasmohan and Ba{\~n}ares, Rafael and Barrufet, Marta and Benajiba, Lina and Berzigotti, Annalisa and Bureau, Christophe and Calvaruso, Vincenza and Cardenas, Andres and D'Amico, Gennaro and De Gottardi, Andrea and Dell'Era, Alessandra and Escorsell, Angels and Fallowfield, Jonathan and Ferral, Hector and Francque, Sven and Gaba, Ron and {Garcia-Pag{\`a}n}, Juan Carlos and Genesc{\`a}, Joan and Rodrigues, Susana Gomes and {Gracia-Sancho}, Jordi and Han, Guogong and {Hernandez-Gea}, Virginia and Jia, Jidong and Kiladjian, Jean Jacques and Krag, Aleksander and Laleman, Wim and La Mura, Vincenzo and Lens, Sabela and Luo, Xuefeng and Mandorfer, Mattias and Murad, Sarwa Darwish and Paradis, Valerie and Patch, David and Piano, Salvatore and Pinzani, Massimo and Plessier, Aurelie and Primignani, Massimo and Procopet, Bogdan and Rautou, Pierre Emmanuel and Rudler, Marika and Sarin, Shiv K. and Schepis, Filippo and Senzolo, Marco and Shah, Vijay and Shukla, Akash and Tandon, Puneeta and Tellez, Luis and Thabut, Dominique and Thiele, Maja and Trebicka, Jonel and Tripathi, Dhiraj and Tsochatzis, Emmanouil and Turco, Laura and Turon, Fanny and Valla, Dominique and Villanueva, Candid and Wanless, Ian and Yoshiji, Hitoshi},
  year = {2022},
  month = apr,
  journal = {Journal of Hepatology},
  volume = {76},
  number = {4},
  pages = {959--974},
  issn = {01688278},
  doi = {10.1016/j.jhep.2021.12.022},
  urldate = {2024-06-30},
  langid = {english},
  file = {../../Bibliography/De Franchis_2022_Baveno VII – Renewing consensus in portal hypertension.pdf}
}

@article{delbarrio_1999_CentralLimitTheorems,
  title = {Central {{Limit Theorems}} for the {{Wasserstein Distance Between}} the {{Empirical}} and the {{True Distributions}}},
  author = {{del Barrio}, Eustasio and Gin{\'e}, Evarist and Matr{\'a}n, Carlos},
  year = {1999},
  month = apr,
  journal = {The Annals of Probability},
  volume = {27},
  number = {2},
  issn = {0091-1798},
  doi = {10.1214/aop/1022677394},
  urldate = {2022-09-07},
  file = {../../Bibliography/del Barrio_1999_Central Limit Theorems for the Wasserstein Distance Between the Empirical and.pdf}
}

@article{delbarrio_2019_RobustClusteringTools,
  title = {Robust Clustering Tools Based on Optimal Transportation},
  author = {{del Barrio}, Eustasio and {Cuesta-Albertos}, Juan Antonio and Matr{\'a}n, C. and {Mayo-{\'I}scar}, Agust{\'{\i}}n},
  year = {2019},
  month = jan,
  journal = {Statistics and Computing},
  volume = {29},
  number = {1},
  pages = {139--160},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-018-9800-z},
  urldate = {2023-09-04},
  langid = {english},
  file = {../../Bibliography/del Barrio_2019_Robust clustering tools based on optimal transportation.pdf}
}

@incollection{deleeuw_1977_ApplicationsConvexAnalysis,
  title = {Applications of Convex Analysis to Multidimensional Scaling},
  booktitle = {Recent Developments in Statistics},
  author = {{de Leeuw}, Jan},
  editor = {Barra, J.R. and Brodeau, F. and Romier, G. and Cutsem, B. Van},
  year = {1977},
  pages = {133--146},
  publisher = {North Holland Publishing Company},
  address = {Amsterdam},
  keywords = {dipliteratur mds visualization}
}

@incollection{deligianni_2011_ProbabilisticFrameworkInfer,
  title = {A {{Probabilistic Framework}} to {{Infer Brain Functional Connectivity}} from {{Anatomical Connections}}},
  booktitle = {Information {{Processing}} in {{Medical Imaging}}},
  author = {Deligianni, Fani and Varoquaux, Gael and Thirion, Bertrand and Robinson, Emma and Sharp, David J. and Edwards, A. David and Rueckert, Daniel},
  editor = {Sz{\'e}kely, G{\'a}bor and Hahn, Horst K.},
  year = {2011},
  volume = {6801},
  pages = {296--307},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-22092-0_25},
  urldate = {2021-10-04},
  isbn = {978-3-642-22091-3 978-3-642-22092-0},
  file = {../../Bibliography/Deligianni_2011_A Probabilistic Framework to Infer Brain Functional Connectivity from.pdf}
}

@article{delon_2020_WassersteinTypeDistanceSpace,
  title = {A {{Wasserstein-Type Distance}} in the {{Space}} of {{Gaussian Mixture Models}}},
  author = {Delon, Julie and Desolneux, Agn{\`e}s},
  year = {2020},
  month = jan,
  journal = {SIAM Journal on Imaging Sciences},
  volume = {13},
  number = {2},
  pages = {936--970},
  issn = {1936-4954},
  doi = {10.1137/19M1301047},
  urldate = {2021-10-01},
  langid = {english},
  file = {../../Bibliography/Delon_2020_A Wasserstein-Type Distance in the Space of Gaussian Mixture Models.pdf}
}

@book{demmel_1997_AppliedNumericalLinear,
  title = {Applied Numerical Linear Algebra},
  author = {Demmel, James W.},
  year = {1997},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {Philadelphia},
  isbn = {978-0-89871-389-3},
  lccn = {QA184 .D455 1997},
  keywords = {Algebras Linear,Numerical calculations},
  file = {../../Bibliography/Demmel_1997_Applied numerical linear algebra.pdf}
}

@article{demmel_2007_FastLinearAlgebra,
  title = {Fast Linear Algebra Is Stable},
  author = {Demmel, James and Dumitriu, Ioana and Holtz, Olga},
  year = {2007},
  month = oct,
  journal = {Numerische Mathematik},
  volume = {108},
  number = {1},
  pages = {59--91},
  issn = {0029-599X, 0945-3245},
  doi = {10.1007/s00211-007-0114-x},
  urldate = {2023-12-14},
  langid = {english},
  file = {../../Bibliography/Demmel_2007_Fast linear algebra is stable.pdf}
}

@article{dempster_1958_HighDimensionalTwo,
  title = {A {{High Dimensional Two Sample Significance Test}}},
  author = {Dempster, A. P.},
  year = {1958},
  month = dec,
  journal = {The Annals of Mathematical Statistics},
  volume = {29},
  number = {4},
  pages = {995--1010},
  issn = {0003-4851},
  doi = {10.1214/aoms/1177706437},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Dempster_1958_A High Dimensional Two Sample Significance Test.pdf}
}

@article{dempster_1977_MaximumLikelihoodIncomplete,
  title = {Maximum {{Likelihood}} from {{Incomplete Data Via}} the {{{\emph{EM}}}} {{Algorithm}}},
  author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
  year = {1977},
  month = sep,
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {39},
  number = {1},
  pages = {1--22},
  issn = {00359246},
  doi = {10.1111/j.2517-6161.1977.tb01600.x},
  urldate = {2022-02-22},
  langid = {english}
}

@book{dennett_1987_IntentionalStance,
  title = {The {{Intentional Stance}}},
  author = {Dennett, D. C.},
  year = {1987},
  publisher = {MIT Press},
  address = {Cambridge, Mass},
  isbn = {978-0-262-04093-8},
  lccn = {B105.I56 D46 1987},
  keywords = {Intentionality (Philosophy)}
}

@inproceedings{devlin_2019_BERTPretrainingDeep,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  booktitle = {Proceedings of the 2019 {{Conference}} of the {{North}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  pages = {4171--4186},
  publisher = {Association for Computational Linguistics},
  address = {Minneapolis, Minnesota},
  doi = {10.18653/v1/N19-1423},
  urldate = {2024-04-07},
  langid = {english}
}

@article{dhillon_2001_ConceptDecompositionsLarge,
  title = {Concept {{Decompositions}} for {{Large Sparse Text Data Using Clustering}}},
  author = {Dhillon, Inderjit S. and Modha, Dharmendra S.},
  year = {2001},
  journal = {Machine Learning},
  volume = {42},
  number = {1/2},
  pages = {143--175},
  issn = {08856125},
  doi = {10.1023/A:1007612920971},
  urldate = {2022-02-23},
  file = {../../Bibliography/Dhillon_2001_Concept Decompositions for Large Sparse Text Data Using Clustering.pdf}
}

@misc{diethe_2015_NoteKullbackLeiblerDivergence,
  title = {A {{Note}} on the {{Kullback-Leibler Divergence}} for the von {{Mises-Fisher}} Distribution},
  author = {Diethe, Tom},
  year = {2015},
  month = feb,
  number = {arXiv:1502.07104},
  eprint = {1502.07104},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1502.07104},
  urldate = {2025-02-04},
  abstract = {We present a derivation of the Kullback Leibler (KL)-Divergence (also known as Relative Entropy) for the von Mises Fisher (VMF) Distribution in \$d\$-dimensions.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Machine Learning},
  file = {../../../../../Zotero/storage/RKNAHCQE/Diethe - 2015 - A Note on the Kullback-Leibler Divergence for the .pdf;../../../../../Zotero/storage/58GANLEL/1502.html}
}

@inproceedings{ding_2002_AdaptiveDimensionReduction,
  title = {Adaptive Dimension Reduction for Clustering High Dimensional Data},
  booktitle = {2002 {{IEEE International Conference}} on {{Data Mining}}, 2002. {{Proceedings}}.},
  author = {Ding, C. and {Xiaofeng He} and {Hongyuan Zha} and Simon, H.D.},
  year = {2002},
  pages = {147--154},
  publisher = {IEEE Comput. Soc},
  address = {Maebashi City, Japan},
  doi = {10.1109/ICDM.2002.1183897},
  urldate = {2022-06-28},
  isbn = {978-0-7695-1754-4},
  file = {../../Bibliography/Ding_2002_Adaptive dimension reduction for clustering high dimensional data.pdf}
}

@article{ding_2021_GeometryWassersteinSpace,
  title = {Geometry on the {{Wasserstein Space Over}} a {{Compact Riemannian Manifold}}},
  author = {Ding, Hao and Fang, Shizan},
  year = {2021},
  month = nov,
  journal = {Acta Mathematica Scientia},
  volume = {41},
  number = {6},
  pages = {1959--1984},
  issn = {0252-9602, 1572-9087},
  doi = {10.1007/s10473-021-0612-4},
  urldate = {2023-12-20},
  langid = {english},
  file = {../../Bibliography/Ding_2021_Geometry on the Wasserstein Space Over a Compact Riemannian Manifold.pdf}
}

@article{ding_2022_CooperativeLearningMultiview,
  title = {Cooperative Learning for Multiview Analysis},
  author = {Ding, Daisy Yi and Li, Shuangning and Narasimhan, Balasubramanian and Tibshirani, Robert},
  year = {2022},
  month = sep,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {38},
  pages = {e2202113119},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2202113119},
  urldate = {2023-12-26},
  abstract = {We propose a method for supervised learning with multiple sets of features (``views''). The multiview problem is especially important in biology and medicine, where ``-omics'' data, such as genomics, proteomics, and radiomics, are measured on a common set of samples. ``Cooperative learning'' combines the usual squared-error loss of predictions with an ``agreement'' penalty to encourage the predictions from different data views to agree. By varying the weight of the agreement penalty, we get a continuum of solutions that include the well-known early and late fusion approaches. Cooperative learning chooses the degree of agreement (or fusion) in an adaptive manner, using a validation set or cross-validation to estimate test set prediction error. One version of our fitting procedure is modular, where one can choose different fitting mechanisms (e.g., lasso, random forests, boosting, or neural networks) appropriate for different data views. In the setting of cooperative regularized linear regression, the method combines the lasso penalty with the agreement penalty, yielding feature sparsity. The method can be especially powerful when the different data views share some underlying relationship in their signals that can be exploited to boost the signals. We show that cooperative learning achieves higher predictive accuracy on simulated data and real multiomics examples of labor-onset prediction. By leveraging aligned signals and allowing flexible fitting mechanisms for different modalities, cooperative learning offers a powerful approach to multiomics data fusion.},
  langid = {english},
  file = {../../Bibliography/Ding_2022_Cooperative learning for multiview analysis.pdf}
}

@article{doersch_2016_TutorialVariationalAutoencoders,
  title = {Tutorial on {{Variational Autoencoders}}},
  author = {Doersch, Carl},
  year = {2016},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1606.05908},
  urldate = {2022-03-23},
  abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  file = {../../Bibliography/Doersch_2016_Tutorial on Variational Autoencoders.pdf}
}

@article{dosenbach_2010_PredictionIndividualBrain,
  title = {Prediction of {{Individual Brain Maturity Using fMRI}}},
  author = {Dosenbach, Nico U. F. and Nardos, Binyam and Cohen, Alexander L. and Fair, Damien A. and Power, Jonathan D. and Church, Jessica A. and Nelson, Steven M. and Wig, Gagan S. and Vogel, Alecia C. and {Lessov-Schlaggar}, Christina N. and Barnes, Kelly Anne and Dubis, Joseph W. and Feczko, Eric and Coalson, Rebecca S. and Pruett, John R. and Barch, Deanna M. and Petersen, Steven E. and Schlaggar, Bradley L.},
  year = {2010},
  month = sep,
  journal = {Science},
  volume = {329},
  number = {5997},
  pages = {1358--1361},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1194144},
  urldate = {2021-10-04},
  abstract = {Group functional connectivity magnetic resonance imaging (fcMRI) studies have documented reliable changes in human functional brain maturity over development. Here we show that support vector machine-based multivariate pattern analysis extracts sufficient information from fcMRI data to make accurate predictions about individuals' brain maturity across development. The use of only 5 minutes of resting-state fcMRI data from 238 scans of typically developing volunteers (ages 7 to 30 years) allowed prediction of individual brain maturity as a functional connectivity maturation index. The resultant functional maturation curve accounted for 55\% of the sample variance and followed a nonlinear asymptotic growth curve shape. The greatest relative contribution to predicting individual brain maturity was made by the weakening of short-range functional connections between the adult brain's major functional networks.},
  langid = {english},
  file = {../../Bibliography/Dosenbach_2010_Prediction of Individual Brain Maturity Using fMRI.pdf}
}

@article{dowson_1982_FrechetDistanceMultivariate,
  title = {The {{Fr{\'e}chet}} Distance between Multivariate Normal Distributions},
  author = {Dowson, D.C and Landau, B.V},
  year = {1982},
  month = sep,
  journal = {Journal of Multivariate Analysis},
  volume = {12},
  number = {3},
  pages = {450--455},
  issn = {0047259X},
  doi = {10.1016/0047-259X(82)90077-X},
  urldate = {2021-11-09},
  langid = {english},
  file = {../../Bibliography/Dowson_1982_The Fréchet distance between multivariate normal distributions.pdf}
}

@inproceedings{drucker_1996_SupportVectorRegression,
  title = {Support Vector Regression Machines},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Drucker, Harris and Burges, Christopher J. C. and Kaufman, Linda and Smola, Alex and Vapnik, Vladimir},
  editor = {Mozer, M.C. and Jordan, M. and Petsche, T.},
  year = {1996},
  volume = {9},
  publisher = {MIT Press},
  file = {../../Bibliography/Drucker_1996_Support vector regression machines.pdf}
}

@book{dryden_1998_StatisticalShapeAnalysis,
  title = {Statistical Shape Analysis},
  author = {Dryden, I. L. and Mardia, K. V.},
  year = {1998},
  series = {Wiley Series in Probability and Statistics},
  publisher = {John Wiley \& Sons},
  address = {Chichester ; New York},
  isbn = {978-0-471-95816-1},
  lccn = {QA612.7 .D79 1998},
  keywords = {Shape theory (Topology),Statistical methods}
}

@article{dryden_2009_NonEuclideanStatisticsCovariance,
  title = {Non-{{Euclidean}} Statistics for Covariance Matrices, with Applications to Diffusion Tensor Imaging},
  author = {Dryden, Ian L. and Koloydenko, Alexey and Zhou, Diwei},
  year = {2009},
  month = sep,
  journal = {The Annals of Applied Statistics},
  volume = {3},
  number = {3},
  issn = {1932-6157},
  doi = {10.1214/09-AOAS249},
  urldate = {2021-09-27},
  file = {../../Bibliography/Dryden_2009_Non-Euclidean statistics for covariance matrices, with applications to.pdf}
}

@book{dryden_2016_StatisticalShapeAnalysis,
  title = {Statistical Shape Analysis with Applications in {{R}}},
  author = {Dryden, I. L. and Mardia, K. V.},
  year = {2016},
  series = {Wiley Series in Probability and Statistics},
  edition = {Second edition},
  publisher = {Wiley},
  address = {Chichester, UK ; Hoboken, NJ},
  isbn = {978-0-470-69962-1},
  lccn = {QA612.7 .D79 2016},
  keywords = {Shape theory (Topology),Statistical methods}
}

@article{drysdale_2017_RestingstateConnectivityBiomarkers,
  title = {Resting-State Connectivity Biomarkers Define Neurophysiological Subtypes of Depression},
  author = {Drysdale, Andrew T and Grosenick, Logan and Downar, Jonathan and Dunlop, Katharine and Mansouri, Farrokh and Meng, Yue and Fetcho, Robert N and Zebley, Benjamin and Oathes, Desmond J and Etkin, Amit and Schatzberg, Alan F and Sudheimer, Keith and Keller, Jennifer and Mayberg, Helen S and Gunning, Faith M and Alexopoulos, George S and Fox, Michael D and {Pascual-Leone}, Alvaro and Voss, Henning U and Casey, Bj and Dubin, Marc J and Liston, Conor},
  year = {2017},
  month = jan,
  journal = {Nature Medicine},
  volume = {23},
  number = {1},
  pages = {28--38},
  issn = {1078-8956, 1546-170X},
  doi = {10.1038/nm.4246},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Drysdale_2017_Resting-state connectivity biomarkers define neurophysiological subtypes of.pdf}
}

@article{dubey_2019_FrechetAnalysisVariance,
  title = {Fr{\'e}chet Analysis of Variance for Random Objects},
  author = {Dubey, Paromita and M{\"u}ller, Hans-Georg},
  year = {2019},
  month = dec,
  journal = {Biometrika},
  volume = {106},
  number = {4},
  pages = {803--821},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/asz052},
  urldate = {2022-03-10},
  abstract = {Summary             Fr{\'e}chet mean and variance provide a way of obtaining a mean and variance for metric space-valued random variables, and can be used for statistical analysis of data objects that lie in abstract spaces devoid of algebraic structure and operations. Examples of such data objects include covariance matrices, graph Laplacians of networks and univariate probability distribution functions. We derive a central limit theorem for the Fr{\'e}chet variance under mild regularity conditions, using empirical process theory, and also provide a consistent estimator of the asymptotic variance. These results lead to a test for comparing \$k\$ populations of metric space-valued data objects in terms of Fr{\'e}chet means and variances. We examine the finite-sample performance of this novel inference procedure through simulation studies on several special cases that include probability distributions and graph Laplacians, leading to a test for comparing populations of networks. The proposed approach has good finite-sample performance in simulations for different kinds of random objects. We illustrate the proposed methods by analysing data on mortality profiles of various countries and resting-state functional magnetic resonance imaging data.},
  langid = {english}
}

@article{dubey_2020_FrechetChangepointDetection,
  title = {Fr{\'e}chet Change-Point Detection},
  author = {Dubey, Paromita and M{\"u}ller, Hans-Georg},
  year = {2020},
  month = dec,
  journal = {The Annals of Statistics},
  volume = {48},
  number = {6},
  issn = {0090-5364},
  doi = {10.1214/19-AOS1930},
  urldate = {2022-03-10}
}

@book{duda_2001_PatternClassification,
  title = {Pattern Classification},
  author = {Duda, Richard O. and Hart, Peter E. and Stork, David G.},
  year = {2001},
  edition = {2nd ed},
  publisher = {Wiley},
  address = {New York},
  isbn = {978-0-471-05669-0},
  lccn = {Q327 .D83 2001},
  keywords = {Pattern recognition systems,Statistical decision}
}

@book{dullerud_2005_CourseRobustControl,
  title = {A Course in Robust Control Theory: A Convex Approach},
  shorttitle = {A Course in Robust Control Theory},
  author = {Dullerud, Geir E. and Paganini, Fernando},
  year = {2005},
  series = {Texts in Applied Mathematics},
  edition = {2., corr. printing},
  number = {36},
  publisher = {Springer},
  address = {New York Berlin Heidelberg},
  isbn = {978-0-387-98945-7},
  langid = {english}
}

@inproceedings{dvurechenskii_2018_DecentralizeRandomizeFaster,
  title = {Decentralize and Randomize: {{Faster}} Algorithm for Wasserstein Barycenters},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Dvurechenskii, Pavel and Dvinskikh, Darina and Gasnikov, Alexander and Uribe, Cesar and Nedich, Angelia},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and {Cesa-Bianchi}, N. and Garnett, R.},
  year = {2018},
  volume = {31},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Dvurechenskii_2018_Decentralize and randomize.pdf}
}

@article{dy_2004_FeatureSelectionUnsupervised,
  title = {Feature Selection for Unsupervised Learning},
  author = {Dy, Jennifer G. and Brodley, Carla E.},
  year = {2004},
  month = dec,
  journal = {Journal of Machine Learning Research},
  volume = {5},
  pages = {845--889},
  publisher = {JMLR.org},
  issn = {1532-4435},
  issue_date = {12/1/2004},
  file = {../../Bibliography/Dy_2004_Feature selection for unsupervised learning.pdf}
}

@article{eaves_1994_SubtypesAutismCluster,
  title = {Subtypes of Autism by Cluster Analysis},
  author = {Eaves, Linda C. and Ho, Helena H. and Eaves, David M.},
  year = {1994},
  month = feb,
  journal = {Journal of Autism and Developmental Disorders},
  volume = {24},
  number = {1},
  pages = {3--22},
  issn = {0162-3257, 1573-3432},
  doi = {10.1007/BF02172209},
  urldate = {2024-12-28},
  copyright = {http://www.springer.com/tdm},
  langid = {english}
}

@article{eddelbuettel_2011_RcppSeamlessIntegration,
  title = {Rcpp : {{Seamless R}} and {{C}}++ {{Integration}}},
  shorttitle = {{\textbf{Rcpp}}},
  author = {Eddelbuettel, Dirk and Fran{\c c}ois, Romain},
  year = {2011},
  journal = {Journal of Statistical Software},
  volume = {40},
  number = {8},
  issn = {1548-7660},
  doi = {10.18637/jss.v040.i08},
  urldate = {2021-10-29},
  langid = {english}
}

@article{eddelbuettel_2014_RcppArmadilloAcceleratingHighperformance,
  title = {{{RcppArmadillo}}: {{Accelerating R}} with High-Performance {{C}}++ Linear Algebra},
  shorttitle = {{{RcppArmadillo}}},
  author = {Eddelbuettel, Dirk and Sanderson, Conrad},
  year = {2014},
  month = mar,
  journal = {Computational Statistics \& Data Analysis},
  volume = {71},
  pages = {1054--1063},
  issn = {01679473},
  doi = {10.1016/j.csda.2013.02.005},
  urldate = {2021-10-29},
  langid = {english}
}

@article{edelman_2005_RandomMatrixTheory,
  title = {Random Matrix Theory},
  author = {Edelman, Alan and Rao, N. Raj},
  year = {2005},
  month = may,
  journal = {Acta Numerica},
  volume = {14},
  pages = {233--297},
  issn = {0962-4929, 1474-0508},
  doi = {10.1017/S0962492904000236},
  urldate = {2022-03-27},
  abstract = {Random matrix theory is now a big subject with applications in many disciplines of science, engineering and finance. This article is a survey specifically oriented towards the needs and interests of a numerical analyst. This survey includes some original material not found anywhere else. We include the important mathematics which is a very modern development, as well as the computational software that is transforming the theory into useful practice.},
  langid = {english}
}

@article{edelsbrunner_2002_TopologicalPersistenceSimplification,
  title = {Topological {{Persistence}} and {{Simplification}}},
  author = {{Edelsbrunner} and {Letscher} and {Zomorodian}},
  year = {2002},
  month = nov,
  journal = {Discrete \& Computational Geometry},
  volume = {28},
  number = {4},
  pages = {511--533},
  issn = {0179-5376, 1432-0444},
  doi = {10.1007/s00454-002-2885-2},
  urldate = {2022-08-28},
  langid = {english},
  file = {../../Bibliography/Edelsbrunner_2002_Topological Persistence and Simplification.pdf}
}

@book{edelsbrunner_2010_ComputationalTopologyIntroduction,
  title = {Computational Topology: An Introduction},
  shorttitle = {Computational Topology},
  author = {Edelsbrunner, Herbert and Harer, J.},
  year = {2010},
  publisher = {American Mathematical Society},
  address = {Providence, R.I},
  isbn = {978-0-8218-4925-5},
  lccn = {QA611 .E353 2010},
  keywords = {Algorithms,Computational complexity,Data processing,Geometry,Topology},
  annotation = {OCLC: ocn427757156}
}

@book{efron_2016_ComputerAgeStatistical,
  title = {Computer Age Statistical Inference: Algorithms, Evidence, and Data Science},
  shorttitle = {Computer Age Statistical Inference},
  author = {Efron, Bradley and Hastie, Trevor},
  year = {2016},
  series = {Institute of {{Mathematical Statistics}} Monographs},
  publisher = {Cambridge University Press},
  address = {New York, NY},
  isbn = {978-1-107-14989-2},
  lccn = {QA276.4 .E376 2016},
  keywords = {Data processing,Mathematical statistics},
  file = {../../Bibliography/Efron_2016_Computer age statistical inference.pdf}
}

@inproceedings{elhamifar_2009_SparseSubspaceClustering,
  title = {Sparse Subspace Clustering},
  booktitle = {2009 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Elhamifar, Ehsan and Vidal, Rene},
  year = {2009},
  month = jun,
  pages = {2790--2797},
  publisher = {IEEE},
  address = {Miami, FL},
  doi = {10.1109/CVPR.2009.5206547},
  urldate = {2022-07-26},
  isbn = {978-1-4244-3992-8},
  file = {../../Bibliography/Elhamifar_2009_Sparse subspace clustering.pdf}
}

@article{elmoselhy_2012_BayesianInferenceOptimal,
  title = {Bayesian Inference with Optimal Maps},
  author = {El Moselhy, Tarek A. and Marzouk, Youssef M.},
  year = {2012},
  month = oct,
  journal = {Journal of Computational Physics},
  volume = {231},
  number = {23},
  pages = {7815--7850},
  issn = {00219991},
  doi = {10.1016/j.jcp.2012.07.022},
  urldate = {2022-09-07},
  langid = {english},
  file = {../../Bibliography/El Moselhy_2012_Bayesian inference with optimal maps.pdf}
}

@book{elton_2014_ModernPortfolioTheory,
  title = {Modern Portfolio Theory and Investment Analysis},
  author = {Elton, Edwin J.},
  year = {2014},
  edition = {Ninth edition},
  publisher = {Wiley},
  address = {Hoboken, NJ},
  isbn = {978-1-118-46994-1},
  lccn = {HG4529.5 .E47 2014},
  keywords = {Investment analysis,Portfolio management}
}

@article{engel_2012_SurveyDimensionReduction,
  title = {A {{Survey}} of {{Dimension Reduction Methods}} for {{High-dimensional Data Analysis}} and {{Visualization}}},
  author = {Engel, Daniel and H{\"u}ttenberger, Lars and Hamann, Bernd},
  year = {2012},
  pages = {15 pages},
  publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany},
  doi = {10.4230/OASICS.VLUDS.2011.135},
  urldate = {2021-11-17},
  collaborator = {Herbstritt, Marc},
  langid = {english},
  keywords = {000 Computer science knowledge general works,Computer Science},
  file = {../../Bibliography/Engel_2012_A Survey of Dimension Reduction Methods for High-dimensional Data Analysis and.pdf}
}

@article{erba_2019_IntrinsicDimensionEstimation,
  title = {Intrinsic Dimension Estimation for Locally Undersampled Data},
  author = {Erba, Vittorio and Gherardi, Marco and Rotondo, Pietro},
  year = {2019},
  month = dec,
  journal = {Scientific Reports},
  volume = {9},
  number = {1},
  pages = {17133},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-53549-9},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Erba_2019_Intrinsic dimension estimation for locally undersampled data.pdf}
}

@book{everitt_2010_HandbookStatisticalAnalyses,
  title = {A Handbook of Statistical Analyses Using {{R}}},
  author = {Everitt, Brian and Hothorn, Torsten},
  year = {2010},
  edition = {2nd ed},
  publisher = {CRC Press},
  address = {Boca Raton},
  isbn = {978-1-4200-7933-3},
  lccn = {QA276.45.R3 E94 2010},
  keywords = {Data processing,Handbooks manuals etc,Mathematical statistics,R (Computer program language)},
  annotation = {OCLC: ocn226357301}
}

@article{facco_2017_EstimatingIntrinsicDimension,
  title = {Estimating the Intrinsic Dimension of Datasets by a Minimal Neighborhood Information},
  author = {Facco, Elena and {d'Errico}, Maria and Rodriguez, Alex and Laio, Alessandro},
  year = {2017},
  month = dec,
  journal = {Scientific Reports},
  volume = {7},
  number = {1},
  pages = {12140},
  issn = {2045-2322},
  doi = {10.1038/s41598-017-11873-y},
  urldate = {2021-11-01},
  langid = {english},
  file = {../../Bibliography/Facco_2017_Estimating the intrinsic dimension of datasets by a minimal neighborhood.pdf}
}

@article{fan_2016_OverviewEstimationLarge,
  title = {An Overview of the Estimation of Large Covariance and Precision Matrices},
  author = {Fan, Jianqing and Liao, Yuan and Liu, Han},
  year = {2016},
  month = feb,
  journal = {The Econometrics Journal},
  volume = {19},
  number = {1},
  pages = {C1-C32},
  issn = {1368-4221, 1368-423X},
  doi = {10.1111/ectj.12061},
  urldate = {2021-10-10},
  langid = {english},
  file = {../../Bibliography/Fan_2016_An overview of the estimation of large covariance and precision matrices.pdf}
}

@inproceedings{fan_2021_ScalableComputationsWasserstein,
  title = {Scalable {{Computations}} of {{Wasserstein Barycenter}} via {{Input Convex Neural Networks}}},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  author = {Fan, Amirhossein, Jiaojiao, Taghvaei and Chen, Yongxin},
  editor = {Meila, Marina and Zhang, Tong},
  year = {2021-07-18/2021-07-24},
  series = {Proceedings of Machine Learning Research},
  volume = {139},
  pages = {1571--1581},
  publisher = {PMLR},
  abstract = {Wasserstein Barycenter is a principled approach to represent the weighted mean of a given set of probability distributions, utilizing the geometry induced by optimal transport. In this work, we present a novel scalable algorithm to approximate the Wasserstein Barycenters aiming at high-dimensional applications in machine learning. Our proposed algorithm is based on the Kantorovich dual formulation of the Wasserstein-2 distance as well as a recent neural network architecture, input convex neural network, that is known to parametrize convex functions. The distinguishing features of our method are: i) it only requires samples from the marginal distributions; ii) unlike the existing approaches, it represents the Barycenter with a generative model and can thus generate infinite samples from the barycenter without querying the marginal distributions; iii) it works similar to Generative Adversarial Model in one marginal case. We demonstratethe efficacy of our algorithm by comparing it with the state-of-art methods in multiple experiments.},
  file = {../../Bibliography/Fan_2021_Scalable Computations of Wasserstein Barycenter via Input Convex Neural Networks.pdf}
}

@misc{fan_2022_NeuralMongeMap,
  title = {Neural {{Monge Map}} Estimation and Its Applications},
  author = {Fan, Jiaojiao and Liu, Shu and Ma, Shaojun and Zhou, Haomin and Chen, Yongxin},
  year = {2022},
  month = nov,
  number = {arXiv:2106.03812},
  eprint = {2106.03812},
  primaryclass = {cs, math},
  publisher = {arXiv},
  urldate = {2023-03-17},
  abstract = {Monge map refers to the optimal transport map between two probability distributions and provides a principled approach to transform one distribution to another. Neural network based optimal transport map solver has gained great attention in recent years. Along this line, we present a scalable algorithm for computing the neural Monge map between two probability distributions. Our algorithm is based on a weak form of the optimal transport problem, thus it only requires samples from the marginals instead of their analytic expressions, and can accommodate optimal transport between two distributions with different dimensions. Our algorithm is suitable for general cost functions, compared with other existing methods for estimating Monge maps using samples, which are usually for quadratic costs. The performance of our algorithms is demonstrated through a series of experiments with both synthetic and realistic data, including text-to-image generation and image inpainting tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  file = {../../Bibliography/Fan_2022_Neural Monge Map estimation and its applications.pdf}
}

@article{fauteux_2021_IdentificationTranscriptionalSubtypes,
  title = {Identification of Transcriptional Subtypes in Lung Adenocarcinoma and Squamous Cell Carcinoma through Integrative Analysis of Microarray and {{RNA}} Sequencing Data},
  author = {Fauteux, Fran{\c c}ois and Surendra, Anuradha and McComb, Scott and Pan, Youlian and Hill, Jennifer J.},
  year = {2021},
  month = dec,
  journal = {Scientific Reports},
  volume = {11},
  number = {1},
  pages = {8709},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-88209-4},
  urldate = {2022-08-04},
  langid = {english},
  file = {../../Bibliography/Fauteux_2021_Identification of transcriptional subtypes in lung adenocarcinoma and squamous.pdf}
}

@article{fay_2010_WeightedSpectralDistribution,
  title = {Weighted {{Spectral Distribution}} for {{Internet Topology Analysis}}: {{Theory}} and {{Applications}}},
  shorttitle = {Weighted {{Spectral Distribution}} for {{Internet Topology Analysis}}},
  author = {Fay, D. and Haddadi, H. and Thomason, A. and Moore, A.W. and Mortier, R. and Jamakovic, A. and Uhlig, S. and Rio, M.},
  year = {2010},
  month = feb,
  journal = {IEEE/ACM Transactions on Networking},
  volume = {18},
  number = {1},
  pages = {164--176},
  issn = {1063-6692, 1558-2566},
  doi = {10.1109/TNET.2009.2022369},
  urldate = {2022-08-28},
  file = {../../Bibliography/Fay_2010_Weighted Spectral Distribution for Internet Topology Analysis.pdf}
}

@inproceedings{feragen_2015_GeodesicExponentialKernels,
  title = {Geodesic Exponential Kernels: {{When}} Curvature and Linearity Conflict},
  shorttitle = {Geodesic Exponential Kernels},
  booktitle = {2015 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Feragen, Aasa and Lauze, Francois and Hauberg, Soren},
  year = {2015},
  month = jun,
  pages = {3032--3042},
  publisher = {IEEE},
  address = {Boston, MA, USA},
  doi = {10.1109/CVPR.2015.7298922},
  urldate = {2022-07-26},
  isbn = {978-1-4673-6964-0},
  file = {../../Bibliography/Feragen_2015_Geodesic exponential kernels.pdf}
}

@unpublished{figalli_2010_RegularityOptimalTransport,
  title = {Regularity of Optimal Transport Maps (after {{Ma-Trudinger-Wang}} and {{Loeper}})},
  author = {Figalli, Alessio},
  year = {2010},
  address = {Ast{\'e}risque},
  file = {../../Bibliography/figalli_2010_regularity of optimal transport maps (after ma-trudinger-wang and loeper).pdf}
}

@book{figalli_2021_InvitationOptimalTransport,
  title = {An Invitation to Optimal Transport, {{Wasserstein}} Distances, and Gradient Flows},
  author = {Figalli, Alessio and Glaudo, Federico},
  year = {2021},
  series = {{{EMS Textbooks}} in {{Mathematics}}},
  publisher = {EMS Press},
  address = {Berlin},
  doi = {10.4171/ETB/22},
  isbn = {978-3-9854701-0-5},
  langid = {english},
  file = {../../Bibliography/Figalli_2021_An invitation to optimal transport, Wasserstein distances, and gradient flows.pdf}
}

@article{finn_2015_FunctionalConnectomeFingerprinting,
  title = {Functional Connectome Fingerprinting: Identifying Individuals Using Patterns of Brain Connectivity},
  shorttitle = {Functional Connectome Fingerprinting},
  author = {Finn, Emily S and Shen, Xilin and Scheinost, Dustin and Rosenberg, Monica D and Huang, Jessica and Chun, Marvin M and Papademetris, Xenophon and Constable, R Todd},
  year = {2015},
  month = nov,
  journal = {Nature Neuroscience},
  volume = {18},
  number = {11},
  pages = {1664--1671},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4135},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Finn_2015_Functional connectome fingerprinting.pdf}
}

@article{fisher_1936_USEMULTIPLEMEASUREMENTS,
  title = {{{THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS}}},
  author = {Fisher, R. A.},
  year = {1936},
  month = sep,
  journal = {Annals of Eugenics},
  volume = {7},
  number = {2},
  pages = {179--188},
  issn = {20501420},
  doi = {10.1111/j.1469-1809.1936.tb02137.x},
  urldate = {2022-06-28},
  langid = {english}
}

@article{fisher_1953_DispersionSphere,
  title = {Dispersion on a {{Sphere}}},
  author = {Fisher, R.},
  year = {1953},
  month = may,
  journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {217},
  number = {1130},
  pages = {295--305},
  issn = {1364-5021, 1471-2946},
  doi = {10.1098/rspa.1953.0064},
  urldate = {2022-08-16},
  langid = {english},
  file = {../../Bibliography/Fisher_1953_Dispersion on a Sphere.pdf}
}

@article{fisher_2012_TestingIdentityCovariance,
  title = {On Testing for an Identity Covariance Matrix When the Dimensionality Equals or Exceeds the Sample Size},
  author = {Fisher, Thomas J.},
  year = {2012},
  month = jan,
  journal = {Journal of Statistical Planning and Inference},
  volume = {142},
  number = {1},
  pages = {312--326},
  issn = {03783758},
  doi = {10.1016/j.jspi.2011.07.019},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Fisher_2012_On testing for an identity covariance matrix when the dimensionality equals or.pdf}
}

@article{fitch_2019_EffectiveResistancePreserving,
  title = {Effective {{Resistance Preserving Directed Graph Symmetrization}}},
  author = {Fitch, Katherine},
  year = {2019},
  month = jan,
  journal = {SIAM Journal on Matrix Analysis and Applications},
  volume = {40},
  number = {1},
  pages = {49--65},
  issn = {0895-4798, 1095-7162},
  doi = {10.1137/18M1172892},
  urldate = {2021-12-02},
  langid = {english},
  file = {../../Bibliography/Fitch_2019_Effective Resistance Preserving Directed Graph Symmetrization.pdf}
}

@article{flamary_2018_WassersteinDiscriminantAnalysis,
  title = {Wasserstein Discriminant Analysis},
  author = {Flamary, R{\'e}mi and Cuturi, Marco and Courty, Nicolas and Rakotomamonjy, Alain},
  year = {2018},
  month = dec,
  journal = {Machine Learning},
  volume = {107},
  number = {12},
  pages = {1923--1945},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/s10994-018-5717-1},
  urldate = {2023-12-14},
  langid = {english},
  file = {../../Bibliography/Flamary_2018_Wasserstein discriminant analysis.pdf}
}

@article{fletcher_2004_PrincipalGeodesicAnalysis,
  title = {Principal {{Geodesic Analysis}} for the {{Study}} of {{Nonlinear Statistics}} of {{Shape}}},
  author = {Fletcher, P.T. and Lu, C. and Pizer, S.M. and Joshi, S.},
  year = {2004},
  month = aug,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {23},
  number = {8},
  pages = {995--1005},
  issn = {0278-0062},
  doi = {10.1109/TMI.2004.831793},
  urldate = {2021-10-03},
  langid = {english},
  file = {../../Bibliography/Fletcher_2004_Principal Geodesic Analysis for the Study of Nonlinear Statistics of Shape.pdf}
}

@article{fletcher_2009_GeometricMedianRiemannian,
  title = {The Geometric Median on {{Riemannian}} Manifolds with Application to Robust Atlas Estimation},
  author = {Fletcher, P. Thomas and Venkatasubramanian, Suresh and Joshi, Sarang},
  year = {2009},
  month = mar,
  journal = {NeuroImage},
  volume = {45},
  number = {1},
  pages = {S143-S152},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2008.10.052},
  urldate = {2021-10-02},
  langid = {english},
  file = {../../Bibliography/Fletcher_2009_The geometric median on Riemannian manifolds with application to robust atlas.pdf}
}

@article{foote_1984_RegularityDistanceFunction,
  title = {Regularity of the Distance Function},
  author = {Foote, Robert L},
  year = {1984},
  journal = {Proceedings of the American Mathematical Society},
  volume = {92},
  number = {1},
  pages = {153--155},
  file = {../../Bibliography/Foote_1984_Regularity of the distance function.pdf}
}

@article{fournier_2015_RateConvergenceWasserstein,
  title = {On the Rate of Convergence in {{Wasserstein}} Distance of the Empirical Measure},
  author = {Fournier, Nicolas and Guillin, Arnaud},
  year = {2015},
  month = aug,
  journal = {Probability Theory and Related Fields},
  volume = {162},
  number = {3-4},
  pages = {707--738},
  issn = {0178-8051, 1432-2064},
  doi = {10.1007/s00440-014-0583-7},
  urldate = {2022-09-07},
  langid = {english},
  file = {../../Bibliography/Fournier_2015_On the rate of convergence in Wasserstein distance of the empirical measure.pdf}
}

@article{frank_2016_MethodsTestEquality,
  title = {Methods to Test for Equality of Two Normal Distributions},
  author = {Frank, Julian and Klar, Bernhard},
  year = {2016},
  month = nov,
  journal = {Statistical Methods \& Applications},
  volume = {25},
  number = {4},
  pages = {581--599},
  issn = {1618-2510, 1613-981X},
  doi = {10.1007/s10260-016-0353-z},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Frank_2016_Methods to test for equality of two normal distributions.pdf}
}

@article{frechet_1948_ElementsAleatoiresNature,
  title = {{Les {\'e}l{\'e}ments al{\'e}atoires de nature quelconque dans un espace distanci{\'e}}},
  author = {Fr{\'e}chet, Maurice Ren{\'e}},
  year = {1948},
  journal = {Annales de l'institut Henri Poincar{\'e}},
  volume = {10},
  number = {4},
  pages = {215--310},
  publisher = {INSTITUT HENRI POINCAR{\'E} ET GAUTHIER-VILLARS},
  langid = {french},
  zmnumber = {0035.20802}
}

@inproceedings{freund_1999_ShortIntroductionBoosting,
  title = {A Short Introduction to Boosting},
  booktitle = {In Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence},
  author = {Freund, Yoav and Schapire, Robert E.},
  year = {1999},
  pages = {1401--1406},
  publisher = {Morgan Kaufmann},
  file = {../../Bibliography/Freund_1999_A short introduction to boosting.pdf}
}

@article{friesecke_2023_GenColAlgorithmHighDimensional,
  title = {The {{GenCol Algorithm}} for {{High-Dimensional Optimal Transport}}: {{General Formulation}} and {{Application}} to {{Barycenters}} and {{Wasserstein Splines}}},
  shorttitle = {The {{GenCol Algorithm}} for {{High-Dimensional Optimal Transport}}},
  author = {Friesecke, Gero and Penka, Maximilian},
  year = {2023},
  month = dec,
  journal = {SIAM Journal on Mathematics of Data Science},
  volume = {5},
  number = {4},
  pages = {899--919},
  issn = {2577-0187},
  doi = {10.1137/22M1524254},
  urldate = {2024-03-03},
  langid = {english},
  file = {../../Bibliography/Friesecke_2023_The GenCol Algorithm for High-Dimensional Optimal Transport.pdf}
}

@book{fukunaga_1990_IntroductionStatisticalPattern,
  title = {{Introduction to statistical pattern recognition}},
  author = {Fukunaga, Keinosuke},
  year = {1990},
  series = {{Computer science and scientific computing}},
  edition = {2. ed},
  publisher = {Acad. Press},
  address = {San Diego [u.a.]},
  isbn = {978-0-08-047865-4},
  langid = {und},
  lccn = {006.4}
}

@inproceedings{gao_2019_GeometricScatteringGraph,
  title = {Geometric Scattering for Graph Data Analysis},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  author = {Gao, Feng and Wolf, Guy and Hirn, Matthew},
  editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  year = {2019-06-09/2019-06-15},
  series = {Proceedings of Machine Learning Research},
  volume = {97},
  pages = {2122--2131},
  publisher = {PMLR},
  abstract = {We explore the generalization of scattering transforms from traditional (e.g., image or audio) signals to graph data, analogous to the generalization of ConvNets in geometric deep learning, and the utility of extracted graph features in graph data analysis. In particular, we focus on the capacity of these features to retain informative variability and relations in the data (e.g., between individual graphs, or in aggregate), while relating our construction to previous theoretical results that establish the stability of similar transforms to families of graph deformations. We demonstrate the application of our geometric scattering features in graph classification of social network data, and in data exploration of biochemistry data.},
  pdf = {http://proceedings.mlr.press/v97/gao19e/gao19e.pdf},
  file = {../../Bibliography/Gao_2019_Geometric scattering for graph data analysis.pdf}
}

@article{gao_2021_DiffusionGeometryFibre,
  title = {The Diffusion Geometry of Fibre Bundles: {{Horizontal}} Diffusion Maps},
  shorttitle = {The Diffusion Geometry of Fibre Bundles},
  author = {Gao, Tingran},
  year = {2021},
  month = jan,
  journal = {Applied and Computational Harmonic Analysis},
  volume = {50},
  pages = {147--215},
  issn = {10635203},
  doi = {10.1016/j.acha.2019.08.001},
  urldate = {2021-11-10},
  langid = {english}
}

@article{garreau_2018_ConsistentChangepointDetection,
  title = {Consistent Change-Point Detection with Kernels},
  author = {Garreau, Damien and Arlot, Sylvain},
  year = {2018},
  month = jan,
  journal = {Electronic Journal of Statistics},
  volume = {12},
  number = {2},
  issn = {1935-7524},
  doi = {10.1214/18-EJS1513},
  urldate = {2021-11-18},
  file = {../../Bibliography/Garreau_2018_Consistent change-point detection with kernels.pdf}
}

@article{geenens_2023_StatisticalDepthAbstract,
  title = {Statistical Depth in Abstract Metric Spaces},
  author = {Geenens, Gery and {Nieto-Reyes}, Alicia and Francisci, Giacomo},
  year = {2023},
  month = apr,
  journal = {Statistics and Computing},
  volume = {33},
  number = {2},
  pages = {46},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-023-10216-4},
  urldate = {2023-03-08},
  abstract = {Abstract             The concept of depth has proved very important for multivariate and functional data analysis, as it essentially acts as a surrogate for the notion of ranking of observations which is absent in more than one dimension. Motivated by the rapid development of technology, in particular the advent of `Big Data', we extend here that concept to general metric spaces, propose a natural depth measure and explore its properties as a statistical depth function. Working in a general metric space allows the depth to be tailored to the data at hand and to the ultimate goal of the analysis, a very desirable property given the polymorphic nature of modern data sets. This flexibility is thoroughly illustrated by several real data analyses.},
  langid = {english},
  file = {../../Bibliography/Geenens_2023_Statistical depth in abstract metric spaces.pdf}
}

@article{gelbrich_1990_FormulaL2Wasserstein,
  title = {On a {{Formula}} for the {{L2 Wasserstein Metric}} between {{Measures}} on {{Euclidean}} and {{Hilbert Spaces}}},
  author = {Gelbrich, Matthias},
  year = {1990},
  journal = {Mathematische Nachrichten},
  volume = {147},
  number = {1},
  pages = {185--203},
  issn = {0025584X},
  doi = {10.1002/mana.19901470121},
  urldate = {2021-11-09},
  langid = {english}
}

@book{gentle_2007_MatrixAlgebraTheory,
  title = {Matrix Algebra: Theory, Computations, and Applications in Statistics},
  shorttitle = {Matrix Algebra},
  author = {Gentle, James E.},
  year = {2007},
  series = {Springer Texts in Statistics},
  publisher = {Springer},
  address = {New York, N.Y. ; [London]},
  isbn = {978-0-387-70872-0},
  lccn = {QA188 .G56 2007},
  keywords = {Matrices,Problems exercises etc},
  annotation = {OCLC: ocn123374514}
}

@article{ghosh_2008_MinimizingEffectiveResistance,
  title = {Minimizing {{Effective Resistance}} of a {{Graph}}},
  author = {Ghosh, Arpita and Boyd, Stephen and Saberi, Amin},
  year = {2008},
  month = jan,
  journal = {SIAM Review},
  volume = {50},
  number = {1},
  pages = {37--66},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/050645452},
  urldate = {2024-08-30},
  langid = {english},
  file = {../../../../../Zotero/storage/Q4F647B9/Ghosh et al. - 2008 - Minimizing Effective Resistance of a Graph.pdf}
}

@article{gill_1983_ComputingForwardDifferenceIntervals,
  title = {Computing {{Forward-Difference Intervals}} for {{Numerical Optimization}}},
  author = {Gill, Philip E. and Murray, Walter and Saunders, Michael A. and Wright, Margaret H.},
  year = {1983},
  month = jun,
  journal = {SIAM Journal on Scientific and Statistical Computing},
  volume = {4},
  number = {2},
  pages = {310--321},
  issn = {0196-5204, 2168-3417},
  doi = {10.1137/0904025},
  urldate = {2022-02-08},
  langid = {english}
}

@incollection{gine_2006_EmpiricalGraphLaplacian,
  title = {Empirical Graph {{Laplacian}} Approximation of {{Laplace}}--{{Beltrami}} Operators: {{Large}} Sample Results},
  shorttitle = {Empirical Graph {{Laplacian}} Approximation of {{Laplace}}--{{Beltrami}} Operators},
  booktitle = {Institute of {{Mathematical Statistics Lecture Notes}} - {{Monograph Series}}},
  author = {Gin{\'e}, Evarist and Koltchinskii, Vladimir},
  year = {2006},
  pages = {238--259},
  publisher = {Institute of Mathematical Statistics},
  address = {Beachwood, Ohio, USA},
  doi = {10.1214/074921706000000888},
  urldate = {2022-08-28},
  isbn = {978-0-940600-67-6},
  langid = {english}
}

@misc{ginestet_2013_StrongConsistencyFrechet,
  title = {Strong {{Consistency}} of {{Frechet Sample Mean Sets}} for {{Graph-Valued Random Variables}}},
  author = {Ginestet, Cedric E.},
  year = {2013},
  month = may,
  number = {arXiv:1204.3183},
  eprint = {1204.3183},
  primaryclass = {math, q-bio, stat},
  publisher = {arXiv},
  urldate = {2022-07-25},
  abstract = {The Frechet mean or barycenter generalizes the idea of averaging in spaces where pairwise addition is not well-defined. In general metric spaces, the Frechet sample mean is not a consistent estimator of the theoretical Frechet mean. For graph-valued random variables, for instance, the Frechet sample mean may fail to converge to a unique value. Hence, it becomes necessary to consider the convergence of sequences of sets of graphs. We show that a specific type of almost sure convergence for the Frechet sample mean previously introduced by Ziezold (1977) is, in fact, equivalent to the Kuratowski outer limit of a sequence of Frechet sample means. Equipped with this outer limit, we provide a new proof of the strong consistency of the Frechet sample mean for graph-valued random variables in separable (pseudo-)metric space. Our proof strategy exploits the fact that the metric of interest is bounded, since we are considering graphs over a finite number of vertices. In this setting, we describe two strong laws of large numbers for both the restricted and unrestricted Frechet sample means of all orders, thereby generalizing a previous result, due to Sverdrup-Thygeson (1981).},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Statistics Theory,Quantitative Biology - Quantitative Methods,Statistics - Methodology},
  file = {../../Bibliography/Ginestet_2013_Strong Consistency of Frechet Sample Mean Sets for Graph-Valued Random Variables.pdf}
}

@article{ginestet_2017_HypothesisTestingNetwork,
  title = {Hypothesis Testing for Network Data in Functional Neuroimaging},
  author = {Ginestet, Cedric E. and Li, Jun and Balachandran, Prakash and Rosenberg, Steven and Kolaczyk, Eric D.},
  year = {2017},
  month = jun,
  journal = {The Annals of Applied Statistics},
  volume = {11},
  number = {2},
  issn = {1932-6157},
  doi = {10.1214/16-AOAS1015},
  urldate = {2021-10-04},
  file = {../../Bibliography/Ginestet_2017_Hypothesis testing for network data in functional neuroimaging.pdf}
}

@article{giuffre_2024_EvaluatingChatGPTMedical,
  title = {Evaluating {{ChatGPT}} in {{Medical Contexts}}: {{The Imperative}} to {{Guard Against Hallucinations}} and {{Partial Accuracies}}},
  shorttitle = {Evaluating {{ChatGPT}} in {{Medical Contexts}}},
  author = {Giuffr{\`e}, Mauro and You, Kisung and Shung, Dennis L.},
  year = {2024},
  month = may,
  journal = {Clinical Gastroenterology and Hepatology},
  volume = {22},
  number = {5},
  pages = {1145--1146},
  issn = {15423565},
  doi = {10.1016/j.cgh.2023.09.035},
  urldate = {2024-05-06},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/giuffrè_2024_evaluating chatgpt in medical contexts.pdf}
}

@article{giuffre_2024_OptimizingLargeLanguage,
  title = {Optimizing Large Language Models in Digestive Disease: Strategies and Challenges to Improve Clinical Outcomes},
  shorttitle = {Optimizing Large Language Models in Digestive Disease},
  author = {Giuffr{\`e}, Mauro and Kresevic, Simone and Pugliese, Nicola and You, Kisung and Shung, Dennis L.},
  year = {2024},
  month = may,
  journal = {Liver International},
  pages = {liv.15974},
  issn = {1478-3223, 1478-3231},
  doi = {10.1111/liv.15974},
  urldate = {2024-06-03},
  abstract = {Abstract             Large Language Models (LLMs) are transformer-based neural networks with billions of parameters trained on very large text corpora from diverse sources. LLMs have the potential to improve healthcare due to their capability to parse complex concepts and generate context-based responses. The interest in LLMs has not spared digestive disease academics, who have mainly investigated foundational LLM accuracy, which ranges from 25\% to 90\% and is influenced by the lack of standardized rules to report methodologies and results for LLM-oriented research. In addition, a critical issue is the absence of a universally accepted definition of accuracy, varying from binary to scalar interpretations, often tied to grader expertise without reference to clinical guidelines. We address strategies and challenges to increase accuracy. In particular, LLMs can be infused with domain knowledge using Retrieval Augmented Generation (RAG) or Supervised Fine-Tuning (SFT) with reinforcement learning from human feedback (RLHF). RAG faces challenges with in-context window limits and accurate information retrieval from the provided context. SFT, a deeper adaptation method, is computationally demanding and requires specialized knowledge. LLMs may increase patient quality of care across the field of digestive diseases,~where physicians are often engaged in screening, treatment and surveillance for a broad range of pathologies for which in-context learning or SFT with RLHF could improve clinical decision-making and patient outcomes. However, despite their potential, the safe deployment of LLMs in healthcare still needs to overcome hurdles in accuracy, suggesting a need for strategies that integrate human feedback with advanced model training.},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/giuffrè_2024_optimizing large language models in digestive disease.pdf}
}

@article{giuffre_2024_PredictingResponseNonselective,
  title = {Predicting Response to Non-Selective Beta-Blockers with Liver--Spleen Stiffness and Heart Rate in Patients with Liver Cirrhosis and High-Risk Varices},
  author = {Giuffr{\`e}, Mauro and Dupont, Johannes and Visintin, Alessia and Masutti, Flora and Monica, Fabio and You, Kisung and Shung, Dennis L. and Croc{\`e}, Lory Saveria and {The NSBB-Elasto-Response-Prediction Group} and Abazia, Cristiana and Faini, Clara and Campigotto, Michele and Dottor, Francesca and Gulotta, Marco and Albergati, Irma Valeria and Shung, Dennis L.},
  year = {2024},
  month = apr,
  journal = {Hepatology International},
  issn = {1936-0533, 1936-0541},
  doi = {10.1007/s12072-024-10649-7},
  urldate = {2024-05-08},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/Giuffrè_2024_Predicting response to non-selective beta-blockers with liver–spleen stiffness.pdf}
}

@article{giuffre_2024_SystematicReviewUse,
  title = {Systematic Review: {{The}} Use of Large Language Models as Medical Chatbots in Digestive Diseases},
  shorttitle = {Systematic Review},
  author = {Giuffr{\`e}, Mauro and Kresevic, Simone and You, Kisung and Dupont, Johannes and Huebner, Jack and Grimshaw, Alyssa Ann and Shung, Dennis Legen},
  year = {2024},
  month = jul,
  journal = {Alimentary Pharmacology \& Therapeutics},
  volume = {60},
  number = {2},
  pages = {144--166},
  issn = {0269-2813, 1365-2036},
  doi = {10.1111/apt.18058},
  urldate = {2024-06-27},
  abstract = {Summary                            Background               Interest in large language models (LLMs), such as OpenAI's ChatGPT, across multiple specialties has grown as a source of patient-facing medical advice and provider-facing clinical decision support. The accuracy of LLM responses for gastroenterology and hepatology-related questions is unknown.                                         Aims               To evaluate the accuracy and potential safety implications for LLMs for the diagnosis, management and treatment of questions related to gastroenterology and hepatology.                                         Methods               We conducted a systematic literature search including Cochrane Library, Google Scholar, Ovid Embase, Ovid MEDLINE, PubMed, Scopus and the Web of Science Core Collection to identify relevant articles published from inception until January 28, 2024, using a combination of keywords and controlled vocabulary for LLMs and gastroenterology or hepatology. Accuracy was defined as the percentage of entirely correct answers.                                         Results               Among the 1671 reports screened, we identified 33 full-text articles on using LLMs in gastroenterology and hepatology and included 18 in the final analysis. The accuracy of question-responding varied across different model versions. For example, accuracy ranged from 6.4\% to 45.5\% with ChatGPT-3.5 and was between 40\% and 91.4\% with ChatGPT-4. In addition, the absence of standardised methodology and reporting metrics for studies involving LLMs places all the studies at a high risk of bias and does not allow for the generalisation of single-study results.                                         Conclusions               Current general-purpose LLMs have unacceptably low accuracy on clinical gastroenterology and hepatology tasks, which may lead to adverse patient safety events through incorrect information or triage recommendations, which might overburden healthcare systems or delay necessary care.},
  copyright = {All rights reserved},
  langid = {english}
}

@article{givens_1984_ClassWassersteinMetrics,
  title = {A Class of {{Wasserstein}} Metrics for Probability Distributions.},
  author = {Givens, Clark R. and Shortt, Rae Michael},
  year = {1984},
  month = jan,
  journal = {Michigan Mathematical Journal},
  volume = {31},
  number = {2},
  issn = {0026-2285},
  doi = {10.1307/mmj/1029003026},
  urldate = {2021-11-09},
  file = {../../Bibliography/Givens_1984_A class of Wasserstein metrics for probability distributions.pdf}
}

@article{glasser_2013_MinimalPreprocessingPipelines,
  title = {The Minimal Preprocessing Pipelines for the {{Human Connectome Project}}},
  author = {Glasser, Matthew F. and Sotiropoulos, Stamatios N. and Wilson, J. Anthony and Coalson, Timothy S. and Fischl, Bruce and Andersson, Jesper L. and Xu, Junqian and Jbabdi, Saad and Webster, Matthew and Polimeni, Jonathan R. and Van Essen, David C. and Jenkinson, Mark},
  year = {2013},
  month = oct,
  journal = {NeuroImage},
  volume = {80},
  pages = {105--124},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2013.04.127},
  urldate = {2024-08-01},
  langid = {english},
  file = {../../Bibliography/Glasser_2013_The minimal preprocessing pipelines for the Human Connectome Project.pdf}
}

@article{glynn_2010_IntroductionAugmentedInverse,
  title = {An {{Introduction}} to the {{Augmented Inverse Propensity Weighted Estimator}}},
  author = {Glynn, Adam N. and Quinn, Kevin M.},
  year = {2010},
  journal = {Political Analysis},
  volume = {18},
  number = {1},
  pages = {36--56},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mpp036},
  urldate = {2023-12-20},
  abstract = {In this paper, we discuss an estimator for average treatment effects (ATEs) known as the augmented inverse propensity weighted (AIPW) estimator. This estimator has attractive theoretical properties and only requires practitioners to do two things they are already comfortable with: (1) specify a binary regression model for the propensity score, and (2) specify a regression model for the outcome variable. Perhaps the most interesting property of this estimator is its so-called ``double robustness.'' Put simply, the estimator remains consistent for the ATE if either the propensity score model or the outcome regression is misspecified but the other is properly specified. After explaining the AIPW estimator, we conduct a Monte Carlo experiment that compares the finite sample performance of the AIPW estimator to three common competitors: a regression estimator, an inverse propensity weighted (IPW) estimator, and a propensity score matching estimator. The Monte Carlo results show that the AIPW estimator has comparable or lower mean square error than the competing estimators when the propensity score and outcome models are both properly specified and, when one of the models is misspecified, the AIPW estimator is superior.},
  langid = {english},
  file = {../../Bibliography/Glynn_2010_An Introduction to the Augmented Inverse Propensity Weighted Estimator.pdf}
}

@article{goldberger_2000_PhysioBankPhysioToolkitPhysioNet,
  title = {{{PhysioBank}}, {{PhysioToolkit}}, and {{PhysioNet}}: {{Components}} of a {{New Research Resource}} for {{Complex Physiologic Signals}}},
  shorttitle = {{{PhysioBank}}, {{PhysioToolkit}}, and {{PhysioNet}}},
  author = {Goldberger, Ary L. and Amaral, Luis A. N. and Glass, Leon and Hausdorff, Jeffrey M. and Ivanov, Plamen Ch. and Mark, Roger G. and Mietus, Joseph E. and Moody, George B. and Peng, Chung-Kang and Stanley, H. Eugene},
  year = {2000},
  month = jun,
  journal = {Circulation},
  volume = {101},
  number = {23},
  issn = {0009-7322, 1524-4539},
  doi = {10.1161/01.CIR.101.23.e215},
  urldate = {2022-09-11},
  langid = {english}
}

@inproceedings{goldberger_2004_HierarchicalClusteringMixture,
  title = {Hierarchical Clustering of a Mixture Model},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Goldberger, Jacob and Roweis, Sam},
  editor = {Saul, L. and Weiss, Y. and Bottou, L.},
  year = {2004},
  volume = {17},
  publisher = {MIT Press},
  file = {../../Bibliography/goldberger_2004_hierarchical clustering of a mixture model.pdf}
}

@inproceedings{gopal_2014_MisesfisherClusteringModels,
  title = {Von Mises-Fisher Clustering Models},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning},
  author = {Gopal, Siddharth and Yang, Yiming},
  editor = {Xing, Eric P. and Jebara, Tony},
  series = {Proceedings of Machine Learning Research},
  volume = {32},
  pages = {154--162},
  publisher = {PMLR},
  address = {Bejing, China},
  pdf = {http://proceedings.mlr.press/v32/gopal14.pdf},
  file = {../../Bibliography/Gopal_2014_Von mises-fisher clustering models.pdf}
}

@article{gorodnitsky_1997_SparseSignalReconstruction,
  title = {Sparse Signal Reconstruction from Limited Data Using {{FOCUSS}}: A Re-Weighted Minimum Norm Algorithm},
  shorttitle = {Sparse Signal Reconstruction from Limited Data Using {{FOCUSS}}},
  author = {Gorodnitsky, I.F. and Rao, B.D.},
  year = {1997},
  month = mar,
  journal = {IEEE Transactions on Signal Processing},
  volume = {45},
  number = {3},
  pages = {600--616},
  issn = {1053587X},
  doi = {10.1109/78.558475},
  urldate = {2022-09-07},
  file = {../../Bibliography/Gorodnitsky_1997_Sparse signal reconstruction from limited data using FOCUSS.pdf}
}

@article{gralnek_2021_EndoscopicDiagnosisManagement,
  title = {Endoscopic Diagnosis and Management of Nonvariceal Upper Gastrointestinal Hemorrhage ({{NVUGIH}}): {{European Society}} of {{Gastrointestinal Endoscopy}} ({{ESGE}}) {{Guideline}} -- {{Update}} 2021},
  shorttitle = {Endoscopic Diagnosis and Management of Nonvariceal Upper Gastrointestinal Hemorrhage ({{NVUGIH}})},
  author = {Gralnek, Ian M. and Stanley, Adrian J. and Morris, A. John and Camus, Marine and Lau, James and Lanas, Angel and Laursen, Stig B. and Radaelli, Franco and Papanikolaou, Ioannis S. and C{\'u}rdia Gon{\c c}alves, Tiago and {Dinis-Ribeiro}, Mario and Awadie, Halim and Braun, Georg and De Groot, Nicolette and Udd, Marianne and {Sanchez-Yague}, Andres and Neeman, Ziv and Van Hooft, Jeanin E.},
  year = {2021},
  month = mar,
  journal = {Endoscopy},
  volume = {53},
  number = {03},
  pages = {300--332},
  issn = {0013-726X, 1438-8812},
  doi = {10.1055/a-1369-5274},
  urldate = {2024-06-30},
  abstract = {MAIN RECOMMENDATIONS             1 ESGE recommends in patients with acute upper gastrointestinal hemorrhage (UGIH) the use of the Glasgow--Blatchford Score (GBS) for pre-endoscopy risk stratification. Patients with GBS{$\mkern1mu\leq\mkern1mu$}1 are at very low risk of rebleeding, mortality within 30 days, or needing hospital-based intervention and can be safely managed as outpatients with outpatient endoscopy.             Strong recommendation, moderate quality evidence.             2 ESGE recommends that in patients with acute UGIH who are taking low-dose aspirin as monotherapy for secondary cardiovascular prophylaxis, aspirin should not be interrupted. If for any reason it is interrupted, aspirin should be re-started as soon as possible, preferably within 3--5 days.             Strong recommendation, moderate quality evidence.             3 ESGE recommends that following hemodynamic resuscitation, early ({$\leq\mkern1mu$}24 hours) upper gastrointestinal (GI) endoscopy should be performed.             Strong recommendation, high quality evidence.             4 ESGE does not recommend urgent ({$\leq\mkern1mu$}12 hours) upper GI endoscopy since as compared to early endoscopy, patient outcomes are not improved.             Strong recommendation, high quality evidence.             5 ESGE recommends for patients with actively bleeding ulcers (FIa, FIb), combination therapy using epinephrine injection plus a second hemostasis modality (contact thermal or mechanical therapy).             Strong recommendation, high quality evidence.             6 ESGE recommends for patients with an ulcer with a nonbleeding visible vessel (FIIa), contact or noncontact thermal therapy, mechanical therapy, or injection of a sclerosing agent, each as monotherapy or in combination with epinephrine injection.             Strong recommendation, high quality evidence.             7 ESGE suggests that in patients with persistent bleeding refractory to standard hemostasis modalities, the use of a topical hemostatic spray/powder or cap-mounted clip should be considered.             Weak recommendation, low quality evidence.             8 ESGE recommends that for patients with clinical evidence of recurrent peptic ulcer hemorrhage, use of a cap-mounted clip should be considered. In the case of failure of this second attempt at endoscopic hemostasis, transcatheter angiographic embolization (TAE) should be considered. Surgery is indicated when TAE is not locally available or after failed TAE.             Strong recommendation, moderate quality evidence.             9 ESGE recommends high dose proton pump inhibitor (PPI) therapy for patients who receive endoscopic hemostasis and for patients with FIIb ulcer stigmata (adherent clot) not treated endoscopically.             (a) PPI therapy should be administered as an intravenous bolus followed by continuous infusion (e.{$\mkern1mu$}g., 80{$\mkern1mu$}mg then 8{$\mkern1mu$}mg/hour) for 72 hours post endoscopy.             (b) High dose PPI therapies given as intravenous bolus dosing (twice-daily) or in oral formulation (twice-daily) can be considered as alternative regimens.             Strong recommendation, high quality evidence.             10 ESGE recommends that in patients who require ongoing anticoagulation therapy following acute NVUGIH (e.{$\mkern1mu$}g., peptic ulcer hemorrhage), anticoagulation should be resumed as soon as the bleeding has been controlled, preferably within or soon after 7 days of the bleeding event, based on thromboembolic risk. The rapid onset of action of direct oral anticoagulants (DOACS), as compared to vitamin K antagonists (VKAs), must be considered in this context.             Strong recommendation, low quality evidence.},
  langid = {english},
  file = {../../Bibliography/Gralnek_2021_Endoscopic diagnosis and management of nonvariceal upper gastrointestinal.pdf}
}

@article{greenacre_2021_CompositionalDataAnalysis,
  title = {Compositional {{Data Analysis}}},
  author = {Greenacre, Michael},
  year = {2021},
  month = mar,
  journal = {Annual Review of Statistics and Its Application},
  volume = {8},
  number = {1},
  pages = {271--299},
  issn = {2326-8298, 2326-831X},
  doi = {10.1146/annurev-statistics-042720-124436},
  urldate = {2022-10-12},
  langid = {english},
  file = {../../Bibliography/Greenacre_2021_Compositional Data Analysis.pdf}
}

@article{grenander_1994_RepresentationsKnowledgeComplex,
  title = {Representations of {{Knowledge}} in {{Complex Systems}}},
  author = {Grenander, Ulf and Miller, Michael I.},
  year = {1994},
  month = nov,
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {56},
  number = {4},
  pages = {549--581},
  issn = {0035-9246, 2517-6161},
  doi = {10.1111/j.2517-6161.1994.tb02000.x},
  urldate = {2023-12-28},
  abstract = {SUMMARY             Modern sensor technologies, especially in biomedicine, produce increasingly detailed and informative image ensembles, many extremely complex. It will be argued that pattern theory can supply mathematical representations of subject-matter knowledge that can be used as a basis for algorithmic `understanding' of such pictures. After a brief survey of the basic principles of pattern theory we shall illustrate them by an application to a concrete situation: high magnification (greater than 15000{\texttimes}) electron micrographs of cardiac muscle cells. The aim is to build algorithms for automatic hypothesis formation concerning the number, location, orientation and shape of mitochondria and membranes. For this we construct a pattern theoretic model in the form of a prior probability measure on the space of configurations describing these hypotheses. This measure is synthesized by solving sequentially a jump--diffusion equation of generalized Langevin form. The jumps occur for the creation--annihilation of hypotheses, corresponding to a jump from one continuum to another in configuration (hypothesis) space. These continua (subhypotheses) are expressed in terms of products of low dimensional Lie groups acting on the generators of a template. We use a modified Bayes approach to obtain the hypothesis formation, also organized by solving a generalized Langevin equation. to justify this it is shown that the resulting jump-diffusion process is ergodic so that the solution converges to the desired probability measure. to speed up the convergence we reduce the computation of the drift term in the stochastic differential equation analytically to a curvilinear integral, with the random term computed almost instantaneously. The algorithms thus obtained are implemented, both for mitochondria and membranes, on a 4000 processor parallel machine. Photographs of the graphics illustrate how automatic hypothesis formation is achieved. This approach is applied to deformable neuroanatomical atlases and tracking recognition from narrow band and high resolution sensor arrays.},
  langid = {english},
  file = {../../Bibliography/Grenander_1994_Representations of Knowledge in Complex Systems.pdf}
}

@incollection{gretton_2005_MeasuringStatisticalDependence,
  title = {Measuring {{Statistical Dependence}} with {{Hilbert-Schmidt Norms}}},
  booktitle = {Algorithmic {{Learning Theory}}},
  author = {Gretton, Arthur and Bousquet, Olivier and Smola, Alex and Sch{\"o}lkopf, Bernhard},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Jain, Sanjay and Simon, Hans Ulrich and Tomita, Etsuji},
  year = {2005},
  volume = {3734},
  pages = {63--77},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11564089_7},
  urldate = {2022-12-09},
  isbn = {978-3-540-29242-5 978-3-540-31696-1}
}

@inproceedings{gretton_2006_KernelMethodTwosampleproblem,
  title = {A Kernel Method for the Two-Sample-Problem},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Gretton, Arthur and Borgwardt, Karsten and Rasch, Malte and Sch{\"o}lkopf, Bernhard and Smola, Alex},
  editor = {Sch{\"o}lkopf, B. and Platt, J. and Hoffman, T.},
  year = {2006},
  volume = {19},
  publisher = {MIT Press},
  file = {../../Bibliography/Gretton_2006_A kernel method for the two-sample-problem.pdf}
}

@article{griffanti_2014_ICAbasedArtefactRemoval,
  title = {{{ICA-based}} Artefact Removal and Accelerated {{fMRI}} Acquisition for Improved Resting State Network Imaging},
  author = {Griffanti, Ludovica and {Salimi-Khorshidi}, Gholamreza and Beckmann, Christian F. and Auerbach, Edward J. and Douaud, Gwena{\"e}lle and Sexton, Claire E. and Zsoldos, Enik{\H o} and Ebmeier, Klaus P. and Filippini, Nicola and Mackay, Clare E. and Moeller, Steen and Xu, Junqian and Yacoub, Essa and Baselli, Giuseppe and Ugurbil, Kamil and Miller, Karla L. and Smith, Stephen M.},
  year = {2014},
  month = jul,
  journal = {NeuroImage},
  volume = {95},
  pages = {232--247},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2014.03.034},
  urldate = {2024-08-01},
  langid = {english},
  file = {../../Bibliography/Griffanti_2014_ICA-based artefact removal and accelerated fMRI acquisition for improved.pdf}
}

@article{groman_2022_ReinforcementLearningDetuned,
  title = {Reinforcement Learning Detuned in Addiction: Integrative and Translational Approaches},
  shorttitle = {Reinforcement Learning Detuned in Addiction},
  author = {Groman, Stephanie M. and Thompson, Summer L. and Lee, Daeyeol and Taylor, Jane R.},
  year = {2022},
  month = feb,
  journal = {Trends in Neurosciences},
  volume = {45},
  number = {2},
  pages = {96--105},
  issn = {01662236},
  doi = {10.1016/j.tins.2021.11.007},
  urldate = {2023-12-28},
  langid = {english},
  file = {../../Bibliography/Groman_2022_Reinforcement learning detuned in addiction.pdf}
}

@incollection{gromov_1987_HyperbolicGroups,
  title = {Hyperbolic {{Groups}}},
  booktitle = {Essays in {{Group Theory}}},
  author = {Gromov, M.},
  editor = {Chern, S. S. and Kaplansky, I. and Moore, C. C. and Singer, I. M. and Gersten, S. M.},
  year = {1987},
  volume = {8},
  pages = {75--263},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4613-9586-7_3},
  urldate = {2023-12-20},
  isbn = {978-1-4613-9588-1 978-1-4613-9586-7},
  file = {../../Bibliography/Gromov_1987_Hyperbolic Groups.pdf}
}

@article{grove_1973_HowConjugateC1close,
  title = {How to Conjugate {{C1-close}} Group Actions},
  author = {Grove, Karsten and Karcher, Hermann},
  year = {1973},
  month = mar,
  journal = {Mathematische Zeitschrift},
  volume = {132},
  number = {1},
  pages = {11--20},
  issn = {0025-5874, 1432-1823},
  doi = {10.1007/BF01214029},
  urldate = {2021-09-29},
  langid = {english}
}

@article{grubisic_2007_EfficientRankReduction,
  title = {Efficient Rank Reduction of Correlation Matrices},
  author = {Grubi{\v s}i{\'c}, Igor and Pietersz, Raoul},
  year = {2007},
  month = apr,
  journal = {Linear Algebra and its Applications},
  volume = {422},
  number = {2-3},
  pages = {629--653},
  issn = {00243795},
  doi = {10.1016/j.laa.2006.11.024},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Grubišić_2007_Efficient rank reduction of correlation matrices.pdf}
}

@inproceedings{gu_2009_ImprovedSpectralClustering,
  title = {An {{Improved Spectral Clustering Algorithm Based}} on {{Neighbour Adaptive Scale}}},
  booktitle = {2009 {{International Conference}} on {{Business Intelligence}} and {{Financial Engineering}}},
  author = {Gu, Ruijun and Wang, Jiacai},
  year = {2009},
  month = jul,
  pages = {233--236},
  publisher = {IEEE},
  address = {Beijing, China},
  doi = {10.1109/BIFE.2009.62},
  urldate = {2022-07-25},
  isbn = {978-0-7695-3705-4},
  file = {../../Bibliography/Gu_2009_An Improved Spectral Clustering Algorithm Based on Neighbour Adaptive Scale.pdf}
}

@article{guo_2016_EfficientSVDBasedMethod,
  title = {An {{Efficient SVD-Based Method}} for {{Image Denoising}}},
  author = {Guo, Qiang and Zhang, Caiming and Zhang, Yunfeng and Liu, Hui},
  year = {2016},
  month = may,
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  volume = {26},
  number = {5},
  pages = {868--880},
  issn = {1051-8215, 1558-2205},
  doi = {10.1109/TCSVT.2015.2416631},
  urldate = {2022-07-25},
  file = {../../Bibliography/Guo_2016_An Efficient SVD-Based Method for Image Denoising.pdf}
}

@article{gutierrez-gomez_2019_UnsupervisedNetworkEmbeddings,
  title = {Unsupervised Network Embeddings with Node Identity Awareness},
  author = {{Guti{\'e}rrez-G{\'o}mez}, Leonardo and Delvenne, Jean-Charles},
  year = {2019},
  month = dec,
  journal = {Applied Network Science},
  volume = {4},
  number = {1},
  pages = {82},
  issn = {2364-8228},
  doi = {10.1007/s41109-019-0197-1},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Gutiérrez-Gómez_2019_Unsupervised network embeddings with node identity awareness.pdf}
}

@article{haff_1980_EmpiricalBayesEstimation,
  title = {Empirical {{Bayes Estimation}} of the {{Multivariate Normal Covariance Matrix}}},
  author = {Haff, L. R.},
  year = {1980},
  month = may,
  journal = {The Annals of Statistics},
  volume = {8},
  number = {3},
  issn = {0090-5364},
  doi = {10.1214/aos/1176345010},
  urldate = {2022-07-25},
  file = {../../Bibliography/Haff_1980_Empirical Bayes Estimation of the Multivariate Normal Covariance Matrix.pdf}
}

@article{haghverdi_2018_BatchEffectsSinglecell,
  title = {Batch Effects in Single-Cell {{RNA-sequencing}} Data Are Corrected by Matching Mutual Nearest Neighbors},
  author = {Haghverdi, Laleh and Lun, Aaron T L and Morgan, Michael D and Marioni, John C},
  year = {2018},
  month = may,
  journal = {Nature Biotechnology},
  volume = {36},
  number = {5},
  pages = {421--427},
  issn = {1087-0156, 1546-1696},
  doi = {10.1038/nbt.4091},
  urldate = {2022-06-20},
  langid = {english},
  file = {../../Bibliography/Haghverdi_2018_Batch effects in single-cell RNA-sequencing data are corrected by matching.pdf}
}

@book{hairer_2006_GeometricNumericalIntegration,
  title = {Geometric {{Numerical Integration}}},
  author = {Hairer, Ernst and Wanner, Gerhard and Lubich, Christian},
  year = {2006},
  series = {Springer {{Series}} in {{Computational Mathematics}}},
  volume = {31},
  publisher = {Springer-Verlag},
  address = {Berlin/Heidelberg},
  doi = {10.1007/3-540-30666-8},
  urldate = {2021-11-26},
  isbn = {978-3-540-30663-4},
  langid = {english}
}

@book{hall_2015_LieGroupsLie,
  title = {Lie Groups, {{Lie}} Algebras, and Representations: An Elementary Introduction},
  shorttitle = {Lie Groups, {{Lie}} Algebras, and Representations},
  author = {Hall, Brian C.},
  year = {2015},
  series = {Graduate Texts in Mathematics},
  edition = {Second edition},
  number = {222},
  publisher = {Springer},
  address = {Cham ; New York},
  isbn = {978-3-319-13466-6},
  lccn = {QA387 .H34 2015},
  keywords = {Lie algebras,Lie groups,Representations of Lie algebras,Representations of Lie groups},
  annotation = {OCLC: ocn910324548}
}

@article{hamming_1950_ErrorDetectingError,
  title = {Error {{Detecting}} and {{Error Correcting Codes}}},
  author = {Hamming, R. W.},
  year = {1950},
  month = apr,
  journal = {Bell System Technical Journal},
  volume = {29},
  number = {2},
  pages = {147--160},
  issn = {00058580},
  doi = {10.1002/j.1538-7305.1950.tb00463.x},
  urldate = {2022-08-28},
  langid = {english},
  file = {../../Bibliography/Hamming_1950_Error Detecting and Error Correcting Codes.pdf}
}

@inproceedings{hammond_2013_GraphDiffusionDistance,
  title = {Graph Diffusion Distance: {{A}} Difference Measure for Weighted Graphs Based on the Graph {{Laplacian}} Exponential Kernel},
  shorttitle = {Graph Diffusion Distance},
  booktitle = {2013 {{IEEE Global Conference}} on {{Signal}} and {{Information Processing}}},
  author = {Hammond, David K. and Gur, Yaniv and Johnson, Chris R.},
  year = {2013},
  month = dec,
  pages = {419--422},
  publisher = {IEEE},
  address = {Austin, TX, USA},
  doi = {10.1109/GlobalSIP.2013.6736904},
  urldate = {2022-08-28},
  isbn = {978-1-4799-0248-4},
  file = {../../Bibliography/Hammond_2013_Graph diffusion distance.pdf}
}

@article{hampel_1971_GeneralQualitativeDefinition,
  title = {A {{General Qualitative Definition}} of {{Robustness}}},
  author = {Hampel, Frank R.},
  year = {1971},
  month = dec,
  journal = {The Annals of Mathematical Statistics},
  volume = {42},
  number = {6},
  pages = {1887--1896},
  issn = {0003-4851},
  doi = {10.1214/aoms/1177693054},
  urldate = {2024-02-17},
  langid = {english},
  file = {../../Bibliography/Hampel_1971_A General Qualitative Definition of Robustness.pdf}
}

@article{harandi_2014_ManifoldManifoldGeometryAware,
  title = {From {{Manifold}} to {{Manifold}}: {{Geometry-Aware Dimensionality Reduction}} for {{SPD Matrices}}},
  shorttitle = {From {{Manifold}} to {{Manifold}}},
  author = {Harandi, Mehrtash T. and Salzmann, Mathieu and Hartley, Richard},
  year = {2014},
  month = nov,
  journal = {arXiv:1407.1120 [cs]},
  eprint = {1407.1120},
  primaryclass = {cs},
  urldate = {2022-03-24},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {../../Bibliography/Harandi_2014_From Manifold to Manifold.pdf}
}

@article{harandi_2018_DimensionalityReductionSPD,
  title = {Dimensionality {{Reduction}} on {{SPD Manifolds}}: {{The Emergence}} of {{Geometry-Aware Methods}}},
  shorttitle = {Dimensionality {{Reduction}} on {{SPD Manifolds}}},
  author = {Harandi, Mehrtash and Salzmann, Mathieu and Hartley, Richard},
  year = {2018},
  month = jan,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {40},
  number = {1},
  pages = {48--62},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2017.2655048},
  urldate = {2022-03-25},
  file = {../../Bibliography/Harandi_2018_Dimensionality Reduction on SPD Manifolds.pdf}
}

@inproceedings{harchaoui_2008_KernelChangepointAnalysis,
  title = {Kernel Change-Point Analysis},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Harchaoui, Za{\"i}d and Moulines, Eric and Bach, Francis},
  editor = {Koller, D. and Schuurmans, D. and Bengio, Y. and Bottou, L.},
  year = {2008},
  volume = {21},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Harchaoui_2008_Kernel change-point analysis.pdf}
}

@book{hastie_2015_StatisticalLearningSparsity,
  title = {Statistical Learning with Sparsity: The Lasso and Generalizations},
  shorttitle = {Statistical Learning with Sparsity},
  author = {Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
  year = {2015},
  series = {Monographs on Statistics and Applied Probability},
  number = {143},
  publisher = {CRC Press, Taylor \& Francis Group},
  address = {Boca Raton},
  isbn = {978-1-4987-1216-3},
  lccn = {QA275 .H38 2015},
  keywords = {Least squares,Linear models (Statistics),Mathematical statistics,Proof theory}
}

@article{hastings_1970_MonteCarloSampling,
  title = {Monte {{Carlo}} Sampling Methods Using {{Markov}} Chains and Their Applications},
  author = {Hastings, W. K.},
  year = {1970},
  month = apr,
  journal = {Biometrika},
  volume = {57},
  number = {1},
  pages = {97--109},
  issn = {1464-3510, 0006-3444},
  doi = {10.1093/biomet/57.1.97},
  urldate = {2022-08-19},
  langid = {english},
  file = {../../Bibliography/Hastings_1970_Monte Carlo sampling methods using Markov chains and their applications.pdf}
}

@inproceedings{hauberg_2018_DirectionalStatisticsSpherical,
  title = {Directional {{Statistics}} with the {{Spherical Normal Distribution}}},
  booktitle = {2018 21st {{International Conference}} on {{Information Fusion}} ({{FUSION}})},
  author = {Hauberg, Soren},
  year = {2018},
  month = jul,
  pages = {704--711},
  publisher = {IEEE},
  address = {Cambridge, United Kingdom},
  doi = {10.23919/ICIF.2018.8455242},
  urldate = {2021-11-18},
  isbn = {978-0-9964527-6-2},
  file = {../../Bibliography/Hauberg_2018_Directional Statistics with the Spherical Normal Distribution.pdf}
}

@article{he_2004_LocalityPreservingProjections,
  title = {Locality Preserving Projections},
  author = {He, Xiaofei and Niyogi, Partha},
  year = {2004},
  journal = {Advances in neural information processing systems},
  volume = {16},
  number = {16},
  pages = {153--160},
  file = {../../Bibliography/He_2004_Locality preserving projections.pdf}
}

@inproceedings{he_2005_LaplacianScoreFeature,
  title = {Laplacian Score for Feature Selection},
  booktitle = {Proceedings of the 18th International Conference on Neural Information Processing Systems},
  author = {He, Xiaofei and Cai, Deng and Niyogi, Partha},
  year = {2005},
  series = {{{NIPS}}'05},
  pages = {507--514},
  publisher = {MIT Press},
  address = {Cambridge, MA, USA},
  file = {../../Bibliography/He_2005_Laplacian score for feature selection.pdf}
}

@article{he_2014_IntrinsicDimensionalityEstimation,
  title = {Intrinsic Dimensionality Estimation Based on Manifold Assumption},
  author = {He, Jinrong and Ding, Lixin and Jiang, Lei and Li, Zhaokui and Hu, Qinghui},
  year = {2014},
  month = jul,
  journal = {Journal of Visual Communication and Image Representation},
  volume = {25},
  number = {5},
  pages = {740--747},
  issn = {10473203},
  doi = {10.1016/j.jvcir.2014.01.006},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/He_2014_Intrinsic dimensionality estimation based on manifold assumption.pdf}
}

@article{heard_2018_ChoosingMethodsCombining,
  title = {Choosing between Methods of Combining \$p\$-Values},
  author = {Heard, N A and {Rubin-Delanchy}, P},
  year = {2018},
  month = mar,
  journal = {Biometrika},
  volume = {105},
  number = {1},
  pages = {239--246},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/asx076},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Heard_2018_Choosing between methods of combining $p$-values.pdf}
}

@article{heberger_2002_GeneralizationPairCorrelation,
  title = {Generalization of Pair Correlation Method ({{PCM}}) for Non-Parametric Variable Selection: {{Pair}} Correlation Method for Variable Selection},
  shorttitle = {Generalization of Pair Correlation Method ({{PCM}}) for Non-Parametric Variable Selection},
  author = {H{\'e}berger, K{\'a}roly and Rajk{\'o}, R{\'o}bert},
  year = {2002},
  month = aug,
  journal = {Journal of Chemometrics},
  volume = {16},
  number = {8-10},
  pages = {436--443},
  issn = {08869383},
  doi = {10.1002/cem.748},
  urldate = {2022-07-05},
  langid = {english},
  file = {../../Bibliography/Héberger_2002_Generalization of pair correlation method (PCM) for non-parametric variable.pdf}
}

@inproceedings{hein_2005_HilbertianMetricsPositive,
  title = {Hilbertian Metrics and Positive Definite Kernels on Probability Measures},
  booktitle = {International Workshop on Artificial Intelligence and Statistics},
  author = {Hein, Matthias and Bousquet, Olivier},
  year = {2005},
  pages = {136--143},
  organization = {PMLR},
  file = {../../Bibliography/Hein_2005_Hilbertian metrics and positive definite kernels on probability measures.pdf}
}

@article{hellinger_1909_NeueBegrundungTheorie,
  title = {Neue {{Begr{\"u}ndung}} Der {{Theorie}} Quadratischer {{Formen}} von Unendlichvielen {{Ver{\"a}nderlichen}}.},
  author = {Hellinger, E.},
  year = {1909},
  month = jul,
  journal = {Journal f{\"u}r die reine und angewandte Mathematik},
  volume = {1909},
  number = {136},
  pages = {210--271},
  issn = {1435-5345, 0075-4102},
  doi = {10.1515/crll.1909.136.210},
  urldate = {2022-07-02},
  langid = {english}
}

@inproceedings{henderson_2015_EPMEANSEfficientNonparametric,
  title = {{{EP-MEANS}}: An Efficient Nonparametric Clustering of Empirical Probability Distributions},
  shorttitle = {{{EP-MEANS}}},
  booktitle = {Proceedings of the 30th {{Annual ACM Symposium}} on {{Applied Computing}}},
  author = {Henderson, Keith and Gallagher, Brian and {Eliassi-Rad}, Tina},
  year = {2015},
  month = apr,
  pages = {893--900},
  publisher = {ACM},
  address = {Salamanca Spain},
  doi = {10.1145/2695664.2695860},
  urldate = {2022-07-25},
  isbn = {978-1-4503-3196-8},
  langid = {english},
  file = {../../Bibliography/Henderson_2015_EP-MEANS.pdf}
}

@article{henni_2018_UnsupervisedGraphbasedFeature,
  title = {Unsupervised Graph-Based Feature Selection via Subspace and Pagerank Centrality},
  author = {Henni, K. and Mezghani, N. and {Gouin-Vallerand}, C.},
  year = {2018},
  month = dec,
  journal = {Expert Systems with Applications},
  volume = {114},
  pages = {46--53},
  issn = {09574174},
  doi = {10.1016/j.eswa.2018.07.029},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Henni_2018_Unsupervised graph-based feature selection via subspace and pagerank centrality.pdf}
}

@inproceedings{hershey_2007_ApproximatingKullbackLeibler,
  title = {Approximating the {{Kullback Leibler Divergence Between Gaussian Mixture Models}}},
  booktitle = {2007 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} - {{ICASSP}} '07},
  author = {Hershey, John R. and Olsen, Peder A.},
  year = {2007},
  month = apr,
  pages = {IV-317-IV-320},
  publisher = {IEEE},
  address = {Honolulu, HI},
  doi = {10.1109/ICASSP.2007.366913},
  urldate = {2022-07-26},
  isbn = {978-1-4244-0727-9},
  file = {../../Bibliography/Hershey_2007_Approximating the Kullback Leibler Divergence Between Gaussian Mixture Models.pdf}
}

@article{hie_2019_EfficientIntegrationHeterogeneous,
  title = {Efficient Integration of Heterogeneous Single-Cell Transcriptomes Using {{Scanorama}}},
  author = {Hie, Brian and Bryson, Bryan and Berger, Bonnie},
  year = {2019},
  month = jun,
  journal = {Nature Biotechnology},
  volume = {37},
  number = {6},
  pages = {685--691},
  issn = {1087-0156, 1546-1696},
  doi = {10.1038/s41587-019-0113-3},
  urldate = {2022-06-20},
  langid = {english},
  file = {../../Bibliography/Hie_2019_Efficient integration of heterogeneous single-cell transcriptomes using.pdf}
}

@inproceedings{ho_2017_MultilevelClusteringWasserstein,
  title = {Multilevel Clustering via {{Wasserstein}} Means},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  author = {Ho, Nhat and Nguyen, XuanLong and Yurochkin, Mikhail and Bui, Hung Hai and Huynh, Viet and Phung, Dinh},
  editor = {Precup, Doina and Teh, Yee Whye},
  year = {2017-08-06/2017-08-11},
  series = {Proceedings of Machine Learning Research},
  volume = {70},
  pages = {1501--1509},
  publisher = {PMLR},
  file = {../../Bibliography/Ho_2017_Multilevel clustering via Wasserstein means.pdf}
}

@article{hoff_2002_LatentSpaceApproaches,
  title = {Latent {{Space Approaches}} to {{Social Network Analysis}}},
  author = {Hoff, Peter D and Raftery, Adrian E and Handcock, Mark S},
  year = {2002},
  month = dec,
  journal = {Journal of the American Statistical Association},
  volume = {97},
  number = {460},
  pages = {1090--1098},
  issn = {0162-1459, 1537-274X},
  doi = {10.1198/016214502388618906},
  urldate = {2021-11-18},
  langid = {english}
}

@article{hoff_2007_ModelAveragingDimension,
  title = {Model {{Averaging}} and {{Dimension Selection}} for the {{Singular Value Decomposition}}},
  author = {Hoff, Peter D},
  year = {2007},
  month = jun,
  journal = {Journal of the American Statistical Association},
  volume = {102},
  number = {478},
  pages = {674--685},
  issn = {0162-1459, 1537-274X},
  doi = {10.1198/016214506000001310},
  urldate = {2022-07-25},
  langid = {english}
}

@article{hofmann_2008_KernelMethodsMachine,
  title = {Kernel Methods in Machine Learning},
  author = {Hofmann, Thomas and Sch{\"o}lkopf, Bernhard and Smola, Alexander J.},
  year = {2008},
  month = jun,
  journal = {The Annals of Statistics},
  volume = {36},
  number = {3},
  issn = {0090-5364},
  doi = {10.1214/009053607000000677},
  urldate = {2021-11-18},
  file = {../../Bibliography/Hofmann_2008_Kernel methods in machine learning.pdf}
}

@book{hogg_2019_IntroductionMathematicalStatistics,
  title = {Introduction to Mathematical Statistics},
  author = {Hogg, Robert V. and McKean, Joseph W. and Craig, Allen T.},
  year = {2019},
  edition = {Eighth edition},
  publisher = {Pearson},
  address = {Boston},
  isbn = {978-0-13-468699-8},
  lccn = {QA276 .H59 2019},
  keywords = {Mathematical statistics}
}

@misc{holbrook_2016_BayesianInferenceMatrix,
  title = {Bayesian {{Inference}} on {{Matrix Manifolds}} for {{Linear Dimensionality Reduction}}},
  author = {Holbrook, Andrew and {Vandenberg-Rodes}, Alexander and Shahbaba, Babak},
  year = {2016},
  month = jun,
  number = {arXiv:1606.04478},
  eprint = {1606.04478},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2023-12-19},
  abstract = {We reframe linear dimensionality reduction as a problem of Bayesian inference on matrix manifolds. This natural paradigm extends the Bayesian framework to dimensionality reduction tasks in higher dimensions with simpler models at greater speeds. Here an orthogonal basis is treated as a single point on a manifold and is associated with a linear subspace on which observations vary maximally. Throughout this paper, we employ the Grassmann and Stiefel manifolds for various dimensionality reduction problems, explore the connection between the two manifolds, and use Hybrid Monte Carlo for posterior sampling on the Grassmannian for the first time. We delineate in which situations either manifold should be considered. Further, matrix manifold models are used to yield scientific insight in the context of cognitive neuroscience, and we conclude that our methods are suitable for basic inference as well as accurate prediction.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Computation,Statistics - Machine Learning},
  file = {../../Bibliography/Holbrook_2016_Bayesian Inference on Matrix Manifolds for Linear Dimensionality Reduction.pdf;../../../../../Zotero/storage/CK6BMQ9I/1606.html}
}

@article{holbrook_2018_DifferentiatingPseudoDeterminant,
  title = {Differentiating the Pseudo Determinant},
  author = {Holbrook, Andrew},
  year = {2018},
  month = jul,
  journal = {Linear Algebra and its Applications},
  volume = {548},
  pages = {293--304},
  issn = {00243795},
  doi = {10.1016/j.laa.2018.03.018},
  urldate = {2024-01-17},
  langid = {english},
  file = {../../Bibliography/Holbrook_2018_Differentiating the pseudo determinant.pdf}
}

@article{holland_1983_StochasticBlockmodelsFirst,
  title = {Stochastic Blockmodels: {{First}} Steps},
  shorttitle = {Stochastic Blockmodels},
  author = {Holland, Paul W. and Laskey, Kathryn Blackmond and Leinhardt, Samuel},
  year = {1983},
  month = jun,
  journal = {Social Networks},
  volume = {5},
  number = {2},
  pages = {109--137},
  issn = {03788733},
  doi = {10.1016/0378-8733(83)90021-7},
  urldate = {2022-08-28},
  langid = {english},
  file = {../../Bibliography/Holland_1983_Stochastic blockmodels.pdf}
}

@article{honnorat_2024_RiemannianFrameworksHarmonization,
  title = {Riemannian Frameworks for the Harmonization of Resting-State Functional {{MRI}} Scans},
  author = {Honnorat, Nicolas and Seshadri, Sudha and Killiany, Ron and Blangero, John and Glahn, David C. and Fox, Peter and Habes, Mohamad},
  year = {2024},
  month = jan,
  journal = {Medical Image Analysis},
  volume = {91},
  pages = {103043},
  issn = {13618415},
  doi = {10.1016/j.media.2023.103043},
  urldate = {2024-09-13},
  langid = {english}
}

@article{horev_2017_GeometryawarePrincipalComponent,
  title = {Geometry-Aware Principal Component Analysis for Symmetric Positive Definite Matrices},
  author = {Horev, Inbal and Yger, Florian and Sugiyama, Masashi},
  year = {2017},
  month = apr,
  journal = {Machine Learning},
  volume = {106},
  number = {4},
  pages = {493--522},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/s10994-016-5605-5},
  urldate = {2022-03-25},
  langid = {english},
  file = {../../Bibliography/Horev_2017_Geometry-aware principal component analysis for symmetric positive definite.pdf}
}

@article{hornik_2014_MovMFPackageFitting,
  title = {{{movMF}} : {{An R Package}} for {{Fitting Mixtures}} of von {{Mises-Fisher Distributions}}},
  shorttitle = {{{{\textbf{movMF}}}}},
  author = {Hornik, Kurt and Gr{\"u}n, Bettina},
  year = {2014},
  journal = {Journal of Statistical Software},
  volume = {58},
  number = {10},
  issn = {1548-7660},
  doi = {10.18637/jss.v058.i10},
  urldate = {2022-08-20},
  langid = {english},
  file = {../../Bibliography/Hornik_2014_movMF.pdf}
}

@article{hosseini_2020_AlternativeEMGaussian,
  title = {An Alternative to {{EM}} for {{Gaussian}} Mixture Models: Batch and Stochastic {{Riemannian}} Optimization},
  shorttitle = {An Alternative to {{EM}} for {{Gaussian}} Mixture Models},
  author = {Hosseini, Reshad and Sra, Suvrit},
  year = {2020},
  month = may,
  journal = {Mathematical Programming},
  volume = {181},
  number = {1},
  pages = {187--223},
  issn = {0025-5610, 1436-4646},
  doi = {10.1007/s10107-019-01381-4},
  urldate = {2021-10-25},
  langid = {english},
  file = {../../Bibliography/Hosseini_2020_An alternative to EM for Gaussian mixture models.pdf}
}

@article{hotelling_1936_RelationsTwoSets,
  title = {Relations {{Between Two Sets}} of {{Variates}}},
  author = {Hotelling, Harold},
  year = {1936},
  month = dec,
  journal = {Biometrika},
  volume = {28},
  number = {3/4},
  eprint = {2333955},
  eprinttype = {jstor},
  pages = {321},
  issn = {00063444},
  doi = {10.2307/2333955},
  urldate = {2021-10-03},
  file = {../../Bibliography/Hotelling_1936_Relations Between Two Sets of Variates.pdf}
}

@inproceedings{houle_2012_GeneralizedExpansionDimension,
  title = {Generalized {{Expansion Dimension}}},
  booktitle = {2012 {{IEEE}} 12th {{International Conference}} on {{Data Mining Workshops}}},
  author = {Houle, Michael E. and Kashima, Hisashi and Nett, Michael},
  year = {2012},
  month = dec,
  pages = {587--594},
  publisher = {IEEE},
  address = {Brussels, Belgium},
  doi = {10.1109/ICDMW.2012.94},
  urldate = {2022-07-25},
  isbn = {978-1-4673-5164-5 978-0-7695-4925-5},
  file = {../../Bibliography/Houle_2012_Generalized Expansion Dimension.pdf}
}

@inproceedings{huang_2021_ProjectionRobustWasserstein,
  title = {Projection {{Robust Wasserstein Barycenters}}},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  author = {Huang, Minhui and Ma, Shiqian and Lai, Lifeng},
  editor = {Meila, Marina and Zhang, Tong},
  year = {2021-07-18/2021-07-24},
  series = {Proceedings of Machine Learning Research},
  volume = {139},
  pages = {4456--4465},
  publisher = {PMLR},
  abstract = {Collecting and aggregating information from several probability measures or histograms is a fundamental task in machine learning. One of the popular solution methods for this task is to compute the barycenter of the probability measures under the Wasserstein metric. However, approximating the Wasserstein barycenter is numerically challenging because of the curse of dimensionality. This paper proposes the projection robust Wasserstein barycenter (PRWB) that has the potential to mitigate the curse of dimensionality, and a relaxed PRWB (RPRWB) model that is computationally more tractable. By combining the iterative Bregman projection algorithm and Riemannian optimization, we propose two algorithms for computing the RPRWB, which is a max-min problem over the Stiefel manifold. The complexity of arithmetic operations of the proposed algorithms for obtaining an {$\epsilon$}-stationary solution is analyzed. We incorporate the RPRWB into a discrete distribution clustering algorithm, and the numerical results on real text datasets confirm that our RPRWB model helps improve the clustering performance significantly.},
  file = {../../Bibliography/Huang_2021_Projection Robust Wasserstein Barycenters.pdf}
}

@book{huber_1981_RobustStatistics,
  title = {Robust Statistics},
  author = {Huber, Peter J.},
  year = {1981},
  series = {Wiley Series in Probability and Mathematical Statistics},
  publisher = {Wiley},
  address = {New York},
  isbn = {978-0-471-41805-4},
  lccn = {QA276 .H785},
  keywords = {Robust statistics}
}

@article{huber_2008_ProgressiveGaussianMixture,
  title = {Progressive {{Gaussian Mixture Reduction}}},
  author = {Huber, Marco F. and Hanebeck, Uwe D.},
  year = {2008},
  publisher = {Karlsruhe},
  doi = {10.5445/IR/1000034859},
  urldate = {2025-01-05},
  abstract = {For estimation and fusion tasks it is inevitable to approximate a Gaussian mixture by one with fewer components to keep the complexity bounded. Appropriate approximations can be typically generated by exploiting the redundancy in the shape description of the original mixture. In contrast to the common approach of successively merging pairs of components to maintain a desired complexity, the novel Gaussian mixture reduction algorithm introduced in this paper avoids to directly reduce the original Gaussian mixture. Instead, an approximate mixture is generated from scratch by employing homotopy continuation. This allows starting the approximation with a single Gaussian, which is constantly adapted to the progressively incorporated true Gaussian mixture. Whenever a user-defined bound on the deviation of the approximation cannot be maintained during the continuation, further components are added to the approximation. This facilitates significantly reducing the number of components even for complex Gaussian mixtures.},
  copyright = {Open Access, KITopen License},
  langid = {english}
}

@article{huckemann_2010_INTRINSICSHAPEANALYSIS,
  title = {{{INTRINSIC SHAPE ANALYSIS}}: {{GEODESIC PCA FOR RIEMANNIAN MANIFOLDS MODULO ISOMETRIC LIE GROUP ACTIONS}}},
  author = {Huckemann, Stephan and Hotz, Thomas and Munk, Axel},
  year = {2010},
  journal = {Statistica Sinica},
  volume = {20},
  number = {1},
  eprint = {24308976},
  eprinttype = {jstor},
  pages = {1--58},
  publisher = {Institute of Statistical Science, Academia Sinica},
  issn = {10170405, 19968507}
}

@article{hung_2015_IntuitiveClusteringAlgorithm,
  title = {An Intuitive Clustering Algorithm for Spherical Data with Application to Extrasolar Planets},
  author = {Hung, Wen-Liang and {Chang-Chien}, Shou-Jen and Yang, Miin-Shen},
  year = {2015},
  month = oct,
  journal = {Journal of Applied Statistics},
  volume = {42},
  number = {10},
  pages = {2220--2232},
  issn = {0266-4763, 1360-0532},
  doi = {10.1080/02664763.2015.1023271},
  urldate = {2022-07-25},
  langid = {english}
}

@article{hutter_2021_MinimaxEstimationSmooth,
  title = {Minimax Estimation of Smooth Optimal Transport Maps},
  author = {H{\"u}tter, Jan-Christian and Rigollet, Philippe},
  year = {2021},
  month = apr,
  journal = {The Annals of Statistics},
  volume = {49},
  number = {2},
  issn = {0090-5364},
  doi = {10.1214/20-AOS1997},
  urldate = {2022-09-07},
  file = {../../Bibliography/Hütter_2021_Minimax estimation of smooth optimal transport maps.pdf}
}

@article{hyodo_2018_SimultaneousTestingMean,
  title = {A Simultaneous Testing of the Mean Vector and the Covariance Matrix among Two Populations for High-Dimensional Data},
  author = {Hyodo, Masashi and Nishiyama, Takahiro},
  year = {2018},
  month = sep,
  journal = {TEST},
  volume = {27},
  number = {3},
  pages = {680--699},
  issn = {1133-0686, 1863-8260},
  doi = {10.1007/s11749-017-0567-x},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Hyodo_2018_A simultaneous testing of the mean vector and the covariance matrix among two.pdf}
}

@article{hyodo_2021_SimultaneousTestingMean,
  title = {Simultaneous Testing of the Mean Vector and Covariance Matrix among {\emph{k}} Populations for High-Dimensional Data},
  author = {Hyodo, Masashi and Nishiyama, Takahiro},
  year = {2021},
  month = feb,
  journal = {Communications in Statistics - Theory and Methods},
  volume = {50},
  number = {3},
  pages = {663--684},
  issn = {0361-0926, 1532-415X},
  doi = {10.1080/03610926.2019.1639751},
  urldate = {2021-11-23},
  langid = {english}
}

@article{ipsen_2002_EvolutionaryReconstructionNetworks,
  title = {Evolutionary Reconstruction of Networks},
  author = {Ipsen, Mads and Mikhailov, Alexander S.},
  year = {2002},
  month = oct,
  journal = {Physical Review E},
  volume = {66},
  number = {4},
  pages = {046109},
  issn = {1063-651X, 1095-3787},
  doi = {10.1103/PhysRevE.66.046109},
  urldate = {2022-08-28},
  langid = {english}
}

@incollection{irpino_2006_NewWassersteinBased,
  title = {A {{New Wasserstein Based Distance}} for the {{Hierarchical Clustering}} of {{Histogram Symbolic Data}}},
  booktitle = {Data {{Science}} and {{Classification}}},
  author = {Irpino, Antonio and Verde, Rosanna},
  editor = {Batagelj, Vladimir and Bock, Hans-Hermann and Ferligoj, Anu{\v s}ka and {\v Z}iberna, Ale{\v s}},
  year = {2006},
  pages = {185--192},
  publisher = {Springer Berlin Heidelberg},
  doi = {10.1007/3-540-34416-0_20},
  urldate = {2023-09-04},
  isbn = {978-3-540-34415-5},
  langid = {english}
}

@misc{irpino_2016_FuzzyClusteringDistributionvalued,
  title = {Fuzzy Clustering of Distribution-Valued Data Using Adaptive {{L2 Wasserstein}} Distances},
  author = {Irpino, Antonio and De Carvalho, Francisco and Verde, Rosanna},
  year = {2016},
  month = may,
  number = {arXiv:1605.00513},
  eprint = {1605.00513},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2023-09-04},
  abstract = {Distributional (or distribution-valued) data are a new type of data arising from several sources and are considered as realizations of distributional variables. A new set of fuzzy c-means algorithms for data described by distributional variables is proposed. The algorithms use the \$L2\$ Wasserstein distance between distributions as dissimilarity measures. Beside the extension of the fuzzy c-means algorithm for distributional data, and considering a decomposition of the squared \$L2\$ Wasserstein distance, we propose a set of algorithms using different automatic way to compute the weights associated with the variables as well as with their components, globally or cluster-wise. The relevance weights are computed in the clustering process introducing product-to-one constraints. The relevance weights induce adaptive distances expressing the importance of each variable or of each component in the clustering process, acting also as a variable selection method in clustering. We have tested the proposed algorithms on artificial and real-world data. Results confirm that the proposed methods are able to better take into account the cluster structure of the data with respect to the standard fuzzy c-means, with non-adaptive distances.},
  archiveprefix = {arXiv},
  keywords = {62A86 62H30 62G30,G.3,H.3.3,I.5.1,Statistics - Machine Learning},
  file = {../../Bibliography/Irpino_2016_Fuzzy clustering of distribution-valued data using adaptive L2 Wasserstein.pdf}
}

@article{ito_2009_ValidationDecisionMakingModels,
  title = {Validation of {{Decision-Making Models}} and {{Analysis}} of {{Decision Variables}} in the {{Rat Basal Ganglia}}},
  author = {Ito, Makoto and Doya, Kenji},
  year = {2009},
  month = aug,
  journal = {The Journal of Neuroscience},
  volume = {29},
  number = {31},
  pages = {9861--9874},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.6157-08.2009},
  urldate = {2024-01-03},
  abstract = {Reinforcement learning theory plays a key role in understanding the behavioral and neural mechanisms of choice behavior in animals and humans. Especially, intermediate variables of learning models estimated from behavioral data, such as the expectation of reward for each candidate choice (action value), have been used in searches for the neural correlates of computational elements in learning and decision making. The aims of the present study are as follows: (1) to test which computational model best captures the choice learning process in animals and (2) to elucidate how action values are represented in different parts of the corticobasal ganglia circuit. We compared different behavioral learning algorithms to predict the choice sequences generated by rats during a free-choice task and analyzed associated neural activity in the nucleus accumbens (NAc) and ventral pallidum (VP). The major findings of this study were as follows: (1) modified versions of an action--value learning model captured a variety of choice strategies of rats, including win-stay--lose-switch and persevering behavior, and predicted rats' choice sequences better than the best multistep Markov model; and (2) information about action values and future actions was coded in both the NAc and VP, but was less dominant than information about trial types, selected actions, and reward outcome. The results of our model-based analysis suggest that the primary role of the NAc and VP is to monitor information important for updating choice behaviors. Information represented in the NAc and VP might contribute to a choice mechanism that is situated elsewhere.},
  langid = {english},
  file = {../../Bibliography/Ito_2009_Validation of Decision-Making Models and Analysis of Decision Variables in the.pdf}
}

@inproceedings{izzo_2021_DimensionalityReductionWasserstein,
  title = {Dimensionality {{Reduction}} for {{Wasserstein Barycenter}}},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Izzo, Zachary and Silwal, Sandeep and Zhou, Samson},
  editor = {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P.S. and Vaughan, J. Wortman},
  year = {2021},
  volume = {34},
  pages = {15582--15594},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Izzo_2021_Dimensionality Reduction for Wasserstein Barycenter.pdf}
}

@article{jaccard_1912_DISTRIBUTIONFLORAALPINE,
  title = {{{THE DISTRIBUTION OF THE FLORA IN THE ALPINE ZONE}}.1},
  author = {Jaccard, Paul},
  year = {1912},
  month = feb,
  journal = {New Phytologist},
  volume = {11},
  number = {2},
  pages = {37--50},
  issn = {0028-646X, 1469-8137},
  doi = {10.1111/j.1469-8137.1912.tb05611.x},
  urldate = {2022-08-20},
  langid = {english}
}

@article{jakobson_2002_ExtremalMetricsGraphs,
  title = {Extremal Metrics on Graphs {{I}}},
  author = {Jakobson, Dmitry and Rivin, Igor},
  year = {2002},
  month = jan,
  journal = {Forum Mathematicum},
  volume = {14},
  number = {1},
  issn = {0933-7741, 1435-5337},
  doi = {10.1515/form.2002.002},
  urldate = {2022-08-28}
}

@article{jang_2017_IndividualityManifestsDynamic,
  title = {Individuality Manifests in the Dynamic Reconfiguration of Large-Scale Brain Networks during Movie Viewing},
  author = {Jang, Changwon and Knight, Elizabeth Quattrocki and Pae, Chongwon and Park, Bumhee and Yoon, Shin-Ae and Park, Hae-Jeong},
  year = {2017},
  month = feb,
  journal = {Scientific Reports},
  volume = {7},
  number = {1},
  pages = {41414},
  issn = {2045-2322},
  doi = {10.1038/srep41414},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Jang_2017_Individuality manifests in the dynamic reconfiguration of large-scale brain.pdf}
}

@article{jayasumana_2015_KernelMethodsRiemannian,
  title = {Kernel {{Methods}} on {{Riemannian Manifolds}} with {{Gaussian RBF Kernels}}},
  author = {Jayasumana, Sadeep and Hartley, Richard and Salzmann, Mathieu and Li, Hongdong and Harandi, Mehrtash},
  year = {2015},
  month = dec,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {37},
  number = {12},
  pages = {2464--2477},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2015.2414422},
  urldate = {2024-09-12},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  file = {../../../../../Zotero/storage/KLE48I5K/Jayasumana et al. - 2015 - Kernel Methods on Riemannian Manifolds with Gaussi.pdf}
}

@article{jebara_2004_ProbabilityProductKernels,
  title = {Probability Product Kernels},
  author = {Jebara, Tony and Kondor, Risi and Howard, Andrew and Bennett, Kristin and {Cesa-bianchi}, Nicol{\`o}},
  year = {2004},
  journal = {Journal of Machine Learning Research},
  volume = {5},
  pages = {819--844},
  file = {../../Bibliography/Jebara_2004_Probability product kernels.pdf}
}

@article{jeffreys_1946_InvariantFormPrior,
  title = {An Invariant Form for the Prior Probability in Estimation Problems},
  author = {Jeffreys, Harold},
  year = {1946},
  month = sep,
  journal = {Proceedings of the Royal Society of London. Series A. Mathematical and Physical Sciences},
  volume = {186},
  number = {1007},
  pages = {453--461},
  issn = {0080-4630, 2053-9169},
  doi = {10.1098/rspa.1946.0056},
  urldate = {2022-07-02},
  langid = {english},
  file = {../../Bibliography/Jeffreys_1946_An invariant form for the prior probability in estimation problems.pdf}
}

@book{jeffreys_1998_TheoryProbability,
  title = {Theory of Probability},
  author = {Jeffreys, Harold},
  year = {1998},
  series = {Oxford Classic Texts in the Physical Sciences},
  edition = {3rd ed},
  publisher = {Clarendon Press ; Oxford University Press},
  address = {Oxford [Oxfordshire] : New York},
  isbn = {978-0-19-850368-2},
  lccn = {QA273 .J4 1998},
  keywords = {Probabilities}
}

@incollection{jenssen_2005_OptimizingCauchySchwarzPDF,
  title = {Optimizing the {{Cauchy-Schwarz PDF Distance}} for {{Information Theoretic}}, {{Non-parametric Clustering}}},
  booktitle = {Energy {{Minimization Methods}} in {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Jenssen, Robert and Erdogmus, Deniz and Hild, Kenneth E. and Principe, Jose C. and Eltoft, Torbj{\o}rn},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Rangarajan, Anand and Vemuri, Baba and Yuille, Alan L.},
  year = {2005},
  volume = {3757},
  pages = {34--45},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11585978_3},
  urldate = {2022-07-02},
  isbn = {978-3-540-30287-2 978-3-540-32098-2}
}

@article{jeong_2016_ConnectivitybasedChangePoint,
  title = {Connectivity-Based Change Point Detection for Large-Size Functional Networks},
  author = {Jeong, Seok-Oh and Pae, Chongwon and Park, Hae-Jeong},
  year = {2016},
  month = dec,
  journal = {NeuroImage},
  volume = {143},
  pages = {353--363},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2016.09.019},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Jeong_2016_Connectivity-based change point detection for large-size functional networks.pdf}
}

@article{jia_2009_TraceRatioProblem,
  title = {Trace {{Ratio Problem Revisited}}},
  author = {Jia, Yangqing and Nie, Feiping and Zhang, Changshui},
  year = {2009},
  month = apr,
  journal = {IEEE Transactions on Neural Networks},
  volume = {20},
  number = {4},
  pages = {729--735},
  issn = {1045-9227, 1941-0093},
  doi = {10.1109/TNN.2009.2015760},
  urldate = {2021-11-13},
  file = {../../Bibliography/Jia_2009_Trace Ratio Problem Revisited.pdf}
}

@book{johnson_1987_NumericalSolutionPartial,
  title = {Numerical Solution of Partial Differential Equations by the Finite Element Method},
  author = {Johnson, Claes and Johnson, Claes},
  year = {1987},
  publisher = {Cambridge University Press},
  address = {Cambridge [England] ; New York},
  isbn = {978-0-521-34514-9 978-0-521-34758-7},
  lccn = {TA347.F5 J62 1987},
  keywords = {Differential equations Partial,Finite element method,Numerical solutions}
}

@book{joliffe_2002_PrincipalComponentAnalysis,
  title = {Principal {{Component Analysis}}},
  author = {Joliffe, I. T.},
  year = {2002},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer-Verlag},
  address = {New York},
  doi = {10.1007/b98835},
  urldate = {2023-07-26},
  isbn = {978-0-387-95442-4},
  langid = {english}
}

@incollection{josang_2007_InterpretingBeliefFunctions,
  title = {Interpreting {{Belief Functions}} as {{Dirichlet Distributions}}},
  booktitle = {Symbolic and {{Quantitative Approaches}} to {{Reasoning}} with {{Uncertainty}}},
  author = {J{\o}sang, Audun and Elouedi, Zied},
  editor = {Mellouli, Khaled},
  year = {2007},
  volume = {4724},
  pages = {393--404},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-75256-1_36},
  urldate = {2022-10-12},
  isbn = {978-3-540-75255-4 978-3-540-75256-1}
}

@misc{jurman_2010_IntroductionSpectralDistances,
  title = {An Introduction to Spectral Distances in Networks (Extended Version)},
  author = {Jurman, Giuseppe and Visintainer, Roberto and Furlanello, Cesare},
  year = {2010},
  month = oct,
  number = {arXiv:1005.0103},
  eprint = {1005.0103},
  primaryclass = {math, q-bio},
  publisher = {arXiv},
  urldate = {2022-08-28},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Combinatorics,Quantitative Biology - Molecular Networks},
  file = {../../Bibliography/Jurman_2010_An introduction to spectral distances in networks (extended version).pdf}
}

@inproceedings{jurman_2015_HIMGlocalMetric,
  title = {The {{HIM}} Glocal Metric and Kernel for Network Comparison and Classification},
  booktitle = {2015 {{IEEE International Conference}} on {{Data Science}} and {{Advanced Analytics}} ({{DSAA}})},
  author = {Jurman, Giuseppe and Visintainer, Roberto and Filosi, Michele and Riccadonna, Samantha and Furlanello, Cesare},
  year = {2015},
  month = oct,
  pages = {1--10},
  publisher = {IEEE},
  address = {Campus des Cordeliers, Paris, France},
  doi = {10.1109/DSAA.2015.7344816},
  urldate = {2022-08-28},
  isbn = {978-1-4673-8272-4},
  file = {../../Bibliography/Jurman_2015_The HIM glocal metric and kernel for network comparison and classification.pdf}
}

@article{kamada_1989_AlgorithmDrawingGeneral,
  title = {An Algorithm for Drawing General Undirected Graphs},
  author = {Kamada, Tomihisa and Kawai, Satoru},
  year = {1989},
  month = apr,
  journal = {Information Processing Letters},
  volume = {31},
  number = {1},
  pages = {7--15},
  issn = {00200190},
  doi = {10.1016/0020-0190(89)90102-6},
  urldate = {2024-04-25},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {../../Bibliography/Kamada_1989_An algorithm for drawing general undirected graphs.pdf}
}

@inproceedings{kampa_2011_ClosedformCauchyschwarzPDF,
  title = {Closed-Form Cauchy-Schwarz {{PDF}} Divergence for Mixture of {{Gaussians}}},
  booktitle = {The 2011 {{International Joint Conference}} on {{Neural Networks}}},
  author = {Kampa, Kittipat and Hasanbelliu, Erion and Principe, Jose C.},
  year = {2011},
  month = jul,
  pages = {2578--2585},
  publisher = {IEEE},
  address = {San Jose, CA, USA},
  doi = {10.1109/IJCNN.2011.6033555},
  urldate = {2022-07-02},
  isbn = {978-1-4244-9635-8},
  file = {../../Bibliography/Kampa_2011_Closed-form cauchy-schwarz PDF divergence for mixture of Gaussians.pdf}
}

@article{kantorovitch_1958_TranslocationMasses,
  title = {On the {{Translocation}} of {{Masses}}},
  author = {Kantorovitch, L.},
  year = {1958},
  month = oct,
  journal = {Management Science},
  volume = {5},
  number = {1},
  pages = {1--4},
  issn = {0025-1909, 1526-5501},
  doi = {10.1287/mnsc.5.1.1},
  langid = {english}
}

@article{kaplan_2024_AASLDPracticeGuidance,
  title = {{{AASLD Practice Guidance}} on Risk Stratification and Management of Portal Hypertension and Varices in Cirrhosis},
  author = {Kaplan, David E. and Ripoll, Cristina and Thiele, Maja and Fortune, Brett E. and Simonetto, Douglas A. and {Garcia-Tsao}, Guadalupe and Bosch, Jaime},
  year = {2024},
  month = may,
  journal = {Hepatology},
  volume = {79},
  number = {5},
  pages = {1180--1211},
  issn = {0270-9139},
  doi = {10.1097/HEP.0000000000000647},
  urldate = {2024-05-15},
  langid = {english}
}

@article{karrer_2011_StochasticBlockmodelsCommunity,
  title = {Stochastic Blockmodels and Community Structure in Networks},
  author = {Karrer, Brian and Newman, M. E. J.},
  year = {2011},
  month = jan,
  journal = {Physical Review E},
  volume = {83},
  number = {1},
  pages = {016107},
  issn = {1539-3755, 1550-2376},
  doi = {10.1103/PhysRevE.83.016107},
  urldate = {2022-08-28},
  langid = {english},
  file = {../../Bibliography/Karrer_2011_Stochastic blockmodels and community structure in networks.pdf}
}

@article{katz_2019_AlternatingDiffusionMaps,
  title = {Alternating Diffusion Maps for Multimodal Data Fusion},
  author = {Katz, Ori and Talmon, Ronen and Lo, Yu-Lun and Wu, Hau-Tieng},
  year = {2019},
  month = jan,
  journal = {Information Fusion},
  volume = {45},
  pages = {346--360},
  issn = {15662535},
  doi = {10.1016/j.inffus.2018.01.007},
  urldate = {2023-01-09},
  langid = {english},
  file = {../../Bibliography/Katz_2019_Alternating diffusion maps for multimodal data fusion.pdf}
}

@book{kaufman_1990_FindingGroupsData,
  title = {Finding {{Groups}} in {{Data}}: {{An Introduction}} to {{Cluster Analysis}}},
  shorttitle = {Finding {{Groups}} in {{Data}}},
  author = {Kaufman, Leonard and Rousseeuw, Peter J.},
  year = {1990},
  month = mar,
  series = {Wiley {{Series}} in {{Probability}} and {{Statistics}}},
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/9780470316801},
  urldate = {2024-12-27},
  copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
  isbn = {978-0-471-87876-6 978-0-470-31680-1},
  langid = {english}
}

@incollection{kaufman_1990_PartitioningMedoidsProgram,
  title = {Partitioning {{Around Medoids}} ({{Program PAM}})},
  booktitle = {Wiley {{Series}} in {{Probability}} and {{Statistics}}},
  author = {Kaufman, Leonard and Rousseeuw, Peter J.},
  year = {1990},
  month = mar,
  pages = {68--125},
  publisher = {John Wiley \& Sons, Inc.},
  address = {Hoboken, NJ, USA},
  doi = {10.1002/9780470316801.ch2},
  urldate = {2021-10-02},
  isbn = {978-0-470-31680-1 978-0-471-87876-6},
  langid = {english}
}

@book{kaufman_2005_FindingGroupsData,
  title = {Finding Groups in Data: An Introduction to Cluster Analysis},
  shorttitle = {Finding Groups in Data},
  author = {Kaufman, Leonard and Rousseeuw, Peter J.},
  year = {2005},
  series = {Wiley Series in Probability and Mathematical Statistics},
  publisher = {Wiley},
  address = {Hoboken, N.J},
  isbn = {978-0-471-73578-6},
  lccn = {QA278 .K38 2005},
  keywords = {Cluster analysis}
}

@article{keller-ressel_2020_HydraMethodStrainminimizing,
  title = {Hydra: A Method for Strain-Minimizing Hyperbolic Embedding of Network- and Distance-Based Data},
  shorttitle = {Hydra},
  author = {{Keller-Ressel}, Martin and Nargang, Stephanie},
  editor = {Estrada, Ernesto},
  year = {2020},
  month = feb,
  journal = {Journal of Complex Networks},
  volume = {8},
  number = {1},
  pages = {cnaa002},
  issn = {2051-1329},
  doi = {10.1093/comnet/cnaa002},
  urldate = {2022-02-03},
  abstract = {Abstract             We introduce hydra (hyperbolic distance recovery and approximation), a new method for embedding network- or distance-based data into hyperbolic space. We show mathematically that hydra satisfies a certain optimality guarantee: it minimizes the `hyperbolic strain' between original and embedded data points. Moreover, it is able to recover points exactly, when they are contained in a low-dimensional hyperbolic subspace of the feature space. Testing on real network data we show that the embedding quality of hydra is competitive with existing hyperbolic embedding methods, but achieved at substantially shorter computation time. An extended method, termed hydra+, typically outperforms existing methods in both computation time and embedding quality.},
  langid = {english}
}

@article{kendall_1990_ProbabilityConvexityHarmonic,
  title = {Probability, {{Convexity}}, and {{Harmonic Maps}} with {{Small Image I}}: {{Uniqueness}} and {{Fine Existence}}},
  shorttitle = {Probability, {{Convexity}}, and {{Harmonic Maps}} with {{Small Image I}}},
  author = {Kendall, Wilfrid S.},
  year = {1990},
  month = sep,
  journal = {Proceedings of the London Mathematical Society},
  volume = {s3-61},
  number = {2},
  pages = {371--406},
  issn = {00246115},
  doi = {10.1112/plms/s3-61.2.371},
  urldate = {2021-09-29},
  langid = {english}
}

@article{kent_2004_SimulationComplexBingham,
  title = {Simulation for the Complex {{Bingham}} Distribution},
  author = {Kent, John T. and Constable, Patrick D.L. and Er, Fikret},
  year = {2004},
  month = jan,
  journal = {Statistics and Computing},
  volume = {14},
  number = {1},
  pages = {53--57},
  issn = {0960-3174},
  doi = {10.1023/B:STCO.0000009414.14099.03},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Kent_2004_Simulation for the complex Bingham distribution.pdf}
}

@phdthesis{kim_2015_PeriodicSignalAnalysis,
  title = {Periodic Signal Analysis as an Application of Principal Component Analysis},
  author = {Kim, Donggun},
  year = {2015},
  address = {Seoul, South Korea},
  school = {Graduate School, Yonsei University,}
}

@article{kim_2017_WassersteinBarycentersRiemannian,
  title = {Wasserstein Barycenters over {{Riemannian}} Manifolds},
  author = {Kim, Young-Heon and Pass, Brendan},
  year = {2017},
  month = feb,
  journal = {Advances in Mathematics},
  volume = {307},
  pages = {640--683},
  issn = {00018708},
  doi = {10.1016/j.aim.2016.11.026},
  urldate = {2023-09-29},
  langid = {english},
  file = {../../Bibliography/Kim_2017_Wasserstein barycenters over Riemannian manifolds.pdf}
}

@article{kim_2023_PCASVDCentering,
  title = {{{PCA}}, {{SVD}}, and {{Centering}} of {{Data}}},
  author = {Kim, Donggun and You, Kisung},
  year = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2307.15213},
  urldate = {2023-08-01},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Computer and information sciences,Machine Learning (stat.ML),Methodology (stat.ME)}
}

@article{kiselev_2017_SC3ConsensusClustering,
  title = {{{SC3}}: Consensus Clustering of Single-Cell {{RNA-seq}} Data},
  shorttitle = {{{SC3}}},
  author = {Kiselev, Vladimir Yu and Kirschner, Kristina and Schaub, Michael T and Andrews, Tallulah and Yiu, Andrew and Chandra, Tamir and Natarajan, Kedar N and Reik, Wolf and Barahona, Mauricio and Green, Anthony R and Hemberg, Martin},
  year = {2017},
  month = may,
  journal = {Nature Methods},
  volume = {14},
  number = {5},
  pages = {483--486},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/nmeth.4236},
  urldate = {2021-09-03},
  langid = {english},
  file = {../../Bibliography/Kiselev_2017_SC3.pdf}
}

@book{klebanov_2005_NdistancesTheirApplications,
  title = {N-Distances and Their Applications},
  author = {Klebanov, Lev Borisovi{\v c}},
  year = {2005},
  edition = {1. ed},
  publisher = {Karolinum Press},
  address = {Prague},
  isbn = {978-80-246-1152-5},
  langid = {english}
}

@article{klein_1993_ResistanceDistance,
  title = {Resistance Distance},
  author = {Klein, D. J. and Randi{\'c}, M.},
  year = {1993},
  month = dec,
  journal = {Journal of Mathematical Chemistry},
  volume = {12},
  number = {1},
  pages = {81--95},
  issn = {0259-9791, 1572-8897},
  doi = {10.1007/BF01164627},
  urldate = {2024-08-30},
  copyright = {http://www.springer.com/tdm},
  langid = {english}
}

@article{klein_2002_ResistanceDistanceSumRules,
  title = {Resistance-{{Distance Sum Rules}}},
  author = {Klein, Douglas},
  year = {2002},
  month = jun,
  journal = {Croatia Chemica Acta},
  volume = {73}
}

@article{knott_1984_OptimalMappingDistributions,
  title = {On the Optimal Mapping of Distributions},
  author = {Knott, M. and Smith, C. S.},
  year = {1984},
  month = may,
  journal = {Journal of Optimization Theory and Applications},
  volume = {43},
  number = {1},
  pages = {39--49},
  issn = {0022-3239, 1573-2878},
  doi = {10.1007/BF00934745},
  urldate = {2021-11-09},
  langid = {english}
}

@book{kolaczyk_2009_StatisticalAnalysisNetwork,
  title = {Statistical Analysis of Network Data: Methods and Models},
  shorttitle = {Statistical Analysis of Network Data},
  author = {Kolaczyk, Eric D.},
  year = {2009},
  series = {Springer Series in Statistics},
  publisher = {Springer},
  address = {New York ; [London]},
  isbn = {978-0-387-88145-4},
  lccn = {QA402 .K648 2009},
  keywords = {Analyse de systemes,Methodes statistiques,Statistical methods,System analysis},
  annotation = {OCLC: ocn288985465}
}

@article{kolaczyk_2020_AveragesUnlabeledNetworks,
  title = {Averages of Unlabeled Networks: {{Geometric}} Characterization and Asymptotic Behavior},
  shorttitle = {Averages of Unlabeled Networks},
  author = {Kolaczyk, Eric D. and Lin, Lizhen and Rosenberg, Steven and Walters, Jackson and Xu, Jie},
  year = {2020},
  month = feb,
  journal = {The Annals of Statistics},
  volume = {48},
  number = {1},
  issn = {0090-5364},
  doi = {10.1214/19-AOS1820},
  urldate = {2022-08-28},
  file = {../../Bibliography/Kolaczyk_2020_Averages of unlabeled networks.pdf}
}

@article{koles_1991_QuantitativeExtractionTopographic,
  title = {The Quantitative Extraction and Topographic Mapping of the Abnormal Components in the Clinical {{EEG}}},
  author = {Koles, Z.J.},
  year = {1991},
  month = dec,
  journal = {Electroencephalography and Clinical Neurophysiology},
  volume = {79},
  number = {6},
  pages = {440--447},
  issn = {00134694},
  doi = {10.1016/0013-4694(91)90163-X},
  urldate = {2024-07-30},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english}
}

@inproceedings{kolouri_2016_SlicedWassersteinKernels,
  title = {Sliced Wasserstein Kernels for Probability Distributions},
  booktitle = {Proceedings of the {{IEEE}} Conference on Computer Vision and Pattern Recognition ({{CVPR}})},
  author = {Kolouri, Soheil and Zou, Yang and Rohde, Gustavo K.},
  year = {2016},
  month = jun,
  file = {../../Bibliography/Kolouri_2016_Sliced wasserstein kernels for probability distributions.pdf}
}

@inproceedings{kornblith_2019_SimilarityNeuralNetwork,
  title = {Similarity of Neural Network Representations Revisited},
  booktitle = {International Conference on Machine Learning},
  author = {Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  year = {2019},
  pages = {3519--3529},
  organization = {PMLR},
  file = {../../Bibliography/Kornblith_2019_Similarity of neural network representations revisited.pdf}
}

@inproceedings{korotin_2021_ContinuousWasserstein2Barycenter,
  title = {Continuous Wasserstein-2 Barycenter Estimation without Minimax Optimization},
  booktitle = {International Conference on Learning Representations},
  author = {Korotin, Alexander and Li, Lingxiao and Solomon, Justin and Burnaev, Evgeny},
  year = {2021},
  file = {../../Bibliography/Korotin_2021_Continuous wasserstein-2 barycenter estimation without minimax optimization.pdf}
}

@article{korsunsky_2019_FastSensitiveAccurate,
  title = {Fast, Sensitive and Accurate Integration of Single-Cell Data with {{Harmony}}},
  author = {Korsunsky, Ilya and Millard, Nghia and Fan, Jean and Slowikowski, Kamil and Zhang, Fan and Wei, Kevin and Baglaenko, Yuriy and Brenner, Michael and Loh, Po-ru and Raychaudhuri, Soumya},
  year = {2019},
  month = dec,
  journal = {Nature Methods},
  volume = {16},
  number = {12},
  pages = {1289--1296},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/s41592-019-0619-0},
  urldate = {2022-06-20},
  langid = {english},
  file = {../../Bibliography/Korsunsky_2019_Fast, sensitive and accurate integration of single-cell data with Harmony.pdf}
}

@article{kramer_1991_NonlinearPrincipalComponent,
  title = {Nonlinear Principal Component Analysis Using Autoassociative Neural Networks},
  author = {Kramer, Mark A.},
  year = {1991},
  month = feb,
  journal = {AIChE Journal},
  volume = {37},
  number = {2},
  pages = {233--243},
  issn = {0001-1541, 1547-5905},
  doi = {10.1002/aic.690370209},
  urldate = {2023-12-15},
  abstract = {Abstract             Nonlinear principal component analysis is a novel technique for multivariate data analysis, similar to the well-known method of principal component analysis. NLPCA, like PCA, is used to identify and remove correlations among problem variables as an aid to dimensionality reduction, visualization, and exploratory data analysis. While PCA identifies only linear correlations between variables, NLPCA uncovers both linear and nonlinear correlations, without restriction on the character of the nonlinearities present in the data. NLPCA operates by training a feedforward neural network to perform the identity mapping, where the network inputs are reproduced at the output layer. The network contains an internal ``bottleneck'' layer (containing fewer nodes than input or output layers), which forces the network to develop a compact representation of the input data, and two additional hidden layers. The NLPCA method is demonstrated using time-dependent, simulated batch reaction data. Results show that NLPCA successfully reduces dimensionality and produces a feature space map resembling the actual distribution of the underlying system parameters.},
  langid = {english},
  file = {../../Bibliography/Kramer_1991_Nonlinear principal component analysis using autoassociative neural networks.pdf}
}

@book{kreinovich_2024_MachineLearningEconometrics,
  title = {Machine {{Learning}} for {{Econometrics}} and {{Related Topics}}},
  editor = {Kreinovich, Vladik and Sriboonchitta, Songsak and Yamaka, Woraphon},
  year = {2024},
  series = {Studies in {{Systems}}, {{Decision}} and {{Control}}},
  volume = {508},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-43601-7},
  urldate = {2024-06-07},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-031-43600-0 978-3-031-43601-7},
  langid = {english},
  file = {../../Bibliography/Kreinovich_2024_Machine Learning for Econometrics and Related Topics.pdf}
}

@article{kriegeskorte_2008_RepresentationalSimilarityAnalysis,
  title = {Representational Similarity Analysis -- Connecting the Branches of Systems Neuroscience},
  author = {Kriegeskorte, Nikolaus},
  year = {2008},
  journal = {Frontiers in Systems Neuroscience},
  issn = {16625137},
  doi = {10.3389/neuro.06.004.2008},
  urldate = {2022-08-11},
  file = {../../Bibliography/Kriegeskorte_2008_Representational similarity analysis – connecting the branches of systems.pdf}
}

@article{kriegeskorte_2013_RepresentationalGeometryIntegrating,
  title = {Representational Geometry: Integrating Cognition, Computation, and the Brain},
  shorttitle = {Representational Geometry},
  author = {Kriegeskorte, Nikolaus and Kievit, Rogier A.},
  year = {2013},
  month = aug,
  journal = {Trends in Cognitive Sciences},
  volume = {17},
  number = {8},
  pages = {401--412},
  issn = {13646613},
  doi = {10.1016/j.tics.2013.06.007},
  urldate = {2022-08-31},
  langid = {english},
  file = {../../Bibliography/Kriegeskorte_2013_Representational geometry.pdf}
}

@article{kriegeskorte_2021_NeuralTuningRepresentational,
  title = {Neural Tuning and Representational Geometry},
  author = {Kriegeskorte, Nikolaus and Wei, Xue-Xin},
  year = {2021},
  month = nov,
  journal = {Nature Reviews Neuroscience},
  volume = {22},
  number = {11},
  pages = {703--718},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/s41583-021-00502-3},
  urldate = {2022-08-16},
  langid = {english},
  file = {../../Bibliography/Kriegeskorte_2021_Neural tuning and representational geometry.pdf}
}

@article{kruskal_1964_MultidimensionalScalingOptimizing,
  title = {Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis},
  author = {Kruskal, J. B.},
  year = {1964},
  month = mar,
  journal = {Psychometrika},
  volume = {29},
  number = {1},
  pages = {1--27},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02289565},
  urldate = {2022-06-28},
  langid = {english},
  file = {../../Bibliography/Kruskal_1964_Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis.pdf}
}

@article{krzanowski_1987_SelectionVariablesPreserve,
  title = {Selection of {{Variables}} to {{Preserve Multivariate Data Structure}}, {{Using Principal Components}}},
  author = {Krzanowski, W. J.},
  year = {1987},
  journal = {Applied Statistics},
  volume = {36},
  number = {1},
  eprint = {10.2307/2347842},
  eprinttype = {jstor},
  pages = {22},
  issn = {00359254},
  doi = {10.2307/2347842},
  urldate = {2022-07-26},
  file = {../../Bibliography/Krzanowski_1987_Selection of Variables to Preserve Multivariate Data Structure, Using Principal.pdf}
}

@article{kuchroo_2023_SinglecellAnalysisReveals,
  title = {Single-Cell Analysis Reveals Inflammatory Interactions Driving Macular Degeneration},
  author = {Kuchroo, Manik and DiStasio, Marcello and Song, Eric and Calapkulu, Eda and Zhang, Le and Ige, Maryam and Sheth, Amar H. and Majdoubi, Abdelilah and Menon, Madhvi and Tong, Alexander and Godavarthi, Abhinav and Xing, Yu and Gigante, Scott and Steach, Holly and Huang, Jessie and Huguet, Guillaume and Narain, Janhavi and You, Kisung and Mourgkos, George and Dhodapkar, Rahul M. and Hirn, Matthew J. and Rieck, Bastian and Wolf, Guy and Krishnaswamy, Smita and Hafler, Brian P.},
  year = {2023},
  month = may,
  journal = {Nature Communications},
  volume = {14},
  number = {1},
  pages = {2589},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-37025-7},
  urldate = {2023-08-05},
  abstract = {Abstract                            Due to commonalities in pathophysiology, age-related macular degeneration (AMD)~represents a uniquely accessible model to investigate therapies for neurodegenerative diseases, leading us to examine whether pathways of disease progression are shared across neurodegenerative conditions. Here we use single-nucleus RNA sequencing to profile lesions from 11 postmortem human retinas with age-related macular degeneration and 6 control retinas with no history of retinal disease. We create a machine-learning pipeline based on recent advances in data geometry and topology and identify activated glial populations enriched in the early phase of disease. Examining single-cell data from Alzheimer's disease and progressive multiple sclerosis with our pipeline, we find a similar glial activation profile enriched in the early phase of these neurodegenerative diseases. In late-stage age-related macular degeneration, we identify a microglia-to-astrocyte signaling axis mediated by interleukin-1               {$\beta$}               which drives angiogenesis characteristic of disease pathogenesis. We validated this mechanism using in vitro and in vivo assays in mouse, identifying a possible new therapeutic target for AMD and possibly other neurodegenerative conditions. Thus, due to shared glial states, the retina provides a potential system for investigating therapeutic approaches in neurodegenerative diseases.},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/Kuchroo_2023_Single-cell analysis reveals inflammatory interactions driving macular.pdf}
}

@article{kuhn_1962_EfficientAlgorithmNumerical,
  title = {An Efficient Algorithm for the Numerical Solution of the Generalized Weber Problem in Spatial Economics},
  author = {Kuhn, Harold W. and Kuenne, Robert E.},
  year = {1962},
  journal = {Journal of Regional Science},
  volume = {4},
  number = {2},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9787.1962.tb00902.x},
  pages = {21--33},
  doi = {10.1111/j.1467-9787.1962.tb00902.x},
  file = {../../Bibliography/Kuhn_1962_An efficient algorithm for the numerical solution of the generalized weber.pdf}
}

@inproceedings{kulis_2012_RevisitingKmeansNew,
  title = {Revisiting {{K-means}}: {{New}} Algorithms via Bayesian Nonparametrics},
  booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
  author = {Kulis, Brian and Jordan, Michael I.},
  year = {2012},
  series = {{{ICML}}'12},
  pages = {1131--1138},
  publisher = {Omnipress},
  address = {Madison, WI, USA},
  isbn = {978-1-4503-1285-1},
  file = {../../Bibliography/Kulis_2012_Revisiting K-means.pdf}
}

@article{kullback_1951_InformationSufficiency,
  title = {On {{Information}} and {{Sufficiency}}},
  author = {Kullback, S. and Leibler, R. A.},
  year = {1951},
  month = mar,
  journal = {The Annals of Mathematical Statistics},
  volume = {22},
  number = {1},
  pages = {79--86},
  issn = {0003-4851},
  doi = {10.1214/aoms/1177729694},
  urldate = {2022-06-22},
  langid = {english},
  file = {../../Bibliography/Kullback_1951_On Information and Sufficiency.pdf}
}

@article{laine_2021_ACGClinicalGuideline,
  title = {{{ACG Clinical Guideline}}: {{Upper Gastrointestinal}} and {{Ulcer Bleeding}}},
  shorttitle = {{{ACG Clinical Guideline}}},
  author = {Laine, Loren and Barkun, Alan N. and Saltzman, John R. and Martel, Myriam and Leontiadis, Grigorios I.},
  year = {2021},
  month = may,
  journal = {American Journal of Gastroenterology},
  volume = {116},
  number = {5},
  pages = {899--917},
  issn = {0002-9270, 1572-0241},
  doi = {10.14309/ajg.0000000000001245},
  urldate = {2024-06-30},
  abstract = {We performed systematic reviews addressing predefined clinical questions to develop recommendations with the GRADE approach regarding management of patients with overt upper gastrointestinal bleeding. We suggest risk assessment in the emergency department to identify very-low-risk patients (e.g., Glasgow-Blatchford score = 0--1) who may be discharged with outpatient follow-up. For patients hospitalized with upper gastrointestinal bleeding, we suggest red blood cell transfusion at a threshold of 7 g/dL. Erythromycin infusion is suggested before endoscopy, and endoscopy is suggested within 24 hours after presentation. Endoscopic therapy is recommended for ulcers with active spurting or oozing and for nonbleeding visible vessels. Endoscopic therapy with bipolar electrocoagulation, heater probe, and absolute ethanol injection is recommended, and low- to very-low-quality evidence also supports clips, argon plasma coagulation, and soft monopolar electrocoagulation; hemostatic powder spray TC-325 is suggested for actively bleeding ulcers and over-the-scope clips for recurrent ulcer bleeding after previous successful hemostasis. After endoscopic hemostasis, high-dose proton pump inhibitor therapy is recommended continuously or intermittently for 3 days, followed by twice-daily oral proton pump inhibitor for the first 2 weeks of therapy after endoscopy. Repeat endoscopy is suggested for recurrent bleeding, and if endoscopic therapy fails, transcatheter embolization is suggested.},
  langid = {english}
}

@article{lam_2020_HighDimensionalCovariance,
  title = {High-dimensional Covariance Matrix Estimation},
  author = {Lam, Clifford},
  year = {2020},
  month = mar,
  journal = {WIREs Computational Statistics},
  volume = {12},
  number = {2},
  issn = {1939-5108, 1939-0068},
  doi = {10.1002/wics.1485},
  urldate = {2021-10-10},
  langid = {english}
}

@article{lawrence_2005_ProbabilisticNonlinearPrincipal,
  title = {Probabilistic Non-Linear Principal Component Analysis with Gaussian Process Latent Variable Models},
  author = {Lawrence, Neil},
  year = {2005},
  journal = {Journal of Machine Learning Research},
  volume = {6},
  number = {60},
  pages = {1783--1816},
  file = {../../Bibliography/Lawrence_2005_Probabilistic non-linear principal component analysis with gaussian process.pdf}
}

@phdthesis{lawson_1961_ContributionsTheoryLinear,
  title = {Contributions to the {{Theory}} of {{Linear Least Maximum Approximation}}},
  author = {Lawson, Charles Lawrence},
  year = {1961},
  school = {University of California Los Angeles}
}

@misc{lecun_1998_MNISTDatabaseHandwritten,
  title = {The {{MNIST Database}} of {{Handwritten Digits}}},
  author = {LeCun, Yann and Cortes, Corinna and Burges, C.J.},
  year = {1998},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  keywords = {MSc <sub>c</sub>hecked character<sub>r</sub>ecognition mnist network neural}
}

@article{lederman_2018_LearningGeometryCommon,
  title = {Learning the Geometry of Common Latent Variables Using Alternating-Diffusion},
  author = {Lederman, Roy R. and Talmon, Ronen},
  year = {2018},
  month = may,
  journal = {Applied and Computational Harmonic Analysis},
  volume = {44},
  number = {3},
  pages = {509--536},
  issn = {10635203},
  doi = {10.1016/j.acha.2015.09.002},
  urldate = {2023-01-09},
  langid = {english},
  file = {../../Bibliography/Lederman_2018_Learning the geometry of common latent variables using alternating-diffusion.pdf}
}

@article{ledoit_2004_HoneyShrunkSample,
  title = {Honey, {{I Shrunk}} the {{Sample Covariance Matrix}}},
  author = {Ledoit, Olivier and Wolf, Michael},
  year = {2004},
  month = jul,
  journal = {The Journal of Portfolio Management},
  volume = {30},
  number = {4},
  pages = {110--119},
  issn = {0095-4918, 2168-8656},
  doi = {10.3905/jpm.2004.110},
  urldate = {2024-05-03},
  langid = {english},
  file = {../../Bibliography/Ledoit_2004_Honey, I Shrunk the Sample Covariance Matrix.pdf}
}

@article{ledoit_2004_WellconditionedEstimatorLargedimensional,
  title = {A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices},
  author = {Ledoit, Olivier and Wolf, Michael},
  year = {2004},
  month = feb,
  journal = {Journal of Multivariate Analysis},
  volume = {88},
  number = {2},
  pages = {365--411},
  issn = {0047259X},
  doi = {10.1016/S0047-259X(03)00096-4},
  urldate = {2024-05-03},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {../../Bibliography/Ledoit_2004_A well-conditioned estimator for large-dimensional covariance matrices.pdf}
}

@book{lee_1997_RiemannianManifoldsIntroduction,
  title = {Riemannian Manifolds: An Introduction to Curvature},
  shorttitle = {Riemannian Manifolds},
  author = {Lee, John M.},
  year = {1997},
  series = {Graduate Texts in Mathematics},
  number = {176},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-98271-7 978-0-387-98322-6},
  lccn = {QA649 .L397 1997},
  keywords = {Riemannian manifolds}
}

@book{lee_2012_IntroductionSmoothManifolds,
  title = {Introduction to {{Smooth Manifolds}}},
  author = {Lee, John M.},
  year = {2012},
  series = {Graduate {{Texts}} in {{Mathematics}}},
  volume = {218},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4419-9982-5},
  urldate = {2023-12-08},
  isbn = {978-1-4419-9981-8 978-1-4419-9982-5},
  langid = {english},
  file = {../../Bibliography/Lee_2012_Introduction to Smooth Manifolds.pdf}
}

@article{lee_2017_AnalysisStructureFunction,
  title = {Analysis of Structure--Function Network Decoupling in the Brain Systems of Spastic Diplegic Cerebral Palsy},
  author = {Lee, Dongha and Pae, Chongwon and Lee, Jong Doo and Park, Eun Sook and Cho, Sung-Rae and Um, Min-Hee and Lee, Seung-Koo and Oh, Maeng-Keun and Park, Hae-Jeong},
  year = {2017},
  month = oct,
  journal = {Human Brain Mapping},
  volume = {38},
  number = {10},
  pages = {5292--5306},
  issn = {1065-9471, 1097-0193},
  doi = {10.1002/hbm.23738},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Lee_2017_Analysis of structure–function network decoupling in the brain systems of.pdf}
}

@book{lee_2018_IntroductionRiemannianManifolds,
  title = {Introduction to {{Riemannian Manifolds}}},
  author = {Lee, John M.},
  year = {2018},
  series = {Graduate {{Texts}} in {{Mathematics}}},
  edition = {2nd ed. 2018},
  number = {176},
  publisher = {Springer International Publishing : Imprint: Springer},
  address = {Cham},
  doi = {10.1007/978-3-319-91755-9},
  isbn = {978-3-319-91755-9},
  lccn = {516.36},
  keywords = {Differential geometry,Differential Geometry},
  file = {../../Bibliography/Lee_2018_Introduction to Riemannian Manifolds.pdf}
}

@article{lee_2023_BayesianOptimalTwoSample,
  title = {Bayesian {{Optimal Two-Sample Tests}} for {{High-Dimensional Gaussian Populations}}},
  author = {Lee, Kyoungjae and You, Kisung and Lin, Lizhen},
  year = {2023},
  month = jan,
  journal = {Bayesian Analysis},
  volume = {-1},
  number = {-1},
  issn = {1936-0975},
  doi = {10.1214/23-BA1373},
  urldate = {2023-08-05},
  copyright = {All rights reserved},
  file = {../../Bibliography/Lee_2023_Bayesian Optimal Two-Sample Tests for High-Dimensional Gaussian Populations.pdf}
}

@article{legouic_2017_ExistenceConsistencyWasserstein,
  title = {Existence and Consistency of {{Wasserstein}} Barycenters},
  author = {Le~Gouic, Thibaut and Loubes, Jean-Michel},
  year = {2017},
  month = aug,
  journal = {Probability Theory and Related Fields},
  volume = {168},
  number = {3-4},
  pages = {901--917},
  issn = {0178-8051, 1432-2064},
  doi = {10.1007/s00440-016-0727-z},
  urldate = {2021-11-07},
  langid = {english},
  file = {../../Bibliography/Le Gouic_2017_Existence and consistency of Wasserstein barycenters.pdf}
}

@article{legouic_2022_FastConvergenceEmpirical,
  title = {Fast Convergence of Empirical Barycenters in {{Alexandrov}} Spaces and the {{Wasserstein}} Space},
  author = {Le Gouic, Thibaut and Paris, Quentin and Rigollet, Philippe and Stromme, Austin J.},
  year = {2022},
  month = may,
  journal = {Journal of the European Mathematical Society},
  volume = {25},
  number = {6},
  pages = {2229--2250},
  issn = {1435-9855},
  doi = {10.4171/JEMS/1234},
  urldate = {2023-09-04},
  langid = {english},
  file = {../../Bibliography/Le Gouic_2022_Fast convergence of empirical barycenters in Alexandrov spaces and the.pdf}
}

@book{lehmann_2005_TestingStatisticalHypotheses,
  title = {Testing Statistical Hypotheses},
  author = {Lehmann, Erich Leo and Romano, Joseph P.},
  year = {2005},
  series = {Springer Texts in Statistics},
  edition = {3rd ed},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-27605-2},
  langid = {english},
  lccn = {519.56}
}

@article{leonardi_2013_PrincipalComponentsFunctional,
  title = {Principal Components of Functional Connectivity: {{A}} New Approach to Study Dynamic Brain Connectivity during Rest},
  shorttitle = {Principal Components of Functional Connectivity},
  author = {Leonardi, Nora and Richiardi, Jonas and Gschwind, Markus and Simioni, Samanta and Annoni, Jean-Marie and Schluep, Myriam and Vuilleumier, Patrik and Van De Ville, Dimitri},
  year = {2013},
  month = dec,
  journal = {NeuroImage},
  volume = {83},
  pages = {937--950},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2013.07.019},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Leonardi_2013_Principal components of functional connectivity.pdf}
}

@book{ley_2017_ModernDirectionalStatistics,
  title = {Modern {{Directional Statistics}}},
  author = {Ley, Christophe and Verdebout, Thomas},
  year = {2017},
  month = aug,
  edition = {1},
  publisher = {{Chapman and Hall/CRC}},
  doi = {10.1201/9781315119472},
  urldate = {2021-10-29},
  isbn = {978-1-315-11947-2},
  langid = {english}
}

@book{ley_2019_AppliedDirectionalStatistics,
  title = {Applied Directional Statistics},
  editor = {Ley, Christophe and Verdebout, Thomas},
  year = {2019},
  publisher = {CRC Press},
  address = {Boca Raton, FL},
  isbn = {978-1-351-85652-2},
  lccn = {QA276},
  keywords = {Circular data,Mathematical statistics,Spherical data},
  file = {../../Bibliography/Ley_2019_Applied directional statistics.pdf}
}

@inproceedings{li_2007_SpectralClusteringAlgorithm,
  title = {A {{Spectral Clustering Algorithm Based}} on {{Self-Adaption}}},
  booktitle = {2007 {{International Conference}} on {{Machine Learning}} and {{Cybernetics}}},
  author = {Li, Kan and Liu, Yu-Shu},
  year = {2007},
  pages = {3965--3968},
  publisher = {IEEE},
  address = {Hong Kong, China},
  doi = {10.1109/ICMLC.2007.4370839},
  urldate = {2022-07-25},
  isbn = {978-1-4244-0972-3},
  file = {../../Bibliography/Li_2007_A Spectral Clustering Algorithm Based on Self-Adaption.pdf}
}

@article{li_2012_ConstructingAffinityMatrix,
  title = {Constructing Affinity Matrix in Spectral Clustering Based on Neighbor Propagation},
  author = {Li, Xin-Ye and Guo, Li-jie},
  year = {2012},
  month = nov,
  journal = {Neurocomputing},
  volume = {97},
  pages = {125--130},
  issn = {09252312},
  doi = {10.1016/j.neucom.2012.06.023},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Li_2012_Constructing affinity matrix in spectral clustering based on neighbor.pdf}
}

@article{li_2012_TwoSampleTests,
  title = {Two Sample Tests for High-Dimensional Covariance Matrices},
  author = {Li, Jun and Chen, Song Xi},
  year = {2012},
  month = apr,
  journal = {The Annals of Statistics},
  volume = {40},
  number = {2},
  issn = {0090-5364},
  doi = {10.1214/12-AOS993},
  urldate = {2022-07-26},
  file = {../../Bibliography/Li_2012_Two sample tests for high-dimensional covariance matrices.pdf}
}

@inproceedings{li_2020_ContinuousRegularizedWasserstein,
  title = {Continuous Regularized Wasserstein Barycenters},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Li, Lingxiao and Genevay, Aude and Yurochkin, Mikhail and Solomon, Justin M},
  editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M.F. and Lin, H.},
  year = {2020},
  volume = {33},
  pages = {17755--17765},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Li_2020_Continuous regularized wasserstein barycenters.pdf}
}

@article{liao_2014_GeneSelectionUsing,
  title = {Gene {{Selection Using Locality Sensitive Laplacian Score}}},
  author = {Liao, Bo and Jiang, Yan and Liang, Wei and Zhu, Wen and Cai, Lijun and Cao, Zhi},
  year = {2014},
  month = nov,
  journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
  volume = {11},
  number = {6},
  pages = {1146--1156},
  issn = {1545-5963},
  doi = {10.1109/TCBB.2014.2328334},
  urldate = {2022-07-26},
  file = {../../Bibliography/Liao_2014_Gene Selection Using Locality Sensitive Laplacian Score.pdf}
}

@inproceedings{liao_2019_WorstCaseDiscriminativeFeature,
  title = {Worst-{{Case Discriminative Feature Selection}}},
  booktitle = {Proceedings of the {{Twenty-Eighth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Liao, Shuangli and Gao, Quanxue and Nie, Feiping and Liu, Yang and Zhang, Xiangdong},
  year = {2019},
  month = aug,
  pages = {2973--2979},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  address = {Macao, China},
  doi = {10.24963/ijcai.2019/412},
  urldate = {2022-07-26},
  isbn = {978-0-9992411-4-1},
  langid = {english},
  file = {../../Bibliography/Liao_2019_Worst-Case Discriminative Feature Selection.pdf}
}

@article{lim_2021_GrassmannianAffineSubspaces,
  title = {The {{Grassmannian}} of Affine Subspaces},
  author = {Lim, Lek-Heng and Wong, Ken Sze-Wai and Ye, Ke},
  year = {2021},
  month = apr,
  journal = {Foundations of Computational Mathematics},
  volume = {21},
  number = {2},
  pages = {537--574},
  issn = {1615-3375, 1615-3383},
  doi = {10.1007/s10208-020-09459-8},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Lim_2021_The Grassmannian of affine subspaces.pdf}
}

@article{lin_2017_ExtrinsicLocalRegression,
  title = {Extrinsic {{Local Regression}} on {{Manifold-Valued Data}}},
  author = {Lin, Lizhen and St. Thomas, Brian and Zhu, Hongtu and Dunson, David B.},
  year = {2017},
  month = jul,
  journal = {Journal of the American Statistical Association},
  volume = {112},
  number = {519},
  pages = {1261--1273},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2016.1208615},
  urldate = {2022-03-27},
  langid = {english},
  file = {../../Bibliography/Lin_2017_Extrinsic Local Regression on Manifold-Valued Data.pdf}
}

@article{lin_2019_RiemannianGeometrySymmetric,
  title = {Riemannian {{Geometry}} of {{Symmetric Positive Definite Matrices}} via {{Cholesky Decomposition}}},
  author = {Lin, Zhenhua},
  year = {2019},
  month = jan,
  journal = {SIAM Journal on Matrix Analysis and Applications},
  volume = {40},
  number = {4},
  pages = {1353--1370},
  issn = {0895-4798, 1095-7162},
  doi = {10.1137/18M1221084},
  urldate = {2023-12-08},
  langid = {english},
  file = {../../Bibliography/Lin_2019_Riemannian Geometry of Symmetric Positive Definite Matrices via Cholesky.pdf}
}

@misc{lin_2020_RobustOptimizationInference,
  title = {Robust {{Optimization}} and {{Inference}} on {{Manifolds}}},
  author = {Lin, Lizhen and Lazar, Drew and Sarpabayeva, Bayan and Dunson, David B.},
  year = {2020},
  month = jun,
  number = {arXiv:2006.06843},
  eprint = {2006.06843},
  primaryclass = {math, stat},
  publisher = {arXiv},
  urldate = {2023-12-19},
  abstract = {We propose a robust and scalable procedure for general optimization and inference problems on manifolds leveraging the classical idea of `median-of-means' estimation. This is motivated by ubiquitous examples and applications in modern data science in which a statistical learning problem can be cast as an optimization problem over manifolds. Being able to incorporate the underlying geometry for inference while addressing the need for robustness and scalability presents great challenges. We address these challenges by first proving a key lemma that characterizes some crucial properties of geometric medians on manifolds. In turn, this allows us to prove robustness and tighter concentration of our proposed final estimator in a subsequent theorem. This estimator aggregates a collection of subset estimators by taking their geometric median over the manifold. We illustrate bounds on this estimator via calculations in explicit examples. The robustness and scalability of the procedure is illustrated in numerical examples on both simulated and real data sets.},
  archiveprefix = {arXiv},
  keywords = {62R30 62G05,Mathematics - Statistics Theory,Statistics - Methodology},
  file = {../../Bibliography/Lin_2020_Robust Optimization and Inference on Manifolds.pdf;../../../../../Zotero/storage/GHTQVR2S/2006.html}
}

@article{lin_2021_TotalVariationRegularized,
  title = {Total Variation Regularized {{Fr{\'e}chet}} Regression for Metric-Space Valued Data},
  author = {Lin, Zhenhua and M{\"u}ller, Hans-Georg},
  year = {2021},
  month = dec,
  journal = {The Annals of Statistics},
  volume = {49},
  number = {6},
  issn = {0090-5364},
  doi = {10.1214/21-AOS2095},
  urldate = {2022-03-10},
  file = {../../Bibliography/Lin_2021_Total variation regularized Fréchet regression for metric-space valued data.pdf}
}

@inproceedings{lindenbaum_2016_ClusteringBasedMultiView,
  title = {Clustering {{Based}} on {{MultiView Diffusion Maps}}},
  booktitle = {2016 {{IEEE}} 16th {{International Conference}} on {{Data Mining Workshops}} ({{ICDMW}})},
  author = {Lindenbaum, Ofir and Yeredor, Arie and Averbuch, Amir},
  year = {2016},
  month = dec,
  pages = {740--747},
  publisher = {IEEE},
  address = {Barcelona, Spain},
  doi = {10.1109/ICDMW.2016.0109},
  urldate = {2021-11-18},
  isbn = {978-1-5090-5910-2},
  file = {../../Bibliography/Lindenbaum_2016_Clustering Based on MultiView Diffusion Maps.pdf}
}

@article{lindenbaum_2020_MultiviewDiffusionMaps,
  title = {Multi-View Diffusion Maps},
  author = {Lindenbaum, Ofir and Yeredor, Arie and Salhov, Moshe and Averbuch, Amir},
  year = {2020},
  month = mar,
  journal = {Information Fusion},
  volume = {55},
  pages = {127--149},
  issn = {15662535},
  doi = {10.1016/j.inffus.2019.08.005},
  urldate = {2021-11-23},
  langid = {english},
  file = {../../Bibliography/Lindenbaum_2020_Multi-view diffusion maps.pdf}
}

@article{lipor_2021_SubspaceClusteringUsing,
  title = {Subspace Clustering Using Ensembles of {{{\emph{K}}}} -Subspaces},
  author = {Lipor, John and Hong, David and Tan, Yan Shuo and Balzano, Laura},
  year = {2021},
  month = mar,
  journal = {Information and Inference: A Journal of the IMA},
  volume = {10},
  number = {1},
  pages = {73--107},
  issn = {2049-8772},
  doi = {10.1093/imaiai/iaaa031},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Lipor_2021_Subspace clustering using ensembles of iK-i -subspaces.pdf}
}

@article{lipovetsky_2015_MANOVALDAFA,
  title = {{{MANOVA}}, {{LDA}}, and {{FA}} Criteria in Clusters Parameter Estimation},
  author = {Lipovetsky, Stan},
  year = {2015},
  month = dec,
  journal = {Cogent Mathematics},
  volume = {2},
  number = {1},
  pages = {1071013},
  issn = {2331-1835},
  doi = {10.1080/23311835.2015.1071013},
  urldate = {2021-11-02},
  langid = {english},
  file = {../../Bibliography/Lipovetsky_2015_MANOVA, LDA, and FA criteria in clusters parameter estimation.pdf}
}

@inproceedings{liu_2000_NewDistanceMeasure,
  title = {A New Distance Measure for Probability Distribution Function of Mixture Type},
  booktitle = {2000 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}}, and {{Signal Processing}}. {{Proceedings}} ({{Cat}}. {{No}}.{{00CH37100}})},
  author = {Liu, Z. and Huang, Q.},
  year = {2000},
  volume = {1},
  pages = {616--619},
  publisher = {IEEE},
  address = {Istanbul, Turkey},
  doi = {10.1109/ICASSP.2000.862057},
  urldate = {2022-07-26},
  isbn = {978-0-7803-6293-2},
  file = {../../Bibliography/Liu_2000_A new distance measure for probability distribution function of mixture type.pdf}
}

@article{liu_2008_StatisticalSignificanceClustering,
  title = {Statistical {{Significance}} of {{Clustering}} for {{High-Dimension}}, {{Low}}--{{Sample Size Data}}},
  author = {Liu, Yufeng and Hayes, David Neil and Nobel, Andrew and Marron, J. S},
  year = {2008},
  month = sep,
  journal = {Journal of the American Statistical Association},
  volume = {103},
  number = {483},
  pages = {1281--1293},
  issn = {0162-1459, 1537-274X},
  doi = {10.1198/016214508000000454},
  urldate = {2021-09-03},
  langid = {english},
  file = {../../Bibliography/Liu_2008_Statistical Significance of Clustering for High-Dimension, Low–Sample Size Data.pdf}
}

@article{liu_2012_ShapeRetrievalUsing,
  title = {Shape {{Retrieval Using Hierarchical Total Bregman Soft Clustering}}},
  author = {Liu, Meizhu and Vemuri, B. C. and Amari, Shun-Ichi and Nielsen, F.},
  year = {2012},
  month = dec,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {34},
  number = {12},
  pages = {2407--2419},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2012.44},
  urldate = {2022-07-25},
  file = {../../Bibliography/Liu_2012_Shape Retrieval Using Hierarchical Total Bregman Soft Clustering.pdf}
}

@article{liu_2017_SimultaneousTestingMean,
  title = {Simultaneous Testing of Mean Vector and Covariance Matrix for High-Dimensional Data},
  author = {Liu, Zhongying and Liu, Baisen and Zheng, Shurong and Shi, Ning-Zhong},
  year = {2017},
  month = sep,
  journal = {Journal of Statistical Planning and Inference},
  volume = {188},
  pages = {82--93},
  issn = {03783758},
  doi = {10.1016/j.jspi.2017.03.009},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Liu_2017_Simultaneous testing of mean vector and covariance matrix for high-dimensional.pdf}
}

@article{liu_2021_MultiKAutomatedTool,
  title = {{{MultiK}}: An Automated Tool to Determine Optimal Cluster Numbers in Single-Cell {{RNA}} Sequencing Data},
  shorttitle = {{{MultiK}}},
  author = {Liu, Siyao and Thennavan, Aatish and Garay, Joseph P. and Marron, J. S. and Perou, Charles M.},
  year = {2021},
  month = dec,
  journal = {Genome Biology},
  volume = {22},
  number = {1},
  pages = {232},
  issn = {1474-760X},
  doi = {10.1186/s13059-021-02445-5},
  urldate = {2021-09-03},
  langid = {english},
  file = {../../Bibliography/Liu_2021_MultiK.pdf}
}

@article{lloyd_1982_LeastSquaresQuantization,
  title = {Least Squares Quantization in {{PCM}}},
  author = {Lloyd, S.},
  year = {1982},
  month = mar,
  journal = {IEEE Transactions on Information Theory},
  volume = {28},
  number = {2},
  pages = {129--137},
  issn = {0018-9448},
  doi = {10.1109/TIT.1982.1056489},
  urldate = {2021-10-02},
  langid = {english},
  file = {../../Bibliography/Lloyd_1982_Least squares quantization in PCM.pdf}
}

@article{lock_2013_JointIndividualVariation,
  title = {Joint and Individual Variation Explained ({{JIVE}}) for Integrated Analysis of Multiple Data Types},
  author = {Lock, Eric F. and Hoadley, Katherine A. and Marron, J. S. and Nobel, Andrew B.},
  year = {2013},
  month = mar,
  journal = {The Annals of Applied Statistics},
  volume = {7},
  number = {1},
  issn = {1932-6157},
  doi = {10.1214/12-AOAS597},
  urldate = {2021-10-07},
  file = {../../Bibliography/Lock_2013_Joint and individual variation explained (JIVE) for integrated analysis of.pdf}
}

@incollection{lombardi_2011_MinimumNeighborDistance,
  title = {Minimum {{Neighbor Distance Estimators}} of {{Intrinsic Dimension}}},
  booktitle = {Machine {{Learning}} and {{Knowledge Discovery}} in {{Databases}}},
  author = {Lombardi, Gabriele and Rozza, Alessandro and Ceruti, Claudio and Casiraghi, Elena and Campadelli, Paola},
  editor = {Gunopulos, Dimitrios and Hofmann, Thomas and Malerba, Donato and Vazirgiannis, Michalis},
  year = {2011},
  volume = {6912},
  pages = {374--389},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-23783-6_24},
  urldate = {2022-07-25},
  isbn = {978-3-642-23782-9 978-3-642-23783-6}
}

@inproceedings{lopes_2011_MorePowerfulTwosample,
  title = {A More Powerful Two-Sample Test in High Dimensions Using Random Projection},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Lopes, Miles and Jacob, Laurent and Wainwright, Martin J},
  editor = {{Shawe-Taylor}, J. and Zemel, R. and Bartlett, P. and Pereira, F. and Weinberger, K.Q.},
  year = {2011},
  volume = {24},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Lopes_2011_A more powerful two-sample test in high dimensions using random projection.pdf}
}

@inproceedings{lu_2007_FeatureSelectionUsing,
  title = {Feature Selection Using Principal Feature Analysis},
  booktitle = {Proceedings of the 15th International Conference on {{Multimedia}}  - {{MULTIMEDIA}} '07},
  author = {Lu, Yijuan and Cohen, Ira and Zhou, Xiang Sean and Tian, Qi},
  year = {2007},
  pages = {301},
  publisher = {ACM Press},
  address = {Augsburg, Germany},
  doi = {10.1145/1291233.1291297},
  urldate = {2022-07-05},
  isbn = {978-1-59593-702-5},
  langid = {english}
}

@incollection{lu_2012_RobustEfficientSubspace,
  title = {Robust and {{Efficient Subspace Segmentation}} via {{Least Squares Regression}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2012},
  author = {Lu, Can-Yi and Min, Hai and Zhao, Zhong-Qiu and Zhu, Lin and Huang, De-Shuang and Yan, Shuicheng},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
  year = {2012},
  volume = {7578},
  pages = {347--360},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-33786-4_26},
  urldate = {2022-07-26},
  isbn = {978-3-642-33785-7 978-3-642-33786-4},
  langid = {english}
}

@book{luenberger_2008_LinearNonlinearProgramming,
  title = {Linear and Nonlinear Programming},
  author = {Luenberger, David G. and Ye, Yinyu},
  year = {2008},
  series = {International Series in Operations Research and Management Science},
  edition = {3. ed},
  number = {116},
  publisher = {Springer},
  address = {New York, NY},
  isbn = {978-1-4419-4504-4 978-0-387-74502-2},
  langid = {english}
}

@inproceedings{luo_2008_PCABasedUnsupervised,
  title = {A {{PCA Based Unsupervised Feature Selection Algorithm}}},
  booktitle = {2008 {{Second International Conference}} on {{Genetic}} and {{Evolutionary Computing}}},
  author = {Luo, Yihui and Xiong, Shuchu and Wang, Sichun},
  year = {2008},
  month = sep,
  pages = {299--302},
  publisher = {IEEE},
  address = {Jinzhou, China},
  doi = {10.1109/WGEC.2008.109},
  urldate = {2022-07-05},
  isbn = {978-0-7695-3334-6},
  file = {../../Bibliography/Luo_2008_A PCA Based Unsupervised Feature Selection Algorithm.pdf}
}

@article{luo_2021_GeometricCharacteristicsWasserstein,
  title = {Geometric {{Characteristics}} of the {{Wasserstein Metric}} on {{SPD}}(n) and {{Its Applications}} on {{Data Processing}}},
  author = {Luo, Yihao and Zhang, Shiqiang and Cao, Yueqi and Sun, Huafei},
  year = {2021},
  month = sep,
  journal = {Entropy},
  volume = {23},
  number = {9},
  pages = {1214},
  issn = {1099-4300},
  doi = {10.3390/e23091214},
  urldate = {2021-10-25},
  abstract = {The Wasserstein distance, especially among symmetric positive-definite matrices, has broad and deep influences on the development of artificial intelligence (AI) and other branches of computer science. In this paper, by involving the Wasserstein metric on SPD(n), we obtain computationally feasible expressions for some geometric quantities, including geodesics, exponential maps, the Riemannian connection, Jacobi fields and curvatures, particularly the scalar curvature. Furthermore, we discuss the behavior of geodesics and prove that the manifold is globally geodesic convex. Finally, we design algorithms for point cloud denoising and edge detecting of a polluted image based on the Wasserstein curvature on SPD(n). The experimental results show the efficiency and robustness of our curvature-based methods.},
  langid = {english},
  file = {../../Bibliography/Luo_2021_Geometric Characteristics of the Wasserstein Metric on SPD(n) and Its.pdf}
}

@book{ma_2012_ManifoldLearningTheory,
  title = {Manifold Learning Theory and Applications},
  editor = {Ma, Yunqian and Fu, Yun},
  year = {2012},
  publisher = {CRC ; Taylor \& Francis [distributor]},
  address = {Boca Raton, Fla. : London},
  isbn = {978-1-4398-7109-6},
  lccn = {QA613 .M32 2012},
  keywords = {Manifolds (Mathematics)},
  annotation = {OCLC: ocn751753027}
}

@article{maa_1996_ReducingMultidimensionalTwosample,
  title = {Reducing Multidimensional Two-Sample Data to One-Dimensional Interpoint Comparisons},
  author = {Maa, Jen-Fue and Pearl, Dennis K. and Bartoszy{\'n}ski, Robert},
  year = {1996},
  month = jun,
  journal = {The Annals of Statistics},
  volume = {24},
  number = {3},
  issn = {0090-5364},
  doi = {10.1214/aos/1032526956},
  urldate = {2021-10-02},
  file = {../../Bibliography/Maa_1996_Reducing multidimensional two-sample data to one-dimensional interpoint.pdf}
}

@inproceedings{macqueen_1967_MethodsClassificationAnalysis,
  title = {Some {{Methods}} for {{Classification}} and {{Analysis}} of {{Multivariate Observations}}},
  booktitle = {Proc. of the Fifth Berkeley Symposium on Mathematical Statistics and Probability},
  author = {MacQueen, J. B.},
  editor = {Cam, L. M. Le and Neyman, J.},
  year = {1967},
  volume = {1},
  pages = {281--297},
  publisher = {University of California Press},
  keywords = {kmeans clustering},
  file = {../../Bibliography/MacQueen_1967_Some Methods for Classification and Analysis of Multivariate Observations.pdf}
}

@inproceedings{makkuva_2020_OptimalTransportMapping,
  title = {Optimal Transport Mapping via Input Convex Neural Networks},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  author = {Makkuva, Ashok and Taghvaei, Amirhossein and Oh, Sewoong and Lee, Jason},
  editor = {III, Hal Daum{\'e} and Singh, Aarti},
  year = {2020-07-13/2020-07-18},
  series = {Proceedings of Machine Learning Research},
  volume = {119},
  pages = {6672--6681},
  publisher = {PMLR},
  abstract = {In this paper, we present a novel and principled approach to learn the optimal transport between two distributions, from samples. Guided by the optimal transport theory, we learn the optimal Kantorovich potential which induces the optimal transport map. This involves learning two convex functions, by solving a novel minimax optimization. Building upon recent advances in the field of input convex neural networks, we propose a new framework to estimate the optimal transport mapping as the gradient of a convex function that is trained via minimax optimization. Numerical experiments confirm the accuracy of the learned transport map. Our approach can be readily used to train a deep generative model. When trained between a simple distribution in the latent space and a target distribution, the learned optimal transport map acts as a deep generative model. Although scaling this to a large dataset is challenging, we demonstrate two important strengths over standard adversarial training: robustness and discontinuity. As we seek the optimal transport, the learned generative model provides the same mapping regardless of how we initialize the neural networks. Further, a gradient of a neural network can easily represent discontinuous mappings, unlike standard neural networks that are constrained to be continuous. This allows the learned transport map to match any target distribution with many discontinuous supports and achieve sharp boundaries.},
  file = {../../Bibliography/Makkuva_2020_Optimal transport mapping via input convex neural networks2.pdf}
}

@inproceedings{makkuva_2020_OptimalTransportMappinga,
  title = {Optimal Transport Mapping via Input Convex Neural Networks},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  author = {Makkuva, Ashok and Taghvaei, Amirhossein and Oh, Sewoong and Lee, Jason},
  editor = {III, Hal Daum{\'e} and Singh, Aarti},
  year = {2020-07-13/2020-07-18},
  series = {Proceedings of Machine Learning Research},
  volume = {119},
  pages = {6672--6681},
  publisher = {PMLR},
  abstract = {In this paper, we present a novel and principled approach to learn the optimal transport between two distributions, from samples. Guided by the optimal transport theory, we learn the optimal Kantorovich potential which induces the optimal transport map. This involves learning two convex functions, by solving a novel minimax optimization. Building upon recent advances in the field of input convex neural networks, we propose a new framework to estimate the optimal transport mapping as the gradient of a convex function that is trained via minimax optimization. Numerical experiments confirm the accuracy of the learned transport map. Our approach can be readily used to train a deep generative model. When trained between a simple distribution in the latent space and a target distribution, the learned optimal transport map acts as a deep generative model. Although scaling this to a large dataset is challenging, we demonstrate two important strengths over standard adversarial training: robustness and discontinuity. As we seek the optimal transport, the learned generative model provides the same mapping regardless of how we initialize the neural networks. Further, a gradient of a neural network can easily represent discontinuous mappings, unlike standard neural networks that are constrained to be continuous. This allows the learned transport map to match any target distribution with many discontinuous supports and achieve sharp boundaries.},
  file = {../../Bibliography/Makkuva_2020_Optimal transport mapping via input convex neural networks.pdf}
}

@article{malago_2018_WassersteinRiemannianGeometry,
  title = {Wasserstein {{Riemannian}} Geometry of {{Gaussian}} Densities},
  author = {Malag{\`o}, Luigi and Montrucchio, Luigi and Pistone, Giovanni},
  year = {2018},
  month = dec,
  journal = {Information Geometry},
  volume = {1},
  number = {2},
  pages = {137--179},
  issn = {2511-2481, 2511-249X},
  doi = {10.1007/s41884-018-0014-4},
  urldate = {2021-11-09},
  langid = {english},
  file = {../../Bibliography/Malagò_2018_Wasserstein Riemannian geometry of Gaussian densities.pdf}
}

@article{malliaros_2013_ClusteringCommunityDetection,
  title = {Clustering and Community Detection in Directed Networks: {{A}} Survey},
  shorttitle = {Clustering and Community Detection in Directed Networks},
  author = {Malliaros, Fragkiskos D. and Vazirgiannis, Michalis},
  year = {2013},
  month = dec,
  journal = {Physics Reports},
  volume = {533},
  number = {4},
  pages = {95--142},
  issn = {03701573},
  doi = {10.1016/j.physrep.2013.08.002},
  urldate = {2024-08-30},
  langid = {english},
  file = {../../Bibliography/malliaros_2013_clustering and community detection in directed networks.pdf}
}

@inproceedings{maman_2019_DomainAdaptationUsing,
  title = {Domain {{Adaptation Using Riemannian Geometry}} of {{Spd Matrices}}},
  booktitle = {{{ICASSP}} 2019 - 2019 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Maman, Gal and Yair, Or and Eytan, Danny and Talmon, Ronen},
  year = {2019},
  month = may,
  pages = {4464--4468},
  publisher = {IEEE},
  address = {Brighton, United Kingdom},
  doi = {10.1109/ICASSP.2019.8682989},
  urldate = {2024-01-06},
  isbn = {978-1-4799-8131-1},
  file = {../../Bibliography/Maman_2019_Domain Adaptation Using Riemannian Geometry of Spd Matrices.pdf}
}

@book{manning_2008_IntroductionInformationRetrieval,
  title = {Introduction to Information Retrieval},
  author = {Manning, Christopher D. and Raghavan, Prabhakar and Sch{\"u}tze, Hinrich},
  year = {2008},
  publisher = {Cambridge University Press},
  address = {New York},
  isbn = {978-0-521-86571-5},
  lccn = {QA76.9.T48 M26 2008},
  keywords = {Document clustering,Information retrieval,Semantic Web,Text processing (Computer science)},
  annotation = {OCLC: ocn190786122}
}

@article{manole_2021_PluginEstimationSmooth,
  title = {Plugin {{Estimation}} of {{Smooth Optimal Transport Maps}}},
  author = {Manole, Tudor and Balakrishnan, Sivaraman and {Niles-Weed}, Jonathan and Wasserman, Larry},
  year = {2021},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2107.12364},
  urldate = {2022-09-07},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Computer and information sciences,FOS: Mathematics,Machine Learning (stat.ML),Statistics Theory (math.ST)},
  file = {../../Bibliography/Manole_2021_Plugin Estimation of Smooth Optimal Transport Maps.pdf}
}

@article{mantegna_1999_HierarchicalStructureFinancial,
  title = {Hierarchical Structure in Financial Markets},
  author = {Mantegna, R.N.},
  year = {1999},
  month = sep,
  journal = {The European Physical Journal B},
  volume = {11},
  number = {1},
  pages = {193--197},
  issn = {1434-6028},
  doi = {10.1007/s100510050929},
  urldate = {2022-09-12},
  langid = {english},
  file = {../../Bibliography/Mantegna_1999_Hierarchical structure in financial markets.pdf}
}

@book{mardia_2000_DirectionalStatistics,
  title = {Directional Statistics},
  author = {Mardia, K. V. and Jupp, Peter E.},
  year = {2000},
  series = {Wiley Series in Probability and Statistics},
  publisher = {J. Wiley},
  address = {Chichester ; New York},
  isbn = {978-0-471-95333-3},
  lccn = {QA276 .J864 2000},
  keywords = {Distribution (Probability theory),Mathematical statistics,Sampling (Statistics)},
  file = {../../Bibliography/Mardia_2000_Directional statistics.pdf}
}

@article{marozzi_2020_InterpointDistanceTests,
  title = {Interpoint Distance Tests for High-Dimensional Comparison Studies},
  author = {Marozzi, Marco and Mukherjee, Amitava and Kalina, Jan},
  year = {2020},
  month = mar,
  journal = {Journal of Applied Statistics},
  volume = {47},
  number = {4},
  pages = {653--665},
  issn = {0266-4763, 1360-0532},
  doi = {10.1080/02664763.2019.1649374},
  urldate = {2022-07-25},
  langid = {english}
}

@book{marron_2021_ObjectOrientedData,
  title = {Object {{Oriented Data Analysis}}},
  author = {Marron, James Stephen and Dryden, I. L.},
  year = {2021},
  publisher = {Taylor \& Francis Group, LLC},
  address = {Boca Raton},
  isbn = {978-0-8153-9282-8 978-1-03-211480-4},
  lccn = {QA76.9.O35 M369 2021},
  keywords = {Methodology,Object-oriented methods (Computer science),Quantitative research,Statistics}
}

@misc{martens_2020_NewInsightsPerspectives,
  title = {New Insights and Perspectives on the Natural Gradient Method},
  author = {Martens, James},
  year = {2020},
  month = sep,
  number = {arXiv:1412.1193},
  eprint = {1412.1193},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2022-07-25},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {../../Bibliography/Martens_2020_New insights and perspectives on the natural gradient method.pdf}
}

@inproceedings{marti_2016_OptimalTransportVs,
  title = {Optimal Transport vs. {{Fisher-Rao}} Distance between Copulas for Clustering Multivariate Time Series},
  booktitle = {2016 {{IEEE Statistical Signal Processing Workshop}} ({{SSP}})},
  author = {Marti, G. and Andler, S. and Nielsen, F. and Donnat, P.},
  year = {2016},
  month = jun,
  pages = {1--5},
  publisher = {IEEE},
  address = {Palma de Mallorca, Spain},
  doi = {10.1109/SSP.2016.7551770},
  urldate = {2023-09-04},
  isbn = {978-1-4673-7803-1},
  file = {../../Bibliography/Marti_2016_Optimal transport vs.pdf}
}

@article{martin_2020_ManifoldOptimInterfaceROPTLIB,
  title = {{{ManifoldOptim}}: {{An R}} Interface to the {{ROPTLIB}} Library for Riemannian Manifold Optimization},
  author = {Martin, Sean and Raim, Andrew M. and Huang, Wen and Adragni, Kofi P.},
  year = {2020},
  journal = {Journal of Statistical Software},
  volume = {93},
  number = {1},
  pages = {1--32},
  doi = {10.18637/jss.v093.i01}
}

@misc{martinez-taboada_2023_EfficientDoublyRobustTest,
  title = {An {{Efficient Doubly-Robust Test}} for the {{Kernel Treatment Effect}}},
  author = {{Martinez-Taboada}, Diego and Ramdas, Aaditya and Kennedy, Edward H.},
  year = {2023},
  month = oct,
  number = {arXiv:2304.13237},
  eprint = {2304.13237},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2023-12-16},
  abstract = {The average treatment effect, which is the difference in expectation of the counterfactuals, is probably the most popular target effect in causal inference with binary treatments. However, treatments may have effects beyond the mean, for instance decreasing or increasing the variance. We propose a new kernel-based test for distributional effects of the treatment. It is, to the best of our knowledge, the first kernel-based, doubly-robust test with provably valid type-I error. Furthermore, our proposed algorithm is computationally efficient, avoiding the use of permutations.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  file = {../../Bibliography/Martinez-Taboada_2023_An Efficient Doubly-Robust Test for the Kernel Treatment Effect.pdf;../../../../../Zotero/storage/RQICXZWY/2304.html}
}

@manual{MATLAB_R2021b,
  type = {Manual},
  title = {{{MATLAB}} - {{The Language}} of {{Technical Computing}}, {{Version R2021b}}},
  author = {{The MathWorks Inc.}},
  year = {2021},
  address = {Natick, Massachusetts}
}

@article{mccann_1997_ConvexityPrincipleInteracting,
  title = {A {{Convexity Principle}} for {{Interacting Gases}}},
  author = {McCann, Robert J.},
  year = {1997},
  month = jun,
  journal = {Advances in Mathematics},
  volume = {128},
  number = {1},
  pages = {153--179},
  issn = {00018708},
  doi = {10.1006/aima.1997.1634},
  urldate = {2021-11-09},
  langid = {english},
  file = {../../Bibliography/McCann_1997_A Convexity Principle for Interacting Gases.pdf}
}

@article{mccann_2001_PolarFactorizationMaps,
  title = {Polar Factorization of Maps on {{Riemannian}} Manifolds:},
  shorttitle = {Polar Factorization of Maps on {{Riemannian}} Manifolds},
  author = {McCann, R.J.},
  year = {2001},
  month = aug,
  journal = {Geometric and Functional Analysis},
  volume = {11},
  number = {3},
  pages = {589--608},
  issn = {1016-443X},
  doi = {10.1007/PL00001679},
  urldate = {2024-08-23},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {../../Bibliography/mccann_2001_polar factorization of maps on riemannian manifolds.pdf}
}

@book{mccullagh_1998_GeneralizedLinearModels,
  title = {Generalized Linear Models},
  author = {McCullagh, P. and Nelder, John A.},
  year = {1998},
  series = {Monographs on Statistics and Applied Probability},
  edition = {2nd ed},
  number = {37},
  publisher = {Chapman \& Hall/CRC},
  address = {Boca Raton},
  isbn = {978-0-412-31760-6},
  lccn = {QA276 .M38 1998},
  keywords = {Linear models (Statistics)}
}

@article{mclachlan_2019_FiniteMixtureModels,
  title = {Finite {{Mixture Models}}},
  author = {McLachlan, Geoffrey J. and Lee, Sharon X. and Rathnayake, Suren I.},
  year = {2019},
  month = mar,
  journal = {Annual Review of Statistics and Its Application},
  volume = {6},
  number = {1},
  pages = {355--378},
  issn = {2326-8298, 2326-831X},
  doi = {10.1146/annurev-statistics-031017-100325},
  urldate = {2022-02-22},
  langid = {english},
  file = {../../Bibliography/McLachlan_2019_Finite Mixture Models.pdf}
}

@inproceedings{mcqueen_2016_NearlyIsometricEmbedding,
  title = {Nearly Isometric Embedding by Relaxation},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {McQueen, James and Meila, Marina and Joncas, Dominique},
  editor = {Lee, D. and Sugiyama, M. and Luxburg, U. and Guyon, I. and Garnett, R.},
  year = {2016},
  volume = {29},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/McQueen_2016_Nearly isometric embedding by relaxation.pdf}
}

@article{mejia_2018_ImprovedEstimationSubjectlevel,
  title = {Improved Estimation of Subject-Level Functional Connectivity Using Full and Partial Correlation with Empirical {{Bayes}} Shrinkage},
  author = {Mejia, Amanda F. and Nebel, Mary Beth and Barber, Anita D. and Choe, Ann S. and Pekar, James J. and Caffo, Brian S. and Lindquist, Martin A.},
  year = {2018},
  month = may,
  journal = {NeuroImage},
  volume = {172},
  pages = {478--491},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2018.01.029},
  urldate = {2024-08-15},
  langid = {english},
  file = {../../Bibliography/Mejia_2018_Improved estimation of subject-level functional connectivity using full and.pdf}
}

@inproceedings{meng_2019_LargescaleOptimalTransport,
  title = {Large-Scale Optimal Transport Map Estimation Using Projection Pursuit},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Meng, Cheng and Ke, Yuan and Zhang, Jingyi and Zhang, Mengrui and Zhong, Wenxuan and Ma, Ping},
  editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and {dAlch{\'e}-Buc}, F. and Fox, E. and Garnett, R.},
  year = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Meng_2019_Large-scale optimal transport map estimation using projection pursuit.pdf}
}

@article{metropolis_1953_EquationStateCalculations,
  title = {Equation of {{State Calculations}} by {{Fast Computing Machines}}},
  author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
  year = {1953},
  month = jun,
  journal = {The Journal of Chemical Physics},
  volume = {21},
  number = {6},
  pages = {1087--1092},
  issn = {0021-9606, 1089-7690},
  doi = {10.1063/1.1699114},
  urldate = {2022-08-19},
  langid = {english},
  file = {../../Bibliography/Metropolis_1953_Equation of State Calculations by Fast Computing Machines.pdf}
}

@incollection{miller_2023_SphericalGraphDrawing,
  title = {Spherical {{Graph Drawing}} by {{Multi-dimensional Scaling}}},
  booktitle = {Graph {{Drawing}} and {{Network Visualization}}},
  author = {Miller, Jacob and Huroyan, Vahan and Kobourov, Stephen},
  editor = {Angelini, Patrizio and Von Hanxleden, Reinhard},
  year = {2023},
  volume = {13764},
  pages = {77--92},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-22203-0_7},
  urldate = {2023-05-11},
  isbn = {978-3-031-22202-3 978-3-031-22203-0},
  langid = {english}
}

@article{minas_2014_DistancebasedAnalysisVariance,
  title = {Distance-Based Analysis of Variance: {{Approximate}} Inference: {{Distance-Based Analysis}} of {{Variance}}},
  shorttitle = {Distance-Based Analysis of Variance},
  author = {Minas, Christopher and Montana, Giovanni},
  year = {2014},
  month = dec,
  journal = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  volume = {7},
  number = {6},
  pages = {450--470},
  issn = {19321864},
  doi = {10.1002/sam.11227},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Minas_2014_Distance-based analysis of variance.pdf}
}

@inproceedings{minka_2000_AutomaticChoiceDimensionality,
  title = {Automatic Choice of Dimensionality for {{PCA}}},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Minka, Thomas},
  editor = {Leen, T. and Dietterich, T. and Tresp, V.},
  year = {2000},
  volume = {13},
  publisher = {MIT Press},
  file = {../../Bibliography/Minka_2000_Automatic choice of dimensionality for PCA.pdf}
}

@techreport{minka_2000_EstimatingDirichletDistribution,
  title = {Estimating a Dirichlet Distribution},
  author = {Minka, Thomas P.},
  year = {2000},
  file = {../../Bibliography/Minka_2000_Estimating a dirichlet distribution.pdf}
}

@inproceedings{minsker_2014_ScalableRobustBayesian,
  title = {Scalable and Robust Bayesian Inference via the Median Posterior},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning},
  author = {Minsker, Stanislav and Srivastava, Sanvesh and Lin, Lizhen and Dunson, David},
  editor = {Xing, Eric P. and Jebara, Tony},
  year = {2014-06-22/2014-06-24},
  series = {Proceedings of Machine Learning Research},
  volume = {32},
  pages = {1656--1664},
  publisher = {PMLR},
  address = {Bejing, China},
  abstract = {Many Bayesian learning methods for massive data benefit from working with small subsets of observations. In particular, significant progress has been made in scalable Bayesian learning via stochastic approximation. However, Bayesian learning methods in distributed computing environments are often problem- or distribution-specific and use ad hoc techniques. We propose a novel general approach to Bayesian inference that is scalable and robust to corruption in the data. Our technique is based on the idea of splitting the data into several non-overlapping subgroups, evaluating the posterior distribution given each independent subgroup, and then combining the results. The main novelty is the proposed aggregation step which is based on finding the geometric median of posterior distributions. We present both theoretical and numerical results illustrating the advantages of our approach.},
  pdf = {http://proceedings.mlr.press/v32/minsker14.pdf},
  file = {../../Bibliography/Minsker_2014_Scalable and robust bayesian inference via the median posterior.pdf}
}

@article{minsker_2015_GeometricMedianRobust,
  title = {Geometric Median and Robust Estimation in {{Banach}} Spaces},
  author = {Minsker, Stanislav},
  year = {2015},
  month = nov,
  journal = {Bernoulli},
  volume = {21},
  number = {4},
  issn = {1350-7265},
  doi = {10.3150/14-BEJ645},
  urldate = {2021-10-13},
  file = {../../Bibliography/Minsker_2015_Geometric median and robust estimation in Banach spaces.pdf}
}

@article{miyamoto_2024_ClosedFormExpressionsFisherRao,
  title = {On {{Closed-Form Expressions}} for the {{Fisher-Rao Distance}}},
  author = {Miyamoto, Henrique K. and Meneghetti, F{\'a}bio C. C. and Pinele, Julianna and Costa, Sueli I. R.},
  year = {2024},
  month = nov,
  journal = {Information Geometry},
  volume = {7},
  number = {2},
  eprint = {2304.14885},
  primaryclass = {math},
  pages = {311--354},
  issn = {2511-2481, 2511-249X},
  doi = {10.1007/s41884-024-00143-2},
  urldate = {2025-02-04},
  abstract = {The Fisher-Rao distance is the geodesic distance between probability distributions in a statistical manifold equipped with the Fisher metric, which is a natural choice of Riemannian metric on such manifolds. It has recently been applied to supervised and unsupervised problems in machine learning, in various contexts. Finding closed-form expressions for the Fisher-Rao distance is generally a non-trivial task, and those are only available for a few families of probability distributions. In this survey, we collect examples of closed-form expressions for the Fisher-Rao distance of both discrete and continuous distributions, aiming to present them in a unified and accessible language. In doing so, we also: illustrate the relation between negative multinomial distributions and the hyperbolic model, include a few new examples, and write a few more in the standard form of elliptical distributions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Theory,Mathematics - Differential Geometry,Mathematics - Information Theory,Mathematics - Statistics Theory,Statistics - Statistics Theory},
  file = {../../Bibliography/miyamoto_2024_on closed-form expressions for the fisher-rao distance.pdf;../../../../../Zotero/storage/EUKDVY6N/2304.html}
}

@article{moakher_2005_DifferentialGeometricApproach,
  title = {A {{Differential Geometric Approach}} to the {{Geometric Mean}} of {{Symmetric Positive-Definite Matrices}}},
  author = {Moakher, Maher},
  year = {2005},
  month = jan,
  journal = {SIAM Journal on Matrix Analysis and Applications},
  volume = {26},
  number = {3},
  pages = {735--747},
  issn = {0895-4798, 1095-7162},
  doi = {10.1137/S0895479803436937},
  urldate = {2021-09-27},
  langid = {english},
  file = {../../Bibliography/Moakher_2005_A Differential Geometric Approach to the Geometric Mean of Symmetric.pdf}
}

@incollection{moakher_2006_SymmetricPositiveDefiniteMatrices,
  title = {Symmetric {{Positive-Definite Matrices}}: {{From Geometry}} to {{Applications}} and {{Visualization}}},
  shorttitle = {Symmetric {{Positive-Definite Matrices}}},
  booktitle = {Visualization and {{Processing}} of {{Tensor Fields}}},
  author = {Moakher, Maher and Batchelor, Philipp G.},
  editor = {Weickert, Joachim and Hagen, Hans},
  year = {2006},
  pages = {285--298},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-31272-2_17},
  urldate = {2022-07-01},
  isbn = {978-3-540-25032-6 978-3-540-31272-7},
  langid = {english},
  file = {../../Bibliography/Moakher_2006_Symmetric Positive-Definite Matrices.pdf}
}

@book{molnar_2022_InterpretableMachineLearning,
  title = {Interpretable Machine Learning: A Guide for Making Black Box Models Explainable},
  shorttitle = {Interpretable Machine Learning},
  author = {Molnar, Christoph},
  year = {2022},
  edition = {Second edition},
  publisher = {Christoph Molnar},
  address = {Munich, Germany},
  isbn = {9798411463330},
  langid = {english}
}

@book{monge_1781_MemoireTheorieDeblais,
  title = {M{\'e}moire Sur La Th{\'e}orie Des D{\'e}blais et Des Remblais},
  author = {Monge, Gaspard},
  year = {1781},
  publisher = {De l'Imprimerie Royale},
  added-at = {2017-02-08T16:54:11.000+0100},
  biburl = {https://www.bibsonomy.org/bibtex/27501e977c23a6c608ed3d4cfc61f7141/becker},
  description = {Mentioned by Filippo Simini, Marta C. Gonz{\'a}lez, Amos Maritan, and Albert-L{\'a}szl{\'o} Barab{\'a}si in "A universal model for mobility and migration patterns" to mention the gravity model.},
  interhash = {1473bca93a3776814a74f95187ff7f12},
  intrahash = {7501e977c23a6c608ed3d4cfc61f7141},
  keywords = {diss geo gravity inthesis spatial},
  timestamp = {2017-02-08T17:00:30.000+0100}
}

@article{monti_2003_ConsensusClusteringResamplingBased,
  title = {Consensus {{Clustering}}: {{A Resampling-Based Method}} for {{Class Discovery}} and {{Visualization}} of {{Gene Expression Microarray Data}}},
  author = {Monti, Stefano and Tamayo, Pablo and Mesirov, Jill and Golub, Todd},
  year = {2003},
  journal = {Machine Learning},
  volume = {52},
  number = {1/2},
  pages = {91--118},
  issn = {08856125},
  doi = {10.1023/A:1023949509487},
  urldate = {2021-09-03},
  file = {../../Bibliography/Monti_2003_Consensus Clustering.pdf}
}

@article{monti_2014_EstimatingTimevaryingBrain,
  title = {Estimating Time-Varying Brain Connectivity Networks from Functional {{MRI}} Time Series},
  author = {Monti, Ricardo Pio and Hellyer, Peter and Sharp, David and Leech, Robert and Anagnostopoulos, Christoforos and Montana, Giovanni},
  year = {2014},
  month = dec,
  journal = {NeuroImage},
  volume = {103},
  pages = {427--443},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2014.07.033},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Monti_2014_Estimating time-varying brain connectivity networks from functional MRI time.pdf}
}

@article{moon_2019_VisualizingStructureTransitions,
  title = {Visualizing Structure and Transitions in High-Dimensional Biological Data},
  author = {Moon, Kevin R. and {van Dijk}, David and Wang, Zheng and Gigante, Scott and Burkhardt, Daniel B. and Chen, William S. and Yim, Kristina and van den Elzen, Antonia and Hirn, Matthew J. and Coifman, Ronald R. and Ivanova, Natalia B. and Wolf, Guy and Krishnaswamy, Smita},
  year = {2019},
  month = dec,
  journal = {Nature Biotechnology},
  volume = {37},
  number = {12},
  pages = {1482--1492},
  issn = {1087-0156, 1546-1696},
  doi = {10.1038/s41587-019-0336-3},
  urldate = {2021-10-12},
  langid = {english},
  file = {../../Bibliography/Moon_2019_Visualizing structure and transitions in high-dimensional biological data.pdf}
}

@inproceedings{morcos_2018_InsightsRepresentationalSimilarity,
  title = {Insights on Representational Similarity in Neural Networks with Canonical Correlation},
  booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
  author = {Morcos, Ari S. and Raghu, Maithra and Bengio, Samy},
  year = {2018},
  series = {{{NIPS}}'18},
  pages = {5732--5741},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA}
}

@inproceedings{muandet_2012_LearningDistributionsSupport,
  title = {Learning from Distributions via Support Measure Machines},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Muandet, Krikamol and Fukumizu, Kenji and Dinuzzo, Francesco and Sch{\"o}lkopf, Bernhard},
  editor = {Pereira, F. and Burges, C.J. and Bottou, L. and Weinberger, K.Q.},
  year = {2012},
  volume = {25},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Muandet_2012_Learning from distributions via support measure machines.pdf}
}

@article{muandet_2017_KernelMeanEmbedding,
  title = {Kernel {{Mean Embedding}} of {{Distributions}}: {{A Review}} and {{Beyond}}},
  shorttitle = {Kernel {{Mean Embedding}} of {{Distributions}}},
  author = {Muandet, Krikamol and Fukumizu, Kenji and Sriperumbudur, Bharath and Sch{\"o}lkopf, Bernhard},
  year = {2017},
  journal = {Foundations and Trends{\textregistered} in Machine Learning},
  volume = {10},
  number = {1-2},
  pages = {1--141},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000060},
  urldate = {2021-11-18},
  langid = {english},
  file = {../../Bibliography/Muandet_2017_Kernel Mean Embedding of Distributions.pdf}
}

@inproceedings{mukherjee_2017_ClusteringNetworkvaluedData,
  title = {On Clustering Network-Valued Data},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  author = {Mukherjee, Soumendu Sundar and Sarkar, Purnamrita and Lin, Lizhen},
  year = {2017},
  series = {{{NIPS}}'17},
  pages = {7074--7084},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  isbn = {978-1-5108-6096-4},
  file = {../../Bibliography/Mukherjee_2017_On clustering network-valued data.pdf}
}

@article{muller_1997_IntegralProbabilityMetrics,
  title = {Integral {{Probability Metrics}} and {{Their Generating Classes}} of {{Functions}}},
  author = {M{\"u}ller, Alfred},
  year = {1997},
  month = jun,
  journal = {Advances in Applied Probability},
  volume = {29},
  number = {2},
  pages = {429--443},
  issn = {0001-8678, 1475-6064},
  doi = {10.2307/1428011},
  urldate = {2023-12-14},
  abstract = {We consider probability metrics of the following type: for a class                              of functions and probability measures               P, Q               we define                              A unified study of such               integral probability metrics               is given. We characterize the maximal class of functions that generates such a metric. Further, we show how some interesting properties of these probability metrics arise directly from conditions on the generating class of functions. The results are illustrated by several examples, including the Kolmogorov metric, the Dudley metric and the stop-loss metric.},
  langid = {english},
  file = {../../Bibliography/Müller_1997_Integral Probability Metrics and Their Generating Classes of Functions.pdf}
}

@article{nadaraya_1964_EstimatingRegression,
  title = {On {{Estimating Regression}}},
  author = {Nadaraya, E. A.},
  year = {1964},
  month = jan,
  journal = {Theory of Probability \& Its Applications},
  volume = {9},
  number = {1},
  pages = {141--142},
  issn = {0040-585X, 1095-7219},
  doi = {10.1137/1109020},
  urldate = {2023-12-15},
  langid = {english}
}

@article{nadler_2006_DiffusionMapsSpectral,
  title = {Diffusion Maps, Spectral Clustering and Reaction Coordinates of Dynamical Systems},
  author = {Nadler, Boaz and Lafon, St{\'e}phane and Coifman, Ronald R. and Kevrekidis, Ioannis G.},
  year = {2006},
  month = jul,
  journal = {Applied and Computational Harmonic Analysis},
  volume = {21},
  number = {1},
  pages = {113--127},
  issn = {10635203},
  doi = {10.1016/j.acha.2005.07.004},
  urldate = {2022-08-28},
  langid = {english},
  file = {../../Bibliography/Nadler_2006_Diffusion maps, spectral clustering and reaction coordinates of dynamical.pdf}
}

@inproceedings{nagano_2019_WrappedNormalDistribution,
  title = {A Wrapped Normal Distribution on Hyperbolic Space for Gradient-Based Learning},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  author = {Nagano, Yoshihiro and Yamaguchi, Shoichiro and Fujita, Yasuhiro and Koyama, Masanori},
  editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  year = {2019-06-09/2019-06-15},
  series = {Proceedings of Machine Learning Research},
  volume = {97},
  pages = {4693--4702},
  publisher = {PMLR},
  abstract = {Hyperbolic space is a geometry that is known to be well-suited for representation learning of data with an underlying hierarchical structure. In this paper, we present a novel hyperbolic distribution called hyperbolic wrapped distribution, a wrapped normal distribution on hyperbolic space whose density can be evaluated analytically and differentiated with respect to the parameters. Our distribution enables the gradient-based learning of the probabilistic models on hyperbolic space that could never have been considered before. Also, we can sample from this hyperbolic probability distribution without resorting to auxiliary means like rejection sampling. As applications of our distribution, we develop a hyperbolic-analog of variational autoencoder and a method of probabilistic word embedding on hyperbolic space. We demonstrate the efficacy of our distribution on various datasets including MNIST, Atari 2600 Breakout, and WordNet.},
  pdf = {http://proceedings.mlr.press/v97/nagano19a/nagano19a.pdf},
  file = {../../Bibliography/Nagano_2019_A wrapped normal distribution on hyperbolic space for gradient-based learning.pdf}
}

@article{navarrete_2002_AnalysisComparisonEigenspaceBased,
  title = {Analysis and {{Comparison}} of {{Eigenspace-Based Face Recognition Approaches}}},
  author = {Navarrete, Pablo and {Ruiz-Del-Solar}, Javier},
  year = {2002},
  month = nov,
  journal = {International Journal of Pattern Recognition and Artificial Intelligence},
  volume = {16},
  number = {07},
  pages = {817--830},
  issn = {0218-0014, 1793-6381},
  doi = {10.1142/S0218001402002003},
  urldate = {2024-03-04},
  abstract = {Different eigenspace-based approaches have been proposed for the recognition of faces. They differ mostly in the kind of projection method being used and in the similarity matching criterion employed. The aim of this paper is to present a comparative study between some of these different approaches. This study considers theoretical aspects as well as experiments performed using a face database with a few number of classes (Yale) and also with a large number of classes (FERET).},
  langid = {english},
  file = {../../Bibliography/Navarrete_2002_Analysis and Comparison of Eigenspace-Based Face Recognition Approaches.pdf}
}

@article{nel_1986_SolutionMultivariateBehrensfisher,
  title = {A Solution to the Multivariate Behrens-Fisher Problem},
  author = {Nel, D.G. and Van Der Merwe, C.A.},
  year = {1986},
  month = jan,
  journal = {Communications in Statistics - Theory and Methods},
  volume = {15},
  number = {12},
  pages = {3719--3735},
  issn = {0361-0926, 1532-415X},
  doi = {10.1080/03610928608829342},
  urldate = {2022-07-26},
  langid = {english}
}

@article{nelder_1972_GeneralizedLinearModels,
  title = {Generalized {{Linear Models}}},
  author = {Nelder, J. A. and Wedderburn, R. W. M.},
  year = {1972},
  journal = {Journal of the Royal Statistical Society. Series A (General)},
  volume = {135},
  number = {3},
  eprint = {10.2307/2344614},
  eprinttype = {jstor},
  pages = {370},
  issn = {00359238},
  doi = {10.2307/2344614},
  urldate = {2022-09-07},
  file = {../../Bibliography/Nelder_1972_Generalized Linear Models.pdf}
}

@book{newcomb_1891_MeasuresVelocityLight,
  title = {Measures of the {{Velocity}} of {{Light Made Under}} the {{Direction}} of the {{Secretary}} of the {{Navy During}} the {{Years}} 1880-1882},
  author = {Newcomb, S.},
  year = {1891},
  series = {Astronomical {{Papers}} of the {{United States Naval Observatory}} 1882-1986},
  volume = {2},
  publisher = {Bureau of Navigation, Navy Department},
  address = {Washington, D.C.}
}

@article{newman_2006_ModularityCommunityStructure,
  title = {Modularity and Community Structure in Networks},
  author = {Newman, M. E. J.},
  year = {2006},
  month = jun,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {103},
  number = {23},
  pages = {8577--8582},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0601602103},
  urldate = {2022-08-28},
  langid = {english},
  file = {../../Bibliography/Newman_2006_Modularity and community structure in networks.pdf}
}

@inproceedings{ng_2002_SpectralClusteringAnalysis,
  title = {On Spectral Clustering: {{Analysis}} and an Algorithm},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Ng, Andrew and Jordan, Michael and Weiss, Yair},
  editor = {Dietterich, Thomas G. and Becker, Suzanna and Ghahramani, Zoubin},
  year = {2002},
  volume = {14},
  publisher = {MIT Press},
  file = {../../Bibliography/Ng_2002_On spectral clustering.pdf}
}

@incollection{ng_2014_TransportRiemannianManifold,
  title = {Transport on {{Riemannian Manifold}} for {{Functional Connectivity-Based Classification}}},
  booktitle = {Medical {{Image Computing}} and {{Computer-Assisted Intervention}} -- {{MICCAI}} 2014},
  author = {Ng, Bernard and Dressler, Martin and Varoquaux, Ga{\"e}l and Poline, Jean Baptiste and Greicius, Michael and Thirion, Bertrand},
  editor = {Golland, Polina and Hata, Nobuhiko and Barillot, Christian and Hornegger, Joachim and Howe, Robert},
  year = {2014},
  volume = {8674},
  pages = {405--412},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-10470-6_51},
  urldate = {2022-06-19},
  isbn = {978-3-319-10469-0 978-3-319-10470-6},
  langid = {english},
  file = {../../Bibliography/Ng_2014_Transport on Riemannian Manifold for Functional Connectivity-Based.pdf}
}

@article{ni_2019_CommunityDetectionNetworks,
  title = {Community {{Detection}} on {{Networks}} with {{Ricci Flow}}},
  author = {Ni, Chien-Chun and Lin, Yu-Yao and Luo, Feng and Gao, Jie},
  year = {2019},
  month = dec,
  journal = {Scientific Reports},
  volume = {9},
  number = {1},
  pages = {9984},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-46380-9},
  urldate = {2021-09-02},
  langid = {english},
  file = {../../Bibliography/Ni_2019_Community Detection on Networks with Ricci Flow.pdf}
}

@inproceedings{nickel_2017_PoincareEmbeddingsLearning,
  title = {Poincar{\'e} Embeddings for Learning Hierarchical Representations},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Nickel, Maximillian and Kiela, Douwe},
  editor = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Nickel_2017_Poincaré embeddings for learning hierarchical representations.pdf}
}

@incollection{nielsen_2019_ClusteringHilbertProjective,
  title = {Clustering in {{Hilbert}}'s {{Projective Geometry}}: {{The Case Studies}} of the {{Probability Simplex}} and the {{Elliptope}} of {{Correlation Matrices}}},
  shorttitle = {Clustering in {{Hilbert}}'s {{Projective Geometry}}},
  booktitle = {Geometric {{Structures}} of {{Information}}},
  author = {Nielsen, Frank and Sun, Ke},
  editor = {Nielsen, Frank},
  year = {2019},
  pages = {297--331},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-02520-5_11},
  urldate = {2021-10-04},
  isbn = {978-3-030-02519-9 978-3-030-02520-5},
  file = {../../Bibliography/Nielsen_2019_Clustering in Hilbert’s Projective Geometry.pdf}
}

@misc{nielsen_2021_MixturesFiniteConvex,
  title = {On \$w\$-Mixtures: {{Finite}} Convex Combinations of Prescribed Component Distributions},
  shorttitle = {On \$w\$-Mixtures},
  author = {Nielsen, Frank and Nock, Richard},
  year = {2021},
  month = jun,
  number = {arXiv:1708.00568},
  eprint = {1708.00568},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2022-07-25},
  abstract = {We consider the space of \$w\$-mixtures which is defined as the set of finite statistical mixtures sharing the same prescribed component distributions closed under convex combinations. The information geometry induced by the Bregman generator set to the Shannon negentropy on this space yields a dually flat space called the mixture family manifold. We show how the Kullback-Leibler (KL) divergence can be recovered from the corresponding Bregman divergence for the negentropy generator: That is, the KL divergence between two \$w\$-mixtures amounts to a Bregman Divergence (BD) induced by the Shannon negentropy generator. Thus the KL divergence between two Gaussian Mixture Models (GMMs) sharing the same Gaussian components is equivalent to a Bregman divergence. This KL-BD equivalence on a mixture family manifold implies that we can perform optimal KL-averaging aggregation of \$w\$-mixtures without information loss. More generally, we prove that the statistical skew Jensen-Shannon divergence between \$w\$-mixtures is equivalent to a skew Jensen divergence between their corresponding parameters. Finally, we state several properties, divergence identities, and inequalities relating to \$w\$-mixtures.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {../../Bibliography/Nielsen_2021_On $w$-mixtures.pdf}
}

@inproceedings{NIPS2016_26f5bd4a,
  title = {Mapping Estimation for Discrete Optimal Transport},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Perrot, Micha{\"e}l and Courty, Nicolas and Flamary, R{\'e}mi and Habrard, Amaury},
  editor = {Lee, D. and Sugiyama, M. and Luxburg, U. and Guyon, I. and Garnett, R.},
  year = {2016},
  volume = {29},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Perrot_2016_Mapping estimation for discrete optimal transport.pdf}
}

@article{nourani_1998_ComparisonSimulatedAnnealing,
  title = {A Comparison of Simulated Annealing Cooling Strategies},
  author = {Nourani, Yaghout and Andresen, Bjarne},
  year = {1998},
  month = oct,
  journal = {Journal of Physics A: Mathematical and General},
  volume = {31},
  number = {41},
  pages = {8373--8385},
  issn = {0305-4470, 1361-6447},
  doi = {10.1088/0305-4470/31/41/011},
  urldate = {2022-07-25},
  file = {../../Bibliography/Nourani_1998_A comparison of simulated annealing cooling strategies.pdf}
}

@article{oh_2001_BayesianMultidimensionalScaling,
  title = {Bayesian {{Multidimensional Scaling}} and {{Choice}} of {{Dimension}}},
  author = {Oh, Man-Suk and Raftery, Adrian E},
  year = {2001},
  month = sep,
  journal = {Journal of the American Statistical Association},
  volume = {96},
  number = {455},
  pages = {1031--1044},
  issn = {0162-1459, 1537-274X},
  doi = {10.1198/016214501753208690},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Oh_2001_Bayesian Multidimensional Scaling and Choice of Dimension.pdf}
}

@article{olkin_1982_DistanceTwoRandom,
  title = {The Distance between Two Random Vectors with given Dispersion Matrices},
  author = {Olkin, I. and Pukelsheim, F.},
  year = {1982},
  month = dec,
  journal = {Linear Algebra and its Applications},
  volume = {48},
  pages = {257--263},
  issn = {00243795},
  doi = {10.1016/0024-3795(82)90112-4},
  urldate = {2021-11-09},
  langid = {english},
  file = {../../Bibliography/Olkin_1982_The distance between two random vectors with given dispersion matrices.pdf}
}

@article{onnela_2003_DynamicsMarketCorrelations,
  title = {Dynamics of Market Correlations: {{Taxonomy}} and Portfolio Analysis},
  shorttitle = {Dynamics of Market Correlations},
  author = {Onnela, J.-P. and Chakraborti, A. and Kaski, K. and Kert{\'e}sz, J. and Kanto, A.},
  year = {2003},
  month = nov,
  journal = {Physical Review E},
  volume = {68},
  number = {5},
  pages = {056110},
  issn = {1063-651X, 1095-3787},
  doi = {10.1103/PhysRevE.68.056110},
  urldate = {2022-09-12},
  langid = {english},
  file = {../../Bibliography/Onnela_2003_Dynamics of market correlations.pdf}
}

@book{osborne_1985_FiniteAlgorithmsOptimization,
  title = {Finite Algorithms in Optimization and Data Analysis},
  author = {Osborne, M. R.},
  year = {1985},
  series = {Wiley Series in Probability and Mathematical Statistics},
  publisher = {Wiley},
  address = {Chichester ; New York},
  isbn = {978-0-471-90539-4},
  lccn = {QA402.5 .O8 1985},
  keywords = {Approximation theory,Computer algorithms,Data processing,Least squares,Mathematical optimization}
}

@article{otto_2001_GeometryDissipativeEvolution,
  title = {The Geometry of Dissipative Evolution Equations: The Porous Medium Equation},
  shorttitle = {{{THE GEOMETRY OF DISSIPATIVE EVOLUTION EQUATIONS}}},
  author = {Otto, Felix},
  year = {2001},
  month = jan,
  journal = {Communications in Partial Differential Equations},
  volume = {26},
  number = {1-2},
  pages = {101--174},
  issn = {0360-5302, 1532-4133},
  doi = {10.1081/PDE-100002243},
  urldate = {2021-11-09},
  langid = {english}
}

@book{panaretos_2020_InvitationStatisticsWasserstein,
  title = {An {{Invitation}} to {{Statistics}} in {{Wasserstein Space}}},
  author = {Panaretos, Victor M. and Zemel, Yoav},
  year = {2020},
  series = {{{SpringerBriefs}} in {{Probability}} and {{Mathematical Statistics}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-38438-8},
  urldate = {2021-11-06},
  isbn = {978-3-030-38437-1 978-3-030-38438-8},
  langid = {english},
  file = {../../Bibliography/Panaretos_2020_An Invitation to Statistics in Wasserstein Space.pdf}
}

@article{park_2013_StructuralFunctionalBrain,
  title = {Structural and {{Functional Brain Networks}}: {{From Connections}} to {{Cognition}}},
  shorttitle = {Structural and {{Functional Brain Networks}}},
  author = {Park, H.-J. and Friston, K.},
  year = {2013},
  month = nov,
  journal = {Science},
  volume = {342},
  number = {6158},
  pages = {1238411--1238411},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1238411},
  urldate = {2021-10-04},
  langid = {english}
}

@article{park_2014_GraphIndependentComponent,
  title = {Graph {{Independent Component Analysis Reveals Repertoires}} of {{Intrinsic Network Components}} in the {{Human Brain}}},
  author = {Park, Bumhee and Kim, Dae-Shik and Park, Hae-Jeong},
  editor = {Chialvo, Dante R.},
  year = {2014},
  month = jan,
  journal = {PLoS ONE},
  volume = {9},
  number = {1},
  pages = {e82873},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0082873},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Park_2014_Graph Independent Component Analysis Reveals Repertoires of Intrinsic Network.pdf}
}

@inproceedings{park_2016_K2abcApproximateBayesian,
  title = {K2-Abc: {{Approximate}} Bayesian Computation with Kernel Embeddings},
  booktitle = {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  author = {Park, Mijung and Jitkrittum, Wittawat and Sejdinovic, Dino},
  editor = {Gretton, Arthur and Robert, Christian C.},
  year = {2016-05-09/2016-05-11},
  series = {Proceedings of Machine Learning Research},
  volume = {51},
  pages = {398--407},
  publisher = {PMLR},
  address = {Cadiz, Spain},
  abstract = {Complicated generative models often result in a situation where computing the likelihood of observed data is intractable, while simulating from the conditional density given a parameter value is relatively easy. Approximate Bayesian Computation (ABC) is a paradigm that enables simulation-based posterior inference in such cases by measuring the similarity between simulated and observed data in terms of a chosen set of summary statistics. However, there is no general rule to construct sufficient summary statistics for complex models. Insufficient summary statistics will leak information, which leads to ABC algorithms yielding samples from an incorrect posterior. In this paper, we propose a fully nonparametric ABC paradigm which circumvents the need for manually selecting summary statistics. Our approach, K2-ABC, uses maximum mean discrepancy (MMD) to construct a dissimilarity measure between the observed and simulated data. The embedding of an empirical distribution of the data into a reproducing kernel Hilbert space plays a role of the summary statistic and is sufficient whenever the corresponding kernels are characteristic. Experiments on a simulated scenario and a real-world biological problem illustrate the effectiveness of the proposed algorithm.},
  pdf = {http://proceedings.mlr.press/v51/park16.pdf},
  file = {../../Bibliography/Park_2016_K2-abc.pdf}
}

@article{park_2019_VolumeChangePattern,
  title = {Volume Change Pattern of Decompression of Mandibular Odontogenic Keratocyst},
  author = {Park, Jin Hoo and Kwak, Eun-Jung and You, Kisung and Jung, Young-Soo and Jung, Hwi-Dong},
  year = {2019},
  month = dec,
  journal = {Maxillofacial Plastic and Reconstructive Surgery},
  volume = {41},
  number = {1},
  pages = {2},
  issn = {2288-8586},
  doi = {10.1186/s40902-018-0184-y},
  urldate = {2022-10-30},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/Park_2019_Volume change pattern of decompression of mandibular odontogenic keratocyst.pdf}
}

@book{patrangenaru_2016_NonparametricStatisticsManifolds,
  title = {Nonparametric Statistics on Manifolds and Their Applications to Object Data Analysis},
  author = {Patrangenaru, Victor and Ellingson, Leif},
  year = {2016},
  publisher = {CRC Press, Taylor \& Francis Group},
  address = {Boca Raton},
  isbn = {978-1-4398-2050-6},
  lccn = {QA278.2 .P364 2016},
  keywords = {Geography,Manifolds (Mathematics),Nonparametric statistics,Spatial analysis (Statistics),Statistical methods}
}

@article{pearson_1895_NoteRegressionInheritance,
  title = {Note on Regression and Inheritance in the Case of Two Parents},
  author = {Pearson, Karl},
  year = {1895},
  month = dec,
  journal = {Proceedings of the Royal Society of London},
  volume = {58},
  number = {347-352},
  pages = {240--242},
  issn = {0370-1662, 2053-9126},
  doi = {10.1098/rspl.1895.0041},
  urldate = {2022-11-08},
  langid = {english}
}

@article{pearson_1901_LIIILinesPlanes,
  title = {{{LIII}}. {{{\emph{On}}}}{\emph{ Lines and Planes of Closest Fit to Systems of Points in Space}}},
  author = {Pearson, Karl},
  year = {1901},
  month = nov,
  journal = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  volume = {2},
  number = {11},
  pages = {559--572},
  issn = {1941-5982, 1941-5990},
  doi = {10.1080/14786440109462720},
  urldate = {2021-10-03},
  langid = {english},
  file = {../../Bibliography/Pearson_1901_LIII.pdf}
}

@inproceedings{pei_2021_TrustworthyDataScience,
  title = {Towards {{Trustworthy Data Science}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Pei, Jian},
  year = {2021},
  month = dec,
  pages = {3--4},
  publisher = {IEEE},
  address = {Orlando, FL, USA},
  doi = {10.1109/BigData52589.2021.9671278},
  urldate = {2022-10-24},
  isbn = {978-1-66543-902-2}
}

@inproceedings{peng_2023_ConvergenceIRLSIts,
  title = {On the {{Convergence}} of {{IRLS}} and {{Its Variants}} in {{Outlier-Robust Estimation}}},
  booktitle = {2023 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Peng, Liangzu and K{\"u}mmerle, Christian and Vidal, Ren{\'e}},
  year = {2023},
  month = jun,
  pages = {17808--17818},
  publisher = {IEEE},
  address = {Vancouver, BC, Canada},
  doi = {10.1109/CVPR52729.2023.01708},
  urldate = {2024-03-04},
  isbn = {9798350301298},
  file = {../../Bibliography/Peng_2023_On the Convergence of IRLS and Its Variants in Outlier-Robust Estimation.pdf}
}

@article{pennec_2006_IntrinsicStatisticsRiemannian,
  title = {Intrinsic {{Statistics}} on {{Riemannian Manifolds}}: {{Basic Tools}} for {{Geometric Measurements}}},
  shorttitle = {Intrinsic {{Statistics}} on {{Riemannian Manifolds}}},
  author = {Pennec, Xavier},
  year = {2006},
  month = jul,
  journal = {Journal of Mathematical Imaging and Vision},
  volume = {25},
  number = {1},
  pages = {127--154},
  issn = {0924-9907, 1573-7683},
  doi = {10.1007/s10851-006-6228-4},
  urldate = {2021-09-27},
  langid = {english},
  file = {../../Bibliography/Pennec_2006_Intrinsic Statistics on Riemannian Manifolds.pdf}
}

@article{pennec_2006_RiemannianFrameworkTensor,
  title = {A {{Riemannian Framework}} for {{Tensor Computing}}},
  author = {Pennec, Xavier and Fillard, Pierre and Ayache, Nicholas},
  year = {2006},
  month = jan,
  journal = {International Journal of Computer Vision},
  volume = {66},
  number = {1},
  pages = {41--66},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-005-3222-z},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Pennec_2006_A Riemannian Framework for Tensor Computing.pdf}
}

@book{pennec_2020_RiemannianGeometricStatistics,
  title = {Riemannian {{Geometric Statistics}} in {{Medical Image Analysis}}},
  author = {Pennec, Xavier and Sommer, Stefan and Fletcher, Tom},
  year = {2020},
  publisher = {Academic Press},
  address = {San Diego},
  isbn = {978-0-12-814725-2},
  langid = {english},
  annotation = {OCLC: 1128025962}
}

@inproceedings{perrault-joncas_2011_DirectedGraphEmbedding,
  title = {Directed Graph Embedding: An Algorithm Based on Continuous Limits of Laplacian-Type Operators},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {{Perrault-joncas}, Dominique and Meila, Marina},
  editor = {{Shawe-Taylor}, J. and Zemel, R. and Bartlett, P. and Pereira, F. and Weinberger, K.Q.},
  year = {2011},
  volume = {24},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Perrault-joncas_2011_Directed graph embedding.pdf}
}

@book{petersen_2012_MatrixCookbook,
  title = {The {{Matrix Cookbook}}},
  author = {Petersen, K.B. and Pedersen, M.S.},
  year = {2012/nov},
  edition = {Version 20121115},
  publisher = {Technical Univeresity of Denmark}
}

@article{petersen_2019_FrechetRegressionRandom,
  title = {Fr{\'e}chet Regression for Random Objects with {{Euclidean}} Predictors},
  author = {Petersen, Alexander and M{\"u}ller, Hans-Georg},
  year = {2019},
  month = apr,
  journal = {The Annals of Statistics},
  volume = {47},
  number = {2},
  issn = {0090-5364},
  doi = {10.1214/17-AOS1624},
  urldate = {2022-03-10},
  file = {../../Bibliography/Petersen_2019_Fréchet regression for random objects with Euclidean predictors.pdf}
}

@article{petersen_2022_ModelingProbabilityDensity,
  title = {Modeling {{Probability Density Functions}} as {{Data Objects}}},
  author = {Petersen, Alexander and Zhang, Chao and Kokoszka, Piotr},
  year = {2022},
  month = jan,
  journal = {Econometrics and Statistics},
  volume = {21},
  pages = {159--178},
  issn = {24523062},
  doi = {10.1016/j.ecosta.2021.04.004},
  urldate = {2022-03-10},
  langid = {english}
}

@article{peyre_2019_ComputationalOptimalTransport,
  title = {Computational {{Optimal Transport}}: {{With Applications}} to {{Data Science}}},
  shorttitle = {Computational {{Optimal Transport}}},
  author = {Peyr{\'e}, Gabriel and Cuturi, Marco},
  year = {2019},
  journal = {Foundations and Trends{\textregistered} in Machine Learning},
  volume = {11},
  number = {5-6},
  pages = {355--607},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000073},
  urldate = {2021-10-14},
  langid = {english},
  file = {../../Bibliography/Peyré_2019_Computational Optimal Transport.pdf}
}

@article{pincombe_2007_DetectingChangesTime,
  title = {Detecting Changes in Time Series of Network Graphs Using Minimum Mean Squared Error and Cumulative Summation},
  author = {Pincombe, Brandon},
  year = {2007},
  month = oct,
  journal = {ANZIAM Journal},
  volume = {49},
  pages = {450},
  issn = {1445-8810},
  doi = {10.21914/anziamj.v48i0.62},
  urldate = {2022-08-28},
  file = {../../Bibliography/Pincombe_2007_Detecting changes in time series of network graphs using minimum mean squared.pdf}
}

@incollection{pistone_2013_NonparametricInformationGeometry,
  title = {Nonparametric {{Information Geometry}}},
  booktitle = {Geometric {{Science}} of {{Information}}},
  author = {Pistone, Giovanni},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Nielsen, Frank and Barbaresco, Fr{\'e}d{\'e}ric},
  year = {2013},
  volume = {8085},
  pages = {5--36},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-40020-9_3},
  urldate = {2022-02-17},
  isbn = {978-3-642-40019-3 978-3-642-40020-9},
  file = {../../Bibliography/Pistone_2013_Nonparametric Information Geometry.pdf}
}

@article{pitman_1937_SignificanceTestsWhich,
  title = {Significance {{Tests Which May}} Be {{Applied}} to {{Samples From}} Any {{Populations}}},
  author = {Pitman, E. J. G.},
  year = {1937},
  journal = {Supplement to the Journal of the Royal Statistical Society},
  volume = {4},
  number = {1},
  eprint = {10.2307/2984124},
  eprinttype = {jstor},
  pages = {119},
  issn = {14666162},
  doi = {10.2307/2984124},
  urldate = {2021-10-02},
  file = {../../Bibliography/Pitman_1937_Significance Tests Which May be Applied to Samples From any Populations.pdf}
}

@inproceedings{pmlr-v80-nickel18a,
  title = {Learning Continuous Hierarchies in the {{Lorentz}} Model of Hyperbolic Geometry},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  author = {Nickel, Maximillian and Kiela, Douwe},
  editor = {Dy, Jennifer and Krause, Andreas},
  year = {2018-07-10/2018-07-15},
  series = {Proceedings of Machine Learning Research},
  volume = {80},
  pages = {3779--3788},
  publisher = {PMLR},
  abstract = {We are concerned with the discovery of hierarchical relationships from large-scale unstructured similarity scores. For this purpose, we study different models of hyperbolic space and find that learning embeddings in the Lorentz model is substantially more efficient than in the Poincar{\'e}-ball model. We show that the proposed approach allows us to learn high-quality embeddings of large taxonomies which yield improvements over Poincar{\'e} embeddings, especially in low dimensions. Lastly, we apply our model to discover hierarchies in two real-world datasets: we show that an embedding in hyperbolic space can reveal important aspects of a company's organizational structure as well as reveal historical relationships between language families.},
  pdf = {http://proceedings.mlr.press/v80/nickel18a/nickel18a.pdf},
  file = {../../Bibliography/Nickel_2018_Learning continuous hierarchies in the Lorentz model of hyperbolic geometry.pdf}
}

@article{polanski_2019_BBKNNFastBatch,
  title = {{{BBKNN}}: Fast Batch Alignment of Single Cell Transcriptomes},
  shorttitle = {{{BBKNN}}},
  author = {Pola{\'n}ski, Krzysztof and Young, Matthew D and Miao, Zhichao and Meyer, Kerstin B and Teichmann, Sarah A and Park, Jong-Eun},
  editor = {Berger, Bonnie},
  year = {2019},
  month = aug,
  journal = {Bioinformatics},
  pages = {btz625},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/btz625},
  urldate = {2022-06-20},
  abstract = {Abstract                            Motivation               Increasing numbers of large scale single cell RNA-Seq projects are leading to a data explosion, which can only be fully exploited through data integration. A number of methods have been developed to combine diverse datasets by removing technical batch effects, but most are computationally intensive. To overcome the challenge of enormous datasets, we have developed BBKNN, an extremely fast graph-based data integration algorithm. We illustrate the power of BBKNN on large scale mouse atlasing data, and favourably benchmark its run time against a number of competing methods.                                         Availability and implementation               BBKNN is available at https://github.com/Teichlab/bbknn, along with documentation and multiple example notebooks, and can be installed from pip.                                         Supplementary information               Supplementary data are available at Bioinformatics online.},
  langid = {english},
  file = {../../Bibliography/Polański_2019_BBKNN.pdf}
}

@book{polyak_2021_IntroductionContinuousOptimization,
  title = {Introduction to Continuous Optimization},
  author = {Polyak, Roman A.},
  year = {2021},
  series = {Springer Optimization and Its Applications},
  number = {volume 172},
  publisher = {Springer},
  address = {Cham, Switzerland},
  doi = {10.1007/978-3-030-68713-7},
  isbn = {978-3-030-68711-3},
  langid = {english},
  file = {../../Bibliography/Polyak_2021_Introduction to continuous optimization.pdf}
}

@article{pompe_2020_FrameworkAdaptiveMCMC,
  title = {A Framework for Adaptive {{MCMC}} Targeting Multimodal Distributions},
  author = {Pompe, Emilia and Holmes, Chris and {\L}atuszy{\'n}ski, Krzysztof},
  year = {2020},
  month = oct,
  journal = {The Annals of Statistics},
  volume = {48},
  number = {5},
  issn = {0090-5364},
  doi = {10.1214/19-AOS1916},
  urldate = {2023-12-19},
  file = {../../Bibliography/Pompe_2020_A framework for adaptive MCMC targeting multimodal distributions.pdf}
}

@book{preston_2009_DemographyMeasuringModeling,
  title = {Demography: Measuring and Modeling Population Processes},
  shorttitle = {Demography},
  author = {Preston, Samuel H. and Heuveline, Patrick and Guillot, Michel},
  year = {2009},
  edition = {Nachdr.},
  publisher = {Blackwell},
  address = {Oxford},
  isbn = {978-1-55786-451-2},
  langid = {english}
}

@article{preti_2017_DynamicFunctionalConnectome,
  title = {The Dynamic Functional Connectome: {{State-of-the-art}} and Perspectives},
  shorttitle = {The Dynamic Functional Connectome},
  author = {Preti, Maria Giulia and Bolton, Thomas AW and Van De Ville, Dimitri},
  year = {2017},
  month = oct,
  journal = {NeuroImage},
  volume = {160},
  pages = {41--54},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2016.12.061},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Preti_2017_The dynamic functional connectome.pdf}
}

@article{purkayastha_1991_RotationallySymmetricDirectional,
  title = {A Rotationally Symmetric Directional Distribution: {{Obtained}} through Maximum Likelihood Characterization},
  author = {Purkayastha, Sumitra},
  year = {1991},
  journal = {Sankhy{\=a}: The Indian Journal of Statistics, Series A (1961-2002)},
  volume = {53},
  number = {1},
  eprint = {25050820},
  eprinttype = {jstor},
  pages = {70--83},
  publisher = {Springer},
  issn = {0581572X},
  abstract = {A circularly symmetric directional distribution is obtained by showing that in the class of circularly symmetric distributions on circle it is the only distribution for which the circular median is a maximum likelihood estimate of the location parameter. Subsequently, quently, this result is extended to the spherical case.},
  file = {../../Bibliography/Purkayastha_1991_A rotationally symmetric directional distribution.pdf}
}

@article{qiu_2015_ManifoldLearningBrain,
  title = {Manifold Learning on Brain Functional Networks in Aging},
  author = {Qiu, Anqi and Lee, Annie and Tan, Mingzhen and Chung, Moo K.},
  year = {2015},
  month = feb,
  journal = {Medical Image Analysis},
  volume = {20},
  number = {1},
  pages = {52--60},
  issn = {13618415},
  doi = {10.1016/j.media.2014.10.006},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Qiu_2015_Manifold learning on brain functional networks in aging.pdf}
}

@inproceedings{qu_2002_PrincipalComponentAnalysis,
  title = {Principal Component Analysis for Dimension Reduction in Massive Distributed Data Sets},
  author = {Qu, Yongming and Ostrouchov, George and Samatova, Nagiza and Geist, Al},
  year = {2002},
  month = apr,
  series = {Knowledge and {{Information Systems}} - {{KAIS}}}
}

@incollection{rabin_2012_WassersteinBarycenterIts,
  title = {Wasserstein {{Barycenter}} and {{Its Application}} to {{Texture Mixing}}},
  booktitle = {Scale {{Space}} and {{Variational Methods}} in {{Computer Vision}}},
  author = {Rabin, Julien and Peyr{\'e}, Gabriel and Delon, Julie and Bernot, Marc},
  editor = {Bruckstein, Alfred M. and {ter Haar Romeny}, Bart M. and Bronstein, Alexander M. and Bronstein, Michael M.},
  year = {2012},
  volume = {6667},
  pages = {435--446},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-24785-9_37},
  urldate = {2023-03-23},
  isbn = {978-3-642-24784-2 978-3-642-24785-9},
  file = {../../Bibliography/Rabin_2012_Wasserstein Barycenter and Its Application to Texture Mixing.pdf}
}

@book{rachev_1998_MassTransportationProblems,
  title = {Mass Transportation Problems},
  author = {Rachev, S. T. and R{\"u}schendorf, Ludger},
  year = {1998},
  series = {Probability and Its Applications},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-98350-9 978-0-387-98352-3},
  lccn = {QA402.6 .R33 1998},
  keywords = {Transportation problems (Programming)}
}

@incollection{raftery_2007_EstimatingIntegratedLikelihood,
  title = {Estimating the {{Integrated Likelihood}} via {{Posterior Simulation Using}} the {{Harmonic Mean Identity}}},
  booktitle = {Bayesian {{Statistics}} 8},
  author = {Raftery, Adrian E and Newton, Michael A and Satagopan, Jaya M and Krivitsky, Pavel N},
  editor = {Bernardo, J M and Bayarri, M J and Berger, J O and Dawid, A P and Heckerman, D and Smith, A F M and West, M},
  year = {2007},
  month = jul,
  pages = {381--426},
  publisher = {Oxford University PressOxford},
  doi = {10.1093/oso/9780199214655.003.0015},
  urldate = {2024-01-10},
  abstract = {Abstract             The integrated likelihood (also called the marginal likelihood or the normalizing constant) is a central quantity in Bayesian model selection and model averaging. It is defined as the integral over the parameter space of the likelihood times the prior density. The Bayes factor for model comparison and Bayesian testing is a ratio of integrated likelihoods, and the model weights in Bayesian model averaging are proportional to the integrated likelihoods. We consider the estimation of the integrated likelihood from posterior simulation output, aiming at a generic method that uses only the likelihoods from the posterior simulation iterations. The key is the harmonic mean identity, which says that the reciprocal of the integrated likelihood is equal to the posterior harmonic mean of the likelihood. The simplest estimator based on the identity is thus the harmonic mean of the likelihoods. While this is an unbiased and simulation-consistent estimator, its reciprocal can have infinite variance and so it is unstable in general.},
  isbn = {978-0-19-921465-5 978-1-383-03534-6},
  langid = {english},
  file = {../../Bibliography/Raftery_2007_Estimating the Integrated Likelihood via Posterior Simulation Using the.pdf}
}

@inproceedings{raghu_2017_SVCCASingularVector,
  title = {{{SVCCA}}: {{Singular}} Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  author = {Raghu, Maithra and Gilmer, Justin and Yosinski, Jason and {Sohl-Dickstein}, Jascha},
  year = {2017},
  series = {{{NIPS}}'17},
  pages = {6078--6087},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  abstract = {We propose a new technique, Singular Vector Canonical Correlation Analysis (SVCCA), a tool for quickly comparing two representations in a way that is both invariant to affine transform (allowing comparison between different layers and networks) and fast to compute (allowing more comparisons to be calculated than with previous methods). We deploy this tool to measure the intrinsic dimensionality of layers, showing in some cases needless over-parameterization; to probe learning dynamics throughout training, finding that networks converge to final representations from the bottom up; to show where class-specific information in networks is formed; and to suggest new training regimes that simultaneously save computation and overfit less.},
  isbn = {978-1-5108-6096-4},
  file = {../../Bibliography/Raghu_2017_SVCCA.pdf}
}

@article{rahim_2019_PopulationShrinkageCovariance,
  title = {Population Shrinkage of Covariance ({{PoSCE}}) for Better Individual Brain Functional-Connectivity Estimation},
  author = {Rahim, Mehdi and Thirion, Bertrand and Varoquaux, Ga{\"e}l},
  year = {2019},
  month = may,
  journal = {Medical Image Analysis},
  volume = {54},
  pages = {138--148},
  issn = {13618415},
  doi = {10.1016/j.media.2019.03.001},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Rahim_2019_Population shrinkage of covariance (PoSCE) for better individual brain.pdf}
}

@inproceedings{rajashekar_2024_HumanAlgorithmicInteractionUsing,
  title = {Human-{{Algorithmic Interaction Using}} a {{Large Language Model-Augmented Artificial Intelligence Clinical Decision Support System}}},
  booktitle = {Proceedings of the {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Rajashekar, Niroop Channa and Shin, Yeo Eun and Pu, Yuan and Chung, Sunny and You, Kisung and Giuffre, Mauro and Chan, Colleen E and Saarinen, Theo and Hsiao, Allen and Sekhon, Jasjeet and Wong, Ambrose H and Evans, Leigh V and Kizilcec, Rene F. and Laine, Loren and Mccall, Terika and Shung, Dennis},
  year = {2024},
  month = may,
  pages = {1--20},
  publisher = {ACM},
  address = {Honolulu HI USA},
  doi = {10.1145/3613904.3642024},
  urldate = {2024-05-12},
  copyright = {All rights reserved},
  isbn = {9798400703300},
  langid = {english},
  file = {../../Bibliography/Rajashekar_2024_Human-Algorithmic Interaction Using a Large Language Model-Augmented Artificial.pdf}
}

@article{ramdas_2017_WassersteinTwoSampleTesting,
  title = {On {{Wasserstein Two-Sample Testing}} and {{Related Families}} of {{Nonparametric Tests}}},
  author = {Ramdas, Aaditya and Trillos, Nicol{\'a}s and Cuturi, Marco},
  year = {2017},
  month = jan,
  journal = {Entropy},
  volume = {19},
  number = {2},
  pages = {47},
  issn = {1099-4300},
  doi = {10.3390/e19020047},
  urldate = {2021-10-02},
  langid = {english},
  file = {../../Bibliography/Ramdas_2017_On Wasserstein Two-Sample Testing and Related Families of Nonparametric Tests.pdf}
}

@article{ramsay_1984_MatrixCorrelation,
  title = {Matrix Correlation},
  author = {Ramsay, J. O. and {ten Berge}, Jos and Styan, G. P. H.},
  year = {1984},
  month = sep,
  journal = {Psychometrika},
  volume = {49},
  number = {3},
  pages = {403--423},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02306029},
  urldate = {2022-12-09},
  langid = {english},
  file = {../../Bibliography/Ramsay_1984_Matrix correlation.pdf}
}

@article{rand_1971_ObjectiveCriteriaEvaluation,
  title = {Objective {{Criteria}} for the {{Evaluation}} of {{Clustering Methods}}},
  author = {Rand, William M.},
  year = {1971},
  month = dec,
  journal = {Journal of the American Statistical Association},
  volume = {66},
  number = {336},
  pages = {846--850},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1971.10482356},
  urldate = {2022-08-20},
  langid = {english},
  file = {../../Bibliography/Rand_1971_Objective Criteria for the Evaluation of Clustering Methods.pdf}
}

@book{rasmussen_2006_GaussianProcessesMachine,
  title = {Gaussian Processes for Machine Learning},
  author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
  year = {2006},
  series = {Adaptive Computation and Machine Learning},
  publisher = {MIT Press},
  address = {Cambridge, Mass},
  isbn = {978-0-262-18253-9},
  lccn = {QA274.4 .R37 2006},
  keywords = {Data processing,Gaussian processes,Machine learning,Mathematical models},
  annotation = {OCLC: ocm61285753}
}

@manual{rcoreteam_2022_LanguageEnvironmentStatistical,
  type = {Manual},
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2022},
  address = {Vienna, Austria},
  organization = {R Foundation for Statistical Computing}
}

@inproceedings{renyi_1961_MeasuresEntropyInformation,
  title = {On {{Measures}} of {{Entropy}} and {{Information}}},
  booktitle = {Proceedings of the {{Fourth Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}},
  author = {R\{{\textbackslash}'e\}nyi, Alfr\{{\textbackslash}'e\}d},
  year = {1961},
  volume = {1},
  pages = {547--561},
  publisher = {University of California Press}
}

@book{rice_1964_ApproximationsFunctions,
  title = {The {{Approximations}} of {{Functions}}},
  author = {Rice, John Rischard},
  year = {1964},
  series = {Addison-{{Wesley Series}} in {{Computer Science}} and {{Information Processing}}},
  publisher = {Addison-Wesley Pub. Co},
  address = {Reading, Mass}
}

@article{rizzo_2010_DISCOAnalysisNonparametric,
  title = {{{DISCO}} Analysis: {{A}} Nonparametric Extension of Analysis of Variance},
  shorttitle = {{{DISCO}} Analysis},
  author = {Rizzo, Maria L. and Sz{\'e}kely, G{\'a}bor J.},
  year = {2010},
  month = jun,
  journal = {The Annals of Applied Statistics},
  volume = {4},
  number = {2},
  issn = {1932-6157},
  doi = {10.1214/09-AOAS245},
  urldate = {2022-07-25},
  file = {../../Bibliography/Rizzo_2010_DISCO analysis.pdf}
}

@article{roberts_2024_NaturalLanguageProcessing,
  title = {Natural Language Processing of Clinical Notes Enables Early Inborn Error of Immunity Risk Ascertainment},
  author = {Roberts, Kirk and Chin, Aaron T. and Loewy, Klaus and Pompeii, Lisa and Shin, Harold and Rider, Nicholas L.},
  year = {2024},
  month = may,
  journal = {Journal of Allergy and Clinical Immunology: Global},
  volume = {3},
  number = {2},
  pages = {100224},
  issn = {27728293},
  doi = {10.1016/j.jacig.2024.100224},
  urldate = {2024-10-10},
  langid = {english},
  file = {../../Bibliography/Roberts_2024_Natural language processing of clinical notes enables early inborn error of.pdf}
}

@article{robinson_2017_HypothesisTestingTopological,
  title = {Hypothesis Testing for Topological Data Analysis},
  author = {Robinson, Andrew and Turner, Katharine},
  year = {2017},
  month = dec,
  journal = {Journal of Applied and Computational Topology},
  volume = {1},
  number = {2},
  pages = {241--261},
  issn = {2367-1726, 2367-1734},
  doi = {10.1007/s41468-017-0008-7},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Robinson_2017_Hypothesis testing for topological data analysis.pdf}
}

@book{rockafellar_1997_ConvexAnalysis,
  title = {Convex Analysis},
  author = {Rockafellar, Ralph Tyrrell},
  year = {1997},
  series = {Princeton {{Landmarks}} in Mathematics and Physics},
  edition = {10. print. and 1. paperb. print},
  publisher = {Princeton Univ. Press},
  address = {Princeton, NJ},
  isbn = {978-0-691-01586-6 978-0-691-08069-7},
  langid = {english},
  file = {../../Bibliography/rockafellar_1997_convex analysis.pdf}
}

@article{romano_2005_ExactApproximateStepdown,
  title = {Exact and {{Approximate Stepdown Methods}} for {{Multiple Hypothesis Testing}}},
  author = {Romano, Joseph P and Wolf, Michael},
  year = {2005},
  month = mar,
  journal = {Journal of the American Statistical Association},
  volume = {100},
  number = {469},
  pages = {94--108},
  issn = {0162-1459, 1537-274X},
  doi = {10.1198/016214504000000539},
  urldate = {2024-06-05},
  langid = {english},
  file = {../../Bibliography/Romano_2005_Exact and Approximate Stepdown Methods for Multiple Hypothesis Testing.pdf}
}

@article{rothman_2008_SparsePermutationInvariant,
  title = {Sparse Permutation Invariant Covariance Estimation},
  author = {Rothman, Adam J. and Bickel, Peter J. and Levina, Elizaveta and Zhu, Ji},
  year = {2008},
  month = jan,
  journal = {Electronic Journal of Statistics},
  volume = {2},
  number = {none},
  issn = {1935-7524},
  doi = {10.1214/08-EJS176},
  urldate = {2022-07-26},
  file = {../../Bibliography/Rothman_2008_Sparse permutation invariant covariance estimation.pdf}
}

@book{rousseeuw_1987_RobustRegressionOutlier,
  title = {Robust Regression and Outlier Detection},
  author = {Rousseeuw, Peter J. and Leroy, Annick M.},
  year = {1987},
  publisher = {Wiley},
  address = {New York},
  abstract = {Provides an applications-oriented introduction to robust regression and outlier detection, emphasising {$^\circ$}high-breakdown{$^\circ$} methods which can cope with a sizeable fraction of contamination. Its self-contained treatment allows readers to skip the mathematical material which is concentrated in a few sections},
  isbn = {978-0-471-72538-1},
  langid = {english},
  annotation = {OCLC: 219924217}
}

@article{rousseeuw_1987_SilhouettesGraphicalAid,
  title = {Silhouettes: {{A}} Graphical Aid to the Interpretation and Validation of Cluster Analysis},
  shorttitle = {Silhouettes},
  author = {Rousseeuw, Peter J.},
  year = {1987},
  month = nov,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {20},
  pages = {53--65},
  issn = {03770427},
  doi = {10.1016/0377-0427(87)90125-7},
  urldate = {2021-10-02},
  langid = {english},
  file = {../../Bibliography/Rousseeuw_1987_Silhouettes.pdf}
}

@inproceedings{roy_2014_ModelingMeasuringGraph,
  title = {Modeling and Measuring Graph Similarity: The Case for Centrality Distance},
  shorttitle = {Modeling and Measuring Graph Similarity},
  booktitle = {Proceedings of the 10th {{ACM}} International Workshop on {{Foundations}} of Mobile Computing - {{FOMC}} '14},
  author = {Roy, Matthieu and Schmid, Stefan and Tredan, Gilles},
  year = {2014},
  pages = {47--52},
  publisher = {ACM Press},
  address = {Philadelphia, Pennsylvania, USA},
  doi = {10.1145/2634274.2634277},
  urldate = {2022-08-28},
  isbn = {978-1-4503-2984-2},
  langid = {english},
  file = {../../Bibliography/Roy_2014_Modeling and measuring graph similarity.pdf}
}

@article{rubio_2013_SimpleApproachMaximum,
  title = {A Simple Approach to Maximum Intractable Likelihood Estimation},
  author = {Rubio, F. J. and Johansen, Adam M.},
  year = {2013},
  month = jan,
  journal = {Electronic Journal of Statistics},
  volume = {7},
  number = {none},
  issn = {1935-7524},
  doi = {10.1214/13-EJS819},
  urldate = {2022-07-25},
  file = {../../Bibliography/Rubio_2013_A simple approach to maximum intractable likelihood estimation.pdf}
}

@article{runge_2014_QuantifyingStrengthDelay,
  title = {Quantifying the {{Strength}} and {{Delay}} of {{Climatic Interactions}}: {{The Ambiguities}} of {{Cross Correlation}} and a {{Novel Measure Based}} on {{Graphical Models}}},
  shorttitle = {Quantifying the {{Strength}} and {{Delay}} of {{Climatic Interactions}}},
  author = {Runge, Jakob and Petoukhov, Vladimir and Kurths, J{\"u}rgen},
  year = {2014},
  month = jan,
  journal = {Journal of Climate},
  volume = {27},
  number = {2},
  pages = {720--739},
  issn = {0894-8755, 1520-0442},
  doi = {10.1175/JCLI-D-13-00159.1},
  urldate = {2024-12-27},
  abstract = {Abstract             Lagged cross-correlation and regression analysis are commonly used to gain insights into interaction mechanisms between climatological processes, in particular to assess time delays and to quantify the strength of a mechanism. Exemplified on temperature anomalies in Europe and the tropical Pacific and Atlantic, the authors study lagged correlation and regressions analytically for a simple model system. A strong dependence on the influence of serial dependencies or autocorrelation is demonstrated, which can lead to misleading conclusions about time delays and also obscures a quantification of the interaction mechanism.             To overcome these possible artifacts, the authors propose a two-step procedure based on the concept of graphical models recently introduced to climate research. In the first step, graphical models are used to detect the existence of (Granger) causal interactions that determine the time delays of a mechanism. In the second step, a certain partial correlation and a regression measure are introduced that allow one to specifically quantify the strength of an interaction mechanism in a well interpretable way that enables the exclusion of misleading effects of serial correlation as well as more general dependencies. The potential of the approach to quantify interactions between two and more processes is demonstrated by investigating teleconnections of ENSO and the mechanism of the Walker circulation.             The article is intended to serve as a guideline to interpret lagged correlations and regressions in the presence of autocorrelation and introduces a powerful approach to analyze time delays and the strength of an interaction mechanism.},
  langid = {english},
  file = {../../../../../Zotero/storage/8AEGBPYP/Runge et al. - 2014 - Quantifying the Strength and Delay of Climatic Int.pdf}
}

@article{runnalls_2007_KullbackLeiblerApproachGaussian,
  title = {Kullback-{{Leibler Approach}} to {{Gaussian Mixture Reduction}}},
  author = {Runnalls, A.R.},
  year = {2007},
  month = jul,
  journal = {IEEE Transactions on Aerospace and Electronic Systems},
  volume = {43},
  number = {3},
  pages = {989--999},
  issn = {0018-9251},
  doi = {10.1109/TAES.2007.4383588},
  urldate = {2021-08-17},
  file = {../../Bibliography/Runnalls_2007_Kullback-Leibler Approach to Gaussian Mixture Reduction.pdf}
}

@article{ruschendorf_2002_NCouplingProblem,
  title = {On the N-{{Coupling Problem}}},
  author = {R{\"u}schendorf, Ludger and Uckelmann, Ludger},
  year = {2002},
  month = may,
  journal = {Journal of Multivariate Analysis},
  volume = {81},
  number = {2},
  pages = {242--258},
  issn = {0047259X},
  doi = {10.1006/jmva.2001.2005},
  urldate = {2021-11-08},
  langid = {english},
  file = {../../Bibliography/Rüschendorf_2002_On the n-Coupling Problem.pdf}
}

@article{sabnis_2019_CompressedCovarianceEstimation,
  title = {Compressed {{Covariance Estimation}} with {{Automated Dimension Learning}}},
  author = {Sabnis, Gautam and Pati, Debdeep and Bhattacharya, Anirban},
  year = {2019},
  month = dec,
  journal = {Sankhya A},
  volume = {81},
  number = {2},
  pages = {466--481},
  issn = {0976-836X, 0976-8378},
  doi = {10.1007/s13171-018-0134-x},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Sabnis_2019_Compressed Covariance Estimation with Automated Dimension Learning.pdf}
}

@inproceedings{sala_2018_RepresentationTradeoffsHyperbolic,
  title = {Representation Tradeoffs for Hyperbolic Embeddings},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  author = {Sala, Frederic and De Sa, Chris and Gu, Albert and Re, Christopher},
  editor = {Dy, Jennifer and Krause, Andreas},
  year = {2018-07-10/2018-07-15},
  series = {Proceedings of Machine Learning Research},
  volume = {80},
  pages = {4460--4469},
  publisher = {PMLR},
  abstract = {Hyperbolic embeddings offer excellent quality with few dimensions when embedding hierarchical data structures. We give a combinatorial construction that embeds trees into hyperbolic space with arbitrarily low distortion without optimization. On WordNet, this algorithm obtains a mean-average-precision of 0.989 with only two dimensions, outperforming existing work by 0.11 points. We provide bounds characterizing the precision-dimensionality tradeoff inherent in any hyperbolic embedding. To embed general metric spaces, we propose a hyperbolic generalization of multidimensional scaling (h-MDS). We show how to perform exact recovery of hyperbolic points from distances, provide a perturbation analysis, and give a recovery result that enables us to reduce dimensionality. Finally, we extract lessons from the algorithms and theory above to design a scalable PyTorch-based implementation that can handle incomplete information.},
  file = {../../Bibliography/Sala_2018_Representation tradeoffs for hyperbolic embeddings.pdf}
}

@article{salimi-khorshidi_2014_AutomaticDenoisingFunctional,
  title = {Automatic Denoising of Functional {{MRI}} Data: {{Combining}} Independent Component Analysis and Hierarchical Fusion of Classifiers},
  shorttitle = {Automatic Denoising of Functional {{MRI}} Data},
  author = {{Salimi-Khorshidi}, Gholamreza and Douaud, Gwena{\"e}lle and Beckmann, Christian F. and Glasser, Matthew F. and Griffanti, Ludovica and Smith, Stephen M.},
  year = {2014},
  month = apr,
  journal = {NeuroImage},
  volume = {90},
  pages = {449--468},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2013.11.046},
  urldate = {2024-08-01},
  langid = {english},
  file = {../../Bibliography/Salimi-Khorshidi_2014_Automatic denoising of functional MRI data.pdf}
}

@inproceedings{salmond_1990_MixtureReductionAlgorithms,
  title = {Mixture Reduction Algorithms for Target Tracking in Clutter},
  booktitle = {Signal and {{Data Processing}} of {{Small Targets}} 1990},
  author = {Salmond, D. J.},
  year = {1990},
  month = oct,
  pages = {37},
  publisher = {SPIE},
  address = {Orlando, United States},
  doi = {10.1117/12.2321784},
  urldate = {2021-08-17},
  isbn = {978-0-8194-0356-8},
  file = {../../Bibliography/Salmond_1990_Mixture reduction algorithms for target tracking in clutter.pdf}
}

@book{sammut_2011_EncyclopediaMachineLearning,
  title = {Encyclopedia of Machine Learning},
  author = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2011},
  series = {Springer Reference},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-30164-8},
  langid = {english}
}

@article{sankaran_2023_BootstrapConfidenceRegions,
  title = {Bootstrap {{Confidence Regions}} for {{Learned Feature Embeddings}}},
  author = {Sankaran, Kris},
  year = {2023},
  month = may,
  journal = {Journal of Computational and Graphical Statistics},
  pages = {1--11},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2023.2197478},
  urldate = {2023-09-29},
  langid = {english},
  file = {../../Bibliography/Sankaran_2023_Bootstrap Confidence Regions for Learned Feature Embeddings.pdf}
}

@article{saucan_2018_DiscreteCurvaturesNetwork,
  title = {Discrete Curvatures and Network Analysis},
  author = {Saucan, Emil and Samal, Areejit and Weber, Melanie and Jost, J{\"u}rgen},
  year = {2018},
  journal = {MATCH},
  volume = {80},
  number = {3},
  pages = {605--622},
  file = {../../Bibliography/Saucan_2018_Discrete curvatures and network analysis.pdf}
}

@article{schaefer_2018_LocalGlobalParcellationHuman,
  title = {Local-{{Global Parcellation}} of the {{Human Cerebral Cortex}} from {{Intrinsic Functional Connectivity MRI}}},
  author = {Schaefer, Alexander and Kong, Ru and Gordon, Evan M and Laumann, Timothy O and Zuo, Xi-Nian and Holmes, Avram J and Eickhoff, Simon B and Yeo, B T Thomas},
  year = {2018},
  month = sep,
  journal = {Cerebral Cortex},
  volume = {28},
  number = {9},
  pages = {3095--3114},
  issn = {1047-3211, 1460-2199},
  doi = {10.1093/cercor/bhx179},
  urldate = {2024-08-01},
  copyright = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
  langid = {english},
  file = {../../Bibliography/Schaefer_2018_Local-Global Parcellation of the Human Cerebral Cortex from Intrinsic.pdf}
}

@article{schalk_2004_BCI2000GeneralPurposeBrainComputer,
  title = {{{BCI2000}}: {{A General-Purpose Brain-Computer Interface}} ({{BCI}}) {{System}}},
  shorttitle = {{{BCI2000}}},
  author = {Schalk, G. and McFarland, D.J. and Hinterberger, T. and Birbaumer, N. and Wolpaw, J.R.},
  year = {2004},
  month = jun,
  journal = {IEEE Transactions on Biomedical Engineering},
  volume = {51},
  number = {6},
  pages = {1034--1043},
  issn = {0018-9294},
  doi = {10.1109/TBME.2004.827072},
  urldate = {2022-09-11},
  langid = {english},
  file = {../../Bibliography/Schalk_2004_BCI2000.pdf}
}

@misc{schalk_2009_EEGMotorMovement,
  title = {{{EEG Motor Movement}}/{{Imagery Dataset}}},
  author = {Schalk, Gerwin and McFarland, Dennis J and Hinterberger, Thilo and Birbaumer, Niels and Wolpaw, Jonathan R},
  year = {2009},
  publisher = {physionet.org},
  doi = {10.13026/C28G6P},
  urldate = {2022-09-12},
  abstract = {This data set consists of over 1500 one- and two-minute EEG recordings, obtained from 109 volunteers, as described below.}
}

@inproceedings{schieferdecker_2009_GaussianMixtureReduction,
  title = {Gaussian Mixture Reduction via Clustering},
  booktitle = {2009 12th {{International Conference}} on {{Information Fusion}}},
  author = {Schieferdecker, Dennis and Huber, Marco F.},
  year = {2009},
  pages = {1536--1543},
  file = {../../Bibliography/Schieferdecker_2009_Gaussian mixture reduction via clustering.pdf}
}

@article{schoenberg_1938_MetricSpacesCompletely,
  title = {Metric {{Spaces}} and {{Completely Monotone Functions}}},
  author = {Schoenberg, I. J.},
  year = {1938},
  month = oct,
  journal = {The Annals of Mathematics},
  volume = {39},
  number = {4},
  eprint = {1968466},
  eprinttype = {jstor},
  pages = {811},
  issn = {0003486X},
  doi = {10.2307/1968466},
  urldate = {2024-09-12}
}

@book{scholkopf_2002_LearningKernelsSupport,
  title = {Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond},
  shorttitle = {Learning with Kernels},
  author = {Sch{\"o}lkopf, Bernhard and Smola, Alexander Johannes},
  year = {2002},
  series = {Adaptive Computation and Machine Learning Series},
  edition = {Reprint.},
  publisher = {MIT Press},
  address = {Cambridge, Mass.},
  isbn = {978-0-262-53657-8 978-0-262-19475-4},
  langid = {english},
  file = {../../Bibliography/Schölkopf_2002_Learning with kernels.pdf}
}

@article{schott_2001_TestsEqualityCovariance,
  title = {Some Tests for the Equality of Covariance Matrices},
  author = {Schott, James R.},
  year = {2001},
  month = mar,
  journal = {Journal of Statistical Planning and Inference},
  volume = {94},
  number = {1},
  pages = {25--36},
  issn = {03783758},
  doi = {10.1016/S0378-3758(00)00209-3},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Schott_2001_Some tests for the equality of covariance matrices.pdf}
}

@article{schott_2007_HighdimensionalTestsOneway,
  title = {Some High-Dimensional Tests for a One-Way {{MANOVA}}},
  author = {Schott, James R.},
  year = {2007},
  month = oct,
  journal = {Journal of Multivariate Analysis},
  volume = {98},
  number = {9},
  pages = {1825--1839},
  issn = {0047259X},
  doi = {10.1016/j.jmva.2006.11.007},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Schott_2007_Some high-dimensional tests for a one-way MANOVA.pdf}
}

@article{schott_2007_TestEqualityCovariance,
  title = {A Test for the Equality of Covariance Matrices When the Dimension Is Large Relative to the Sample Sizes},
  author = {Schott, James R.},
  year = {2007},
  month = aug,
  journal = {Computational Statistics \& Data Analysis},
  volume = {51},
  number = {12},
  pages = {6535--6542},
  issn = {01679473},
  doi = {10.1016/j.csda.2007.03.004},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Schott_2007_A test for the equality of covariance matrices when the dimension is large.pdf}
}

@inproceedings{schwander_2016_ComixJointEstimation,
  title = {Comix: {{Joint}} Estimation and Lightspeed Comparison of Mixture Models},
  shorttitle = {Comix},
  booktitle = {2016 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Schwander, Olivier and {Marchand-Maillet}, Stephane and Nielsen, Frank},
  year = {2016},
  month = mar,
  pages = {2449--2453},
  publisher = {IEEE},
  address = {Shanghai},
  doi = {10.1109/ICASSP.2016.7472117},
  urldate = {2022-07-25},
  isbn = {978-1-4799-9988-0},
  file = {../../Bibliography/Schwander_2016_Comix.pdf}
}

@article{schwertman_1979_SmoothingIndefiniteVariancecovariance,
  title = {Smoothing an Indefinite Variance-Covariance Matrix},
  author = {Schwertman, N.C and Allen, D.M},
  year = {1979},
  month = aug,
  journal = {Journal of Statistical Computation and Simulation},
  volume = {9},
  number = {3},
  pages = {183--194},
  issn = {0094-9655, 1563-5163},
  doi = {10.1080/00949657908810316},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Schwertman_1979_Smoothing an indefinite variance-covariance matrix.pdf}
}

@article{scott_1977_KernelDensityEstimation,
  title = {Kernel Density Estimation Revisited},
  author = {Scott, David W. and Tapia, Richard A. and Thompson, James R.},
  year = {1977},
  month = jan,
  journal = {Nonlinear Analysis: Theory, Methods \& Applications},
  volume = {1},
  number = {4},
  pages = {339--372},
  issn = {0362546X},
  doi = {10.1016/S0362-546X(97)90003-1},
  urldate = {2024-12-16},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english}
}

@article{selesnick_2015_Convex1DTotal,
  title = {Convex 1-{{D Total Variation Denoising}} with {{Non-convex Regularization}}},
  author = {Selesnick, Ivan W. and Parekh, Ankit and Bayram, Ilker},
  year = {2015},
  month = feb,
  journal = {IEEE Signal Processing Letters},
  volume = {22},
  number = {2},
  pages = {141--144},
  issn = {1070-9908, 1558-2361},
  doi = {10.1109/LSP.2014.2349356},
  urldate = {2022-03-27},
  file = {../../Bibliography/Selesnick_2015_Convex 1-D Total Variation Denoising with Non-convex Regularization.pdf}
}

@article{senbabaoglu_2015_CriticalLimitationsConsensus,
  title = {Critical Limitations of Consensus Clustering in Class Discovery},
  author = {{\textcommabelow S}enbabao{\u g}lu, Yasin and Michailidis, George and Li, Jun Z.},
  year = {2015},
  month = may,
  journal = {Scientific Reports},
  volume = {4},
  number = {1},
  pages = {6207},
  issn = {2045-2322},
  doi = {10.1038/srep06207},
  urldate = {2021-09-20},
  langid = {english},
  file = {../../Bibliography/Șenbabaoğlu_2015_Critical limitations of consensus clustering in class discovery.pdf}
}

@book{sengupta_2022_DirectionalStatisticsInnovative,
  title = {Directional {{Statistics}} for {{Innovative Applications}}: {{A Bicentennial Tribute}} to {{Florence Nightingale}}},
  shorttitle = {Directional {{Statistics}} for {{Innovative Applications}}},
  editor = {SenGupta, Ashis and Arnold, Barry C.},
  year = {2022},
  series = {Forum for {{Interdisciplinary Mathematics}}},
  publisher = {Springer Nature Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-19-1044-9},
  urldate = {2024-05-03},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-981-19104-3-2 978-981-19104-4-9},
  langid = {english},
  file = {../../Bibliography/SenGupta_2022_Directional Statistics for Innovative Applications.pdf}
}

@book{seo_2013_NonlinearInverseProblems,
  title = {Nonlinear Inverse Problems in Imaging},
  author = {Seo, Jin Keun and Woo, E. J.},
  year = {2013},
  publisher = {Wiley},
  address = {Chichester, West Sussex, United Kingdom},
  abstract = {"This book provides researchers and engineers in the imaging field with the skills they need to effectively deal with nonlinear inverse problems associated with different imaging modalities, including impedance imaging, optical tomography, elastography, and electrical source imaging. Focusing on numerically implementable methods, the book bridges the gap between theory and applications, helping readers tackle problems in applied mathematics and engineering. Complete, self-contained coverage includes basic concepts, models, computational methods, numerical simulations, examples, and case studies. Provides a step-by-step progressive treatment of topics for ease of understanding. Discusses the underlying physical phenomena as well as implementation details of image reconstruction algorithms as prerequisites for finding solutions to non linear inverse problems with practical significance and value. Includes end of chapter problems, case studies and examples with solutions throughout the book. Companion website will provide further examples and solutions, experimental data sets, open problems, teaching material such as PowerPoint slides and software including MATLAB m files. Essential reading for Graduate students and researchers in imaging science working across the areas of applied mathematics, biomedical engineering, and electrical engineering and specifically those involved in nonlinear imaging techniques, impedance imaging, optical tomography, elastography, and electrical source imaging"--},
  isbn = {978-1-118-47815-8 978-1-118-47816-5 978-1-118-47817-2},
  lccn = {TA1637},
  keywords = {Cross-sectional imaging,Image processing,Inverse problems (Differential equations),Mathematics,Nonlinear theories}
}

@article{shahbazi_2021_UsingDistanceRiemannian,
  title = {Using Distance on the {{Riemannian}} Manifold to Compare Representations in Brain and in Models},
  author = {Shahbazi, Mahdiyar and Shirali, Ali and Aghajan, Hamid and Nili, Hamed},
  year = {2021},
  month = oct,
  journal = {NeuroImage},
  volume = {239},
  pages = {118271},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2021.118271},
  urldate = {2024-06-05},
  langid = {english},
  file = {../../Bibliography/Shahbazi_2021_Using distance on the Riemannian manifold to compare representations in brain.pdf}
}

@inproceedings{sheikh_2007_ModeseekingMedoidshifts,
  title = {Mode-Seeking by {{Medoidshifts}}},
  booktitle = {2007 {{IEEE}} 11th {{International Conference}} on {{Computer Vision}}},
  author = {Sheikh, Yaser Ajmal and Khan, Erum Arif and Kanade, Takeo},
  year = {2007},
  pages = {1--8},
  publisher = {IEEE},
  address = {Rio de Janeiro, Brazil},
  doi = {10.1109/ICCV.2007.4408978},
  urldate = {2022-07-25},
  isbn = {978-1-4244-1630-1},
  file = {../../Bibliography/Sheikh_2007_Mode-seeking by Medoidshifts.pdf}
}

@article{sheikhalishahi_2019_NaturalLanguageProcessing,
  title = {Natural {{Language Processing}} of {{Clinical Notes}} on {{Chronic Diseases}}: {{Systematic Review}}},
  shorttitle = {Natural {{Language Processing}} of {{Clinical Notes}} on {{Chronic Diseases}}},
  author = {Sheikhalishahi, Seyedmostafa and Miotto, Riccardo and Dudley, Joel T and Lavelli, Alberto and Rinaldi, Fabio and Osmani, Venet},
  year = {2019},
  month = apr,
  journal = {JMIR Medical Informatics},
  volume = {7},
  number = {2},
  pages = {e12239},
  issn = {2291-9694},
  doi = {10.2196/12239},
  urldate = {2024-10-10},
  langid = {english},
  file = {../../Bibliography/Sheikhalishahi_2019_Natural Language Processing of Clinical Notes on Chronic Diseases.pdf}
}

@article{shen_2017_UsingConnectomebasedPredictive,
  title = {Using Connectome-Based Predictive Modeling to Predict Individual Behavior from Brain Connectivity},
  author = {Shen, Xilin and Finn, Emily S and Scheinost, Dustin and Rosenberg, Monica D and Chun, Marvin M and Papademetris, Xenophon and Constable, R Todd},
  year = {2017},
  month = mar,
  journal = {Nature Protocols},
  volume = {12},
  number = {3},
  pages = {506--518},
  issn = {1754-2189, 1750-2799},
  doi = {10.1038/nprot.2016.178},
  urldate = {2024-08-15},
  langid = {english},
  file = {../../Bibliography/Shen_2017_Using connectome-based predictive modeling to predict individual behavior from.pdf}
}

@article{shi_2000_NormalizedCutsImage,
  title = {Normalized Cuts and Image Segmentation},
  author = {Shi, Jianbo and Malik, Jitendra},
  year = {2000},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {22},
  number = {8},
  pages = {888--905},
  issn = {01628828},
  doi = {10.1109/34.868688},
  urldate = {2021-10-02},
  file = {../../Bibliography/Shi_2000_Normalized cuts and image segmentation.pdf}
}

@article{shi_2009_IntrinsicRegressionModels,
  title = {Intrinsic Regression Models for Manifold-Valued Data},
  author = {Shi, Xiaoyan and Styner, Martin and Lieberman, Jeffrey and Ibrahim, Joseph G. and Lin, Weili and Zhu, Hongtu},
  year = {2009},
  journal = {Medical image computing and computer-assisted intervention: MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
  volume = {12},
  number = {Pt 2},
  pages = {192--199},
  langid = {english},
  pmcid = {PMC4017371},
  pmid = {20426112},
  keywords = {Algorithms,Computer Simulation,Data Interpretation Statistical,Diffusion Magnetic Resonance Imaging,Hippocampus,Humans,Image Enhancement,Image Interpretation Computer-Assisted,Information Storage and Retrieval,Models Anatomic,Models Neurological,Models Statistical,Pattern Recognition Automated,Regression Analysis,Reproducibility of Results,Schizophrenia,Sensitivity and Specificity}
}

@book{shumway_2017_TimeSeriesAnalysis,
  title = {Time {{Series Analysis}} and {{Its Applications}}: {{With R Examples}}},
  shorttitle = {Time {{Series Analysis}} and {{Its Applications}}},
  author = {Shumway, Robert H. and Stoffer, David S.},
  year = {2017},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-52452-8},
  urldate = {2024-05-31},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-319-52451-1 978-3-319-52452-8},
  langid = {english},
  file = {../../Bibliography/Shumway_2017_Time Series Analysis and Its Applications.pdf}
}

@article{shung_2024_AdoptionGastroenterologyHospitalist,
  title = {Adoption of a {{Gastroenterology Hospitalist Model}} and the {{Impact}} on {{Inpatient Endoscopic Practice Volume}}: {{A Controlled Interrupted Time Series Analysis}}},
  shorttitle = {Adoption of a {{Gastroenterology Hospitalist Model}} and the {{Impact}} on {{Inpatient Endoscopic Practice Volume}}},
  author = {Shung, Dennis and Li, Darrick K. and You, Kisung and Hung, Kenneth W. and Laine, Loren and Hughes, Michelle L.},
  year = {2024},
  month = apr,
  journal = {iGIE},
  pages = {S2949708624000414},
  issn = {29497086},
  doi = {10.1016/j.igie.2024.04.008},
  urldate = {2024-04-26},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/Shung_2024_Adoption of a Gastroenterology Hospitalist Model and the Impact on Inpatient.pdf}
}

@article{shung_2024_ValidationElectronicHealth,
  title = {Validation of an {{Electronic Health Record-Based Machine Learning Model Compared}} to {{Clinical Risk Scores}} for {{Gastrointestinal Bleeding}}},
  author = {Shung, Dennis L. and Chan, Colleen E. and You, Kisung and Nakamura, Shinpei and Saarinen, Theo and Zheng, Neil S. and Simonov, Michael and Li, Darrick K. and Tsay, Cynthia and Kawamura, Yuki and Shen, Matthew and Hsiao, Allen and Sekhon, Jasjeet and Laine, Loren},
  year = {2024},
  month = jul,
  journal = {Gastroenterology},
  pages = {S0016508524051837},
  issn = {00165085},
  doi = {10.1053/j.gastro.2024.06.030},
  urldate = {2024-07-10},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/shung_2024_validation of an electronic health record-based machine learning model compared.pdf}
}

@book{silverman_2018_DensityEstimationStatistics,
  title = {Density {{Estimation}} for {{Statistics}} and {{Data Analysis}}},
  author = {Silverman, B.W.},
  year = {2018},
  month = feb,
  edition = {1},
  publisher = {Routledge},
  doi = {10.1201/9781315140919},
  urldate = {2024-12-16},
  isbn = {978-1-315-14091-9},
  langid = {english}
}

@article{siman-tov_2017_EarlyAgeRelatedFunctional,
  title = {Early {{Age-Related Functional Connectivity Decline}} in {{High-Order Cognitive Networks}}},
  author = {{Siman-Tov}, Tali and Bosak, Noam and Sprecher, Elliot and Paz, Rotem and Eran, Ayelet and {Aharon-Peretz}, Judith and Kahn, Itamar},
  year = {2017},
  month = jan,
  journal = {Frontiers in Aging Neuroscience},
  volume = {8},
  issn = {1663-4365},
  doi = {10.3389/fnagi.2016.00330},
  urldate = {2021-10-04},
  file = {../../Bibliography/Siman-Tov_2017_Early Age-Related Functional Connectivity Decline in High-Order Cognitive.pdf}
}

@article{simeon_2022_RiemannianGeometryFunctional,
  title = {Riemannian {{Geometry}} of {{Functional Connectivity Matrices}} for {{Multi-Site Attention-Deficit}}/{{Hyperactivity Disorder Data Harmonization}}},
  author = {Simeon, Guillem and Piella, Gemma and Camara, Oscar and Pareto, Deborah},
  year = {2022},
  month = may,
  journal = {Frontiers in Neuroinformatics},
  volume = {16},
  pages = {769274},
  issn = {1662-5196},
  doi = {10.3389/fninf.2022.769274},
  urldate = {2022-06-18},
  file = {../../Bibliography/Simeon_2022_Riemannian Geometry of Functional Connectivity Matrices for Multi-Site.pdf}
}

@article{singer_2012_VectorDiffusionMaps,
  title = {Vector Diffusion Maps and the Connection {{Laplacian}}},
  author = {Singer, A. and Wu, H.-T.},
  year = {2012},
  month = aug,
  journal = {Communications on Pure and Applied Mathematics},
  volume = {65},
  number = {8},
  pages = {1067--1144},
  issn = {00103640},
  doi = {10.1002/cpa.21395},
  urldate = {2021-11-10},
  langid = {english},
  file = {../../Bibliography/Singer_2012_Vector diffusion maps and the connection Laplacian.pdf}
}

@inproceedings{song_2008_TailoringDensityEstimation,
  title = {Tailoring Density Estimation via Reproducing Kernel Moment Matching},
  booktitle = {Proceedings of the 25th International Conference on {{Machine}} Learning - {{ICML}} '08},
  author = {Song, Le and Zhang, Xinhua and Smola, Alex and Gretton, Arthur and Sch{\"o}lkopf, Bernhard},
  year = {2008},
  pages = {992--999},
  publisher = {ACM Press},
  address = {Helsinki, Finland},
  doi = {10.1145/1390156.1390281},
  urldate = {2022-07-25},
  isbn = {978-1-60558-205-4},
  langid = {english},
  file = {../../Bibliography/Song_2008_Tailoring density estimation via reproducing kernel moment matching.pdf}
}

@inproceedings{spurek_2016_ClusteringGaussianDistributions,
  title = {Clustering of {{Gaussian}} Distributions},
  booktitle = {2016 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Spurek, Przemyslaw and Palka, Wieslaw},
  year = {2016},
  month = jul,
  pages = {3346--3353},
  publisher = {IEEE},
  address = {Vancouver, BC, Canada},
  doi = {10.1109/IJCNN.2016.7727627},
  urldate = {2022-07-25},
  isbn = {978-1-5090-0620-5},
  file = {../../Bibliography/Spurek_2016_Clustering of Gaussian distributions.pdf}
}

@inproceedings{sra_2012_NewMetricManifold,
  title = {A New Metric on the Manifold of Kernel Matrices with Application to Matrix Geometric Means},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Sra, Suvrit},
  editor = {Pereira, F. and Burges, C.J. and Bottou, L. and Weinberger, K.Q.},
  year = {2012},
  volume = {25},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Sra_2012_A new metric on the manifold of kernel matrices with application to matrix.pdf}
}

@article{sra_2012_ShortNoteParameter,
  title = {A Short Note on Parameter Approximation for von {{Mises-Fisher}} Distributions: And a Fast Implementation of {{I}} s (x)},
  shorttitle = {A Short Note on Parameter Approximation for von {{Mises-Fisher}} Distributions},
  author = {Sra, Suvrit},
  year = {2012},
  month = mar,
  journal = {Computational Statistics},
  volume = {27},
  number = {1},
  pages = {177--190},
  issn = {0943-4062, 1613-9658},
  doi = {10.1007/s00180-011-0232-x},
  urldate = {2022-02-08},
  langid = {english},
  file = {../../Bibliography/Sra_2012_A short note on parameter approximation for von Mises-Fisher distributions.pdf}
}

@article{sra_2015_PositiveDefiniteMatrices,
  title = {Positive Definite Matrices and the {{S-divergence}}},
  author = {Sra, Suvrit},
  year = {2015},
  month = oct,
  journal = {Proceedings of the American Mathematical Society},
  volume = {144},
  number = {7},
  pages = {2787--2797},
  issn = {0002-9939, 1088-6826},
  doi = {10.1090/proc/12953},
  urldate = {2022-06-22},
  abstract = {Hermitian positive definite (hpd) matrices form a self-dual convex cone whose interior is a Riemannian manifold of nonpositive curvature. The manifold view comes with a natural distance function but the conic view does not. Thus, drawing motivation from convex optimization we introduce the               S-divergence               , a distance-like function on the cone of hpd matrices. We study basic properties of the S-divergence and explore its connections to the Riemannian distance. In particular, we show that (i) its square-root is a distance, and (ii) it exhibits numerous nonpositive-curvature-like properties.},
  langid = {english},
  file = {../../Bibliography/Sra_2015_Positive definite matrices and the S-divergence.pdf}
}

@article{srivastava_2008_TestMeanVector,
  title = {A Test for the Mean Vector with Fewer Observations than the Dimension},
  author = {Srivastava, Muni S. and Du, Meng},
  year = {2008},
  month = mar,
  journal = {Journal of Multivariate Analysis},
  volume = {99},
  number = {3},
  pages = {386--402},
  issn = {0047259X},
  doi = {10.1016/j.jmva.2006.11.002},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Srivastava_2008_A test for the mean vector with fewer observations than the dimension.pdf}
}

@article{srivastava_2018_ScalableBayesBarycenter,
  title = {Scalable Bayes via Barycenter in Wasserstein Space},
  author = {Srivastava, Sanvesh and Li, Cheng and Dunson, David B.},
  year = {2018},
  month = jan,
  journal = {Journal of Machine Learning Research},
  volume = {19},
  number = {1},
  pages = {312--346},
  publisher = {JMLR.org},
  issn = {1532-4435},
  issue_date = {January 2018},
  keywords = {barycenter,big data,distributed Bayesian computations,empirical measures,linear programming,optimal transportation,Wasserstein distance,Wasserstein space},
  file = {../../Bibliography/Srivastava_2018_Scalable bayes via barycenter in wasserstein space.pdf}
}

@inproceedings{staib_2017_WassersteinKmeansCloud,
  title = {Wasserstein K-Means++ for Cloud Regime Histogram Clustering},
  booktitle = {Proceedings of the Seventh International Workshop on Climate Informatics: {{CI}} 2017},
  author = {Staib, Matthew and Jegelka, Stefanie},
  year = {2017},
  file = {../../Bibliography/Staib_2017_Wasserstein k-means++ for cloud regime histogram clustering.pdf}
}

@book{stein_2011_FunctionalAnalysisIntroduction,
  title = {Functional Analysis: Introduction to Further Topics in Analysis},
  shorttitle = {Functional Analysis},
  author = {Stein, Elias M. and Shakarchi, Rami},
  year = {2011},
  series = {Princeton Lectures in Analysis},
  number = {4},
  publisher = {Princeton University Press},
  address = {Princeton},
  isbn = {978-0-691-11387-6},
  lccn = {QA320 .S839 2011},
  keywords = {Functional analysis,MATHEMATICS / Functional Analysis}
}

@article{storn_1997_DifferentialEvolutionSimple,
  title = {Differential {{Evolution}} -- {{A Simple}} and {{Efficient Heuristic}} for Global {{Optimization}} over {{Continuous Spaces}}},
  author = {Storn, Rainer and Price, Kenneth},
  year = {1997},
  journal = {Journal of Global Optimization},
  volume = {11},
  number = {4},
  pages = {341--359},
  issn = {09255001},
  doi = {10.1023/A:1008202821328},
  file = {../../Bibliography/Storn_1997_Differential Evolution – A Simple and Efficient Heuristic for global.pdf}
}

@article{strang_1993_FundamentalTheoremLinear,
  title = {The {{Fundamental Theorem}} of {{Linear Algebra}}},
  author = {Strang, Gilbert},
  year = {1993},
  month = nov,
  journal = {The American Mathematical Monthly},
  volume = {100},
  number = {9},
  eprint = {2324660},
  eprinttype = {jstor},
  pages = {848},
  issn = {00029890},
  doi = {10.2307/2324660},
  urldate = {2022-03-27},
  file = {../../Bibliography/Strang_1993_The Fundamental Theorem of Linear Algebra.pdf}
}

@article{strehl_2002_ClusterEnsemblesKnowledge,
  title = {Cluster Ensembles---a Knowledge Reuse Framework for Combining Multiple Partitions},
  author = {Strehl, Alexander and Ghosh, Joydeep},
  year = {2002},
  journal = {Journal of machine learning research},
  volume = {3},
  number = {Dec},
  pages = {583--617},
  file = {../../Bibliography/Strehl_2002_Cluster ensembles—a knowledge reuse framework for combining multiple partitions.pdf}
}

@article{stuart_2003_GeneCoexpressionNetworkGlobal,
  title = {A {{Gene-Coexpression Network}} for {{Global Discovery}} of {{Conserved Genetic Modules}}},
  author = {Stuart, Joshua M. and Segal, Eran and Koller, Daphne and Kim, Stuart K.},
  year = {2003},
  month = oct,
  journal = {Science},
  volume = {302},
  number = {5643},
  pages = {249--255},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1087447},
  urldate = {2023-12-15},
  langid = {english},
  file = {../../Bibliography/Stuart_2003_A Gene-Coexpression Network for Global Discovery of Conserved Genetic Modules.pdf}
}

@article{subbarao_2009_NonlinearMeanShift,
  title = {Nonlinear {{Mean Shift}} over {{Riemannian Manifolds}}},
  author = {Subbarao, Raghav and Meer, Peter},
  year = {2009},
  month = aug,
  journal = {International Journal of Computer Vision},
  volume = {84},
  number = {1},
  pages = {1--20},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-008-0195-8},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Subbarao_2009_Nonlinear Mean Shift over Riemannian Manifolds.pdf}
}

@article{sugrue_2004_MatchingBehaviorRepresentation,
  title = {Matching {{Behavior}} and the {{Representation}} of {{Value}} in the {{Parietal Cortex}}},
  author = {Sugrue, Leo P. and Corrado, Greg S. and Newsome, William T.},
  year = {2004},
  month = jun,
  journal = {Science},
  volume = {304},
  number = {5678},
  pages = {1782--1787},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1094765},
  urldate = {2024-01-18},
  abstract = {Psychologists and economists have long appreciated the contribution of reward history and expectation to decision-making. Yet we know little about how specific histories of choice and reward lead to an internal representation of the ``value'' of possible actions. We approached this problem through an integrated application of behavioral, computational, and physiological techniques. Monkeys were placed in a dynamic foraging environment in which they had to track the changing values of alternative choices through time. In this context, the monkeys' foraging behavior provided a window into their subjective valuation. We found that a simple model based on reward history can duplicate this behavior and that neurons in the parietal cortex represent the relative value of competing actions predicted by this model.},
  langid = {english},
  file = {../../Bibliography/Sugrue_2004_Matching Behavior and the Representation of Value in the Parietal Cortex.pdf}
}

@article{sun_2021_LightlikeNeuromanifoldsOccam,
  title = {Lightlike {{Neuromanifolds}}, {{Occam}}'s {{Razor}} and {{Deep Learning}}},
  author = {Sun, Ke and Nielsen, Frank},
  year = {2021},
  month = mar,
  journal = {arXiv:1905.11027 [cs, stat]},
  eprint = {1905.11027},
  primaryclass = {cs, stat},
  urldate = {2021-09-20},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {../../Bibliography/Sun_2021_Lightlike Neuromanifolds, Occam's Razor and Deep Learning.pdf}
}

@article{suthaharan_2021_ComputationalModelingBehavioral,
  title = {Computational Modeling of Behavioral Tasks: {{An}} Illustration on a Classic Reinforcement Learning Paradigm},
  shorttitle = {Computational Modeling of Behavioral Tasks},
  author = {Suthaharan, Praveen and Corlett, Philip R. and Ang, Yuen-Siang},
  year = {2021},
  month = jun,
  journal = {The Quantitative Methods for Psychology},
  volume = {17},
  number = {2},
  pages = {105--140},
  issn = {2292-1354},
  doi = {10.20982/tqmp.17.2.p105},
  urldate = {2023-12-24},
  file = {../../Bibliography/Suthaharan_2021_Computational modeling of behavioral tasks.pdf}
}

@book{sutton_1998_ReinforcementLearningIntroduction,
  title = {Reinforcement Learning: An Introduction},
  shorttitle = {Reinforcement Learning},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {1998},
  series = {Adaptive Computation and Machine Learning},
  publisher = {MIT Press},
  address = {Cambridge, Mass},
  isbn = {978-0-262-19398-6},
  lccn = {Q325.6 .S88 1998},
  keywords = {Reinforcement learning},
  file = {../../Bibliography/Sutton_1998_Reinforcement learning.pdf}
}

@article{szekely_2014_PartialDistanceCorrelation,
  title = {Partial Distance Correlation with Methods for Dissimilarities},
  author = {Sz{\'e}kely, G{\'a}bor J. and Rizzo, Maria L.},
  year = {2014},
  month = dec,
  journal = {The Annals of Statistics},
  volume = {42},
  number = {6},
  issn = {0090-5364},
  doi = {10.1214/14-AOS1255},
  urldate = {2023-02-07},
  file = {../../Bibliography/Székely_2014_Partial distance correlation with methods for dissimilarities.pdf}
}

@book{szekely_2023_EnergyDataDistance,
  title = {The Energy of Data and Distance Correlation},
  author = {Sz{\'e}kely, G{\'a}bor J. and Rizzo, Maria L.},
  year = {2023},
  series = {Chapman \& {{Hall}}/{{CRC Monographs}} on {{Statistics}} and {{Applied Probability}}},
  publisher = {CRC Press},
  address = {Boca Raton},
  abstract = {"Energy distance is a statistical distance between the distributions of random vectors, which characterizes equality of distributions. The name energy derives from Newton's gravitational potential energy, and there is an elegant relation to the notion of potential energy between statistical observations. Energy statistics are functions of distances between statistical observations in metric spaces. The authors hope this book will spark the interest of most statisticians who so far have not explored E-statistics and would like to apply these new methods using R. The Energy of Data and Distance Correlation is intended for teachers and students looking for dedicated material on energy statistics, but can serve as a supplement to a wide range of courses and areas, such as Monte Carlo methods, U-statistics or V-statistics, measures of multivariate dependence, goodness-of-fit tests, nonparametric methods and distance based methods"--},
  isbn = {978-1-4822-4274-4 978-1-03-243379-0},
  lccn = {QA276.A2 S94 2023},
  keywords = {Distribution (Probability theory),Mathematical statistics,Potential theory (Mathematics)}
}

@inproceedings{szummer_2001_PartiallyLabeledClassification,
  title = {Partially Labeled Classification with {{Markov}} Random Walks},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Szummer, Martin and Jaakkola, Tommi},
  editor = {Dietterich, T. and Becker, S. and Ghahramani, Z.},
  year = {2001},
  volume = {14},
  publisher = {MIT Press},
  file = {../../Bibliography/Szummer_2001_Partially labeled classification with Markov random walks.pdf}
}

@inproceedings{taddy_2015_BayesianEmpiricalBayesian,
  title = {Bayesian and Empirical Bayesian Forests},
  booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
  author = {Taddy, Matt and Chen, Chun-Sheng and Yu, Jun and Wyle, Mitch},
  year = {2015},
  series = {{{ICML}}'15},
  pages = {967--976},
  publisher = {JMLR.org},
  address = {Lille, France},
  file = {../../Bibliography/Taddy_2015_Bayesian and empirical bayesian forests.pdf}
}

@article{tak_2018_RepellingAttractingMetropolis,
  title = {A {{Repelling}}--{{Attracting Metropolis Algorithm}} for {{Multimodality}}},
  author = {Tak, Hyungsuk and Meng, Xiao-Li and Van Dyk, David A.},
  year = {2018},
  month = jul,
  journal = {Journal of Computational and Graphical Statistics},
  volume = {27},
  number = {3},
  pages = {479--490},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2017.1415911},
  urldate = {2023-12-19},
  langid = {english},
  file = {../../Bibliography/Tak_2018_A Repelling–Attracting Metropolis Algorithm for Multimodality.pdf}
}

@article{tak_2020_DataTransformingAugmentation,
  title = {Data Transforming Augmentation for Heteroscedastic Models},
  author = {Tak, Hyungsuk and You, Kisung and Ghosh, Sujit K. and Su, Bingyue and Kelly, Joseph},
  year = {2020},
  month = jul,
  journal = {Journal of Computational and Graphical Statistics},
  volume = {29},
  number = {3},
  pages = {659--667},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2019.1704295},
  urldate = {2022-10-30},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/Tak_2020_Data transforming augmentation for heteroscedastic models.pdf}
}

@article{takatsu_2011_WassersteinGeometryGaussian,
  title = {Wasserstein Geometry of {{Gaussian}} Measures},
  author = {Takatsu, Asuka},
  year = {2011},
  journal = {Osaka Journal of Mathematics},
  volume = {48},
  number = {4},
  pages = {1005--1026},
  publisher = {{Osaka University and Osaka Metropolitan University, Departments of Mathematics}},
  file = {../../Bibliography/Takatsu_2011_Wasserstein geometry of Gaussian measures.pdf}
}

@article{tanabe_2007_ParameterEstimationMises,
  title = {Parameter Estimation for von {{Mises}}--{{Fisher}} Distributions},
  author = {Tanabe, Akihiro and Fukumizu, Kenji and Oba, Shigeyuki and Takenouchi, Takashi and Ishii, Shin},
  year = {2007},
  month = apr,
  journal = {Computational Statistics},
  volume = {22},
  number = {1},
  pages = {145--157},
  issn = {0943-4062, 1613-9658},
  doi = {10.1007/s00180-007-0030-7},
  urldate = {2024-04-23},
  langid = {english},
  file = {../../Bibliography/Tanabe_2007_Parameter estimation for von Mises–Fisher distributions.pdf}
}

@article{tetali_1991_RandomWalksEffective,
  title = {Random Walks and the Effective Resistance of Networks},
  author = {Tetali, Prasad},
  year = {1991},
  month = jan,
  journal = {Journal of Theoretical Probability},
  volume = {4},
  number = {1},
  pages = {101--109},
  issn = {0894-9840, 1572-9230},
  doi = {10.1007/BF01046996},
  urldate = {2024-08-30},
  copyright = {http://www.springer.com/tdm},
  langid = {english}
}

@article{thanwerdas_2021_GeodesicQuotientAffineMetrics,
  title = {Geodesic of the {{Quotient-Affine Metrics}} on {{Full-Rank Correlation Matrices}}},
  author = {Thanwerdas, Yann and Pennec, Xavier},
  year = {2021},
  month = mar,
  journal = {arXiv:2103.04621 [math]},
  eprint = {2103.04621},
  primaryclass = {math},
  urldate = {2021-07-15},
  abstract = {Correlation matrices are used in many domains of neurosciences such as fMRI, EEG, MEG. However, statistical analyses often rely on embeddings into a Euclidean space or into Symmetric Positive Definite matrices which do not provide intrinsic tools. The quotient-affine metric was recently introduced as the quotient of the affine-invariant metric on SPD matrices by the action of diagonal matrices. In this work, we provide most of the fundamental Riemannian operations of the quotient-affine metric: the expression of the metric itself, the geodesics with initial tangent vector, the Levi-Civita connection and the curvature.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Differential Geometry},
  file = {../../Bibliography/Thanwerdas_2021_Geodesic of the Quotient-Affine Metrics on Full-Rank Correlation Matrices.pdf}
}

@incollection{thanwerdas_2021_GeodesicsCurvatureQuotientAffine,
  title = {Geodesics and {{Curvature}} of the {{Quotient-Affine Metrics}} on {{Full-Rank Correlation Matrices}}},
  booktitle = {Geometric {{Science}} of {{Information}}},
  author = {Thanwerdas, Yann and Pennec, Xavier},
  editor = {Nielsen, Frank and Barbaresco, Fr{\'e}d{\'e}ric},
  year = {2021},
  volume = {12829},
  pages = {93--102},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-80209-7_11},
  urldate = {2021-08-16},
  isbn = {978-3-030-80208-0 978-3-030-80209-7},
  langid = {english},
  file = {../../Bibliography/Thanwerdas_2021_Geodesics and Curvature of the Quotient-Affine Metrics on Full-Rank Correlation.pdf}
}

@article{thanwerdas_2022_TheoreticallyComputationallyConvenient,
  title = {Theoretically and {{Computationally Convenient Geometries}} on {{Full-Rank Correlation Matrices}}},
  author = {Thanwerdas, Yann and Pennec, Xavier},
  year = {2022},
  month = dec,
  journal = {SIAM Journal on Matrix Analysis and Applications},
  volume = {43},
  number = {4},
  pages = {1851--1872},
  issn = {0895-4798, 1095-7162},
  doi = {10.1137/22M1471729},
  urldate = {2023-11-25},
  langid = {english},
  file = {../../Bibliography/Thanwerdas_2022_Theoretically and Computationally Convenient Geometries on Full-Rank.pdf}
}

@article{thomas_2022_LearningSubspacesDifferent,
  title = {Learning {{Subspaces}} of {{Different Dimensions}}},
  author = {Thomas, Brian St. and You, Kisung and Lin, Lizhen and Lim, Lek-Heng and Mukherjee, Sayan},
  year = {2022},
  month = apr,
  journal = {Journal of Computational and Graphical Statistics},
  volume = {31},
  number = {2},
  pages = {337--350},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2021.2000420},
  urldate = {2022-07-07},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/Thomas_2022_Learning Subspaces of Different Dimensions.pdf}
}

@article{thulin_2014_HighdimensionalTwosampleTest,
  title = {A High-Dimensional Two-Sample Test for the Mean Using Random Subspaces},
  author = {Thulin, M{\aa}ns},
  year = {2014},
  month = jun,
  journal = {Computational Statistics \& Data Analysis},
  volume = {74},
  pages = {26--38},
  issn = {01679473},
  doi = {10.1016/j.csda.2013.12.003},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Thulin_2014_A high-dimensional two-sample test for the mean using random subspaces.pdf}
}

@article{tibshirani_1996_RegressionShrinkageSelection,
  title = {Regression {{Shrinkage}} and {{Selection Via}} the {{Lasso}}},
  author = {Tibshirani, Robert},
  year = {1996},
  month = jan,
  journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {58},
  number = {1},
  pages = {267--288},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/j.2517-6161.1996.tb02080.x},
  urldate = {2024-08-15},
  copyright = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
  langid = {english}
}

@article{tipping_1999_MixturesProbabilisticPrincipal,
  title = {Mixtures of {{Probabilistic Principal Component Analyzers}}},
  author = {Tipping, Michael E. and Bishop, Christopher M.},
  year = {1999},
  month = feb,
  journal = {Neural Computation},
  volume = {11},
  number = {2},
  pages = {443--482},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/089976699300016728},
  urldate = {2024-05-10},
  abstract = {Principal component analysis (PCA) is one of the most popular techniques for processing, compressing, and visualizing data, although its effectiveness is limited by its global linearity. While nonlinear variants of PCA have been proposed, an alternative paradigm is to capture data complexity by a combination of local linear PCA projections. However, conventional PCA does not correspond to a probability density, and so there is no unique way to combine PCA models. Therefore, previous attempts to formulate mixture models for PCA have been ad hoc to some extent. In this article, PCA is formulated within a maximum likelihood framework, based on a specific form of gaussian latent variable model. This leads to a well-defined mixture model for probabilistic principal component analyzers, whose parameters can be determined using an expectation-maximization algorithm. We discuss the advantages of this model in the context of clustering, density modeling, and local dimensionality reduction, and we demonstrate its application to image compression and handwritten digit recognition.},
  langid = {english},
  file = {../../Bibliography/Tipping_1999_Mixtures of Probabilistic Principal Component Analyzers.pdf}
}

@article{tipping_1999_ProbabilisticPrincipalComponent,
  title = {Probabilistic {{Principal Component Analysis}}},
  author = {Tipping, Michael E. and Bishop, Christopher M.},
  year = {1999},
  month = sep,
  journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {61},
  number = {3},
  pages = {611--622},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/1467-9868.00196},
  urldate = {2024-05-10},
  abstract = {Summary             Principal component analysis (PCA) is a ubiquitous technique for data analysis and processing, but one which is not based on a probability model. We demonstrate how the principal axes of a set of observed data vectors may be determined through maximum likelihood estimation of parameters in a latent variable model that is closely related to factor analysis. We consider the properties of the associated likelihood function, giving an EM algorithm for estimating the principal subspace iteratively, and discuss, with illustrative examples, the advantages conveyed by this probabilistic approach to PCA.},
  copyright = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
  langid = {english},
  file = {../../Bibliography/Tipping_1999_Probabilistic Principal Component Analysis.pdf}
}

@article{torgerson_1952_MultidimensionalScalingTheory,
  title = {Multidimensional Scaling: {{I}}. {{Theory}} and Method},
  shorttitle = {Multidimensional Scaling},
  author = {Torgerson, Warren S.},
  year = {1952},
  month = dec,
  journal = {Psychometrika},
  volume = {17},
  number = {4},
  pages = {401--419},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02288916},
  urldate = {2021-11-29},
  langid = {english},
  file = {../../Bibliography/Torgerson_1952_Multidimensional scaling.pdf}
}

@article{townsend_2016_PymanoptPythonToolbox,
  title = {Pymanopt: {{A}} Python Toolbox for Optimization on Manifolds Using Automatic Differentiation},
  author = {Townsend, James and Koep, Niklas and Weichwald, Sebastian},
  year = {2016},
  journal = {Journal of Machine Learning Research},
  volume = {17},
  number = {137},
  pages = {1--5},
  file = {../../Bibliography/Townsend_2016_Pymanopt.pdf}
}

@article{tropp_2018_SimplicialFacesSet,
  title = {Simplicial {{Faces}} of the {{Set}} of {{Correlation Matrices}}},
  author = {Tropp, Joel A.},
  year = {2018},
  month = sep,
  journal = {Discrete \& Computational Geometry},
  volume = {60},
  number = {2},
  pages = {512--529},
  issn = {0179-5376, 1432-0444},
  doi = {10.1007/s00454-017-9961-0},
  urldate = {2021-09-27},
  langid = {english},
  file = {../../Bibliography/Tropp_2018_Simplicial Faces of the Set of Correlation Matrices.pdf}
}

@manual{tsagris_2021_DirectionalCollectionFunctions,
  type = {Manual},
  title = {Directional: {{A}} Collection of {{R}} Functions for Directional Data Analysis},
  author = {Tsagris, Michail and Athineou, Giorgos and Adam, Christos and Sajib, Anamul and Amson, Eli and Waldstein, Micah J.},
  year = {2021}
}

@book{tsybakov_2009_IntroductionNonparametricEstimation,
  title = {Introduction to Nonparametric Estimation},
  author = {Tsybakov, Alexandre B.},
  year = {2009},
  series = {Springer Series in Statistics},
  publisher = {Springer},
  address = {New York ; London},
  isbn = {978-0-387-79051-0 978-0-387-79052-7},
  lccn = {QA278.8 .T79 2009},
  keywords = {Estimation theory,Nonparametric statistics},
  annotation = {OCLC: ocn300399286},
  file = {../../Bibliography/Tsybakov_2009_Introduction to nonparametric estimation.pdf}
}

@book{tu_2011_IntroductionManifolds,
  title = {An {{Introduction}} to {{Manifolds}}},
  author = {Tu, Loring W.},
  year = {2011},
  series = {Universitext},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4419-7400-6},
  urldate = {2024-06-07},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-1-4419-7399-3 978-1-4419-7400-6},
  langid = {english},
  file = {../../Bibliography/Tu_2011_An Introduction to Manifolds.pdf}
}

@article{tucker_2021_VariableSelectionGlobal,
  title = {Variable {{Selection}} for {{Global Fr{\'e}chet Regression}}},
  author = {Tucker, Danielle C. and Wu, Yichao and M{\"u}ller, Hans-Georg},
  year = {2021},
  month = sep,
  journal = {Journal of the American Statistical Association},
  pages = {1--15},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2021.1969240},
  urldate = {2022-03-10},
  langid = {english}
}

@book{udriste_2013_ConvexFunctionsOptimization,
  title = {Convex {{Functions}} and {{Optimization Methods}} on {{Riemannian Manifolds}}.},
  author = {Udriste, Constantin},
  year = {2013},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  urldate = {2021-11-05},
  isbn = {978-94-015-8390-9},
  langid = {english},
  annotation = {OCLC: 1066189744},
  file = {../../Bibliography/Udriste_2013_Convex Functions and Optimization Methods on Riemannian Manifolds.pdf}
}

@article{ulfarsson_2008_DimensionEstimationNoisy,
  title = {Dimension {{Estimation}} in {{Noisy PCA With SURE}} and {{Random Matrix Theory}}},
  author = {Ulfarsson, M.O. and Solo, V.},
  year = {2008},
  month = dec,
  journal = {IEEE Transactions on Signal Processing},
  volume = {56},
  number = {12},
  pages = {5804--5816},
  issn = {1053-587X, 1941-0476},
  doi = {10.1109/TSP.2008.2005865},
  urldate = {2022-07-25}
}

@article{ulfarsson_2015_SelectingNumberPrincipal,
  title = {Selecting the {{Number}} of {{Principal Components}} with {{SURE}}},
  author = {Ulfarsson, Magnus O. and Solo, Victor},
  year = {2015},
  month = feb,
  journal = {IEEE Signal Processing Letters},
  volume = {22},
  number = {2},
  pages = {239--243},
  issn = {1070-9908, 1558-2361},
  doi = {10.1109/LSP.2014.2337276},
  urldate = {2022-07-25}
}

@article{unlu_2019_EstimatingNumberClusters,
  title = {Estimating the Number of Clusters in a Dataset via Consensus Clustering},
  author = {{\"U}nl{\"u}, Ramazan and Xanthopoulos, Petros},
  year = {2019},
  month = jul,
  journal = {Expert Systems with Applications},
  volume = {125},
  pages = {33--39},
  issn = {09574174},
  doi = {10.1016/j.eswa.2019.01.074},
  urldate = {2021-09-20},
  langid = {english},
  file = {../../Bibliography/Ünlü_2019_Estimating the number of clusters in a dataset via consensus clustering.pdf}
}

@misc{uscidda_2023_MongeGapRegularizer,
  title = {The {{Monge Gap}}: {{A Regularizer}} to {{Learn All Transport Maps}}},
  shorttitle = {The {{Monge Gap}}},
  author = {Uscidda, Th{\'e}o and Cuturi, Marco},
  year = {2023},
  month = feb,
  number = {arXiv:2302.04953},
  eprint = {2302.04953},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2023-03-17},
  abstract = {Optimal transport (OT) theory has been been used in machine learning to study and characterize maps that can push-forward efficiently a probability measure onto another. Recent works have drawn inspiration from Brenier's theorem, which states that when the ground cost is the squared-Euclidean distance, the ``best'' map to morph a continuous measure in \${\textbackslash}mathcal\{P\}({\textbackslash}Rd)\$ into another must be the gradient of a convex function. To exploit that result, [Makkuva+ 2020, Korotin+2020] consider maps \$T={\textbackslash}nabla f\_{\textbackslash}theta\$, where \$f\_{\textbackslash}theta\$ is an input convex neural network (ICNN), as defined by Amos+2017, and fit \${\textbackslash}theta\$ with SGD using samples. Despite their mathematical elegance, fitting OT maps with ICNNs raises many challenges, due notably to the many constraints imposed on \${\textbackslash}theta\$; the need to approximate the conjugate of \$f\_{\textbackslash}theta\$; or the limitation that they only work for the squared-Euclidean cost. More generally, we question the relevance of using Brenier's result, which only applies to densities, to constrain the architecture of candidate maps fitted on samples. Motivated by these limitations, we propose a radically different approach to estimating OT maps: Given a cost \$c\$ and a reference measure \${\textbackslash}rho\$, we introduce a regularizer, the Monge gap \${\textbackslash}mathcal\{M\}{\textasciicircum}c\_\{{\textbackslash}rho\}(T)\$ of a map \$T\$. That gap quantifies how far a map \$T\$ deviates from the ideal properties we expect from a \$c\$-OT map. In practice, we drop all architecture requirements for \$T\$ and simply minimize a distance (e.g., the Sinkhorn divergence) between \$T{\textbackslash}sharp{\textbackslash}mu\$ and \${\textbackslash}nu\$, regularized by \${\textbackslash}mathcal\{M\}{\textasciicircum}c\_{\textbackslash}rho(T)\$. We study \${\textbackslash}mathcal\{M\}{\textasciicircum}c\_\{{\textbackslash}rho\}\$, and show how our simple pipeline outperforms significantly other baselines in practice.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {../../Bibliography/Uscidda_2023_The Monge Gap.pdf}
}

@book{vaart_1996_WeakConvergenceEmpirical,
  title = {Weak Convergence and Empirical Processes},
  author = {van der Vaart, A. W. and Wellner, Jon A.},
  year = {1996},
  series = {Springer Series in Statistics},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-94640-5},
  lccn = {QA274 .V33 1996},
  keywords = {Convergence,Distribution (Probability theory),Sampling (Statistics),Stochastic processes}
}

@book{vaart_1998_AsymptoticStatistics,
  title = {Asymptotic Statistics},
  author = {van der Vaart, A. W.},
  year = {1998},
  series = {Cambridge Series in Statistical and Probabilistic Mathematics},
  publisher = {Cambridge University Press},
  address = {Cambridge, UK ; New York, NY, USA},
  isbn = {978-0-521-49603-2},
  lccn = {QA276 .V22 1998},
  keywords = {Asymptotic theory,Mathematical statistics},
  file = {../../Bibliography/Vaart_1998_Asymptotic statistics.pdf}
}

@article{vandermaaten_2008_VisualizingDataUsing,
  title = {Visualizing Data Using T-{{SNE}}},
  author = {{van der Maaten}, Laurens and Hinton, Geoffrey},
  year = {2008},
  journal = {Journal of Machine Learning Research},
  volume = {9},
  number = {86},
  pages = {2579--2605},
  file = {../../Bibliography/van der Maaten_2008_Visualizing data using t-SNE.pdf}
}

@article{vanessen_2012_HumanConnectomeProject,
  title = {The {{Human Connectome Project}}: {{A}} Data Acquisition Perspective},
  shorttitle = {The {{Human Connectome Project}}},
  author = {Van Essen, D.C. and Ugurbil, K. and Auerbach, E. and Barch, D. and Behrens, T.E.J. and Bucholz, R. and Chang, A. and Chen, L. and Corbetta, M. and Curtiss, S.W. and Della Penna, S. and Feinberg, D. and Glasser, M.F. and Harel, N. and Heath, A.C. and {Larson-Prior}, L. and Marcus, D. and Michalareas, G. and Moeller, S. and Oostenveld, R. and Petersen, S.E. and Prior, F. and Schlaggar, B.L. and Smith, S.M. and Snyder, A.Z. and Xu, J. and Yacoub, E.},
  year = {2012},
  month = oct,
  journal = {NeuroImage},
  volume = {62},
  number = {4},
  pages = {2222--2231},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2012.02.018},
  urldate = {2022-08-28},
  langid = {english},
  file = {../../Bibliography/Van Essen_2012_The Human Connectome Project.pdf}
}

@book{vanrossum_2009_PythonReferenceManual,
  title = {Python 3 Reference Manual},
  author = {Van Rossum, Guido and Drake, Fred L.},
  year = {2009},
  publisher = {CreateSpace},
  address = {Scotts Valley, CA},
  isbn = {1-4414-1269-7}
}

@article{vardi_2000_MultivariateL1medianAssociated,
  title = {The Multivariate {{L1-median}} and Associated Data Depth},
  author = {Vardi, Y. and Zhang, C.-H.},
  year = {2000},
  month = feb,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {97},
  number = {4},
  pages = {1423--1426},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.97.4.1423},
  urldate = {2021-11-11},
  langid = {english},
  file = {../../Bibliography/Vardi_2000_The multivariate L1-median and associated data depth.pdf}
}

@incollection{varoquaux_2010_DetectionBrainFunctionalConnectivity,
  title = {Detection of {{Brain Functional-Connectivity Difference}} in {{Post-stroke Patients Using Group-Level Covariance Modeling}}},
  booktitle = {Medical {{Image Computing}} and {{Computer-Assisted Intervention}} -- {{MICCAI}} 2010},
  author = {Varoquaux, Ga{\"e}l and Baronnet, Flore and Kleinschmidt, Andreas and Fillard, Pierre and Thirion, Bertrand},
  year = {2010},
  volume = {6361},
  pages = {200--208},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-15705-9_25},
  urldate = {2021-09-27},
  isbn = {978-3-642-15704-2 978-3-642-15705-9},
  langid = {english},
  file = {../../Bibliography/Varoquaux_2010_Detection of Brain Functional-Connectivity Difference in Post-stroke Patients.pdf}
}

@inproceedings{vasconcelos_1998_LearningMixtureHierarchies,
  title = {Learning Mixture Hierarchies},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Vasconcelos, Nuno and Lippman, Andrew},
  editor = {Kearns, M. and Solla, S. and Cohn, D.},
  year = {1998},
  volume = {11},
  publisher = {MIT Press},
  file = {../../Bibliography/vasconcelos_1998_learning mixture hierarchies.pdf}
}

@incollection{vedaldi_2008_QuickShiftKernel,
  title = {Quick {{Shift}} and {{Kernel Methods}} for {{Mode Seeking}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2008},
  author = {Vedaldi, Andrea and Soatto, Stefano},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Forsyth, David and Torr, Philip and Zisserman, Andrew},
  year = {2008},
  volume = {5305},
  pages = {705--718},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-88693-8_52},
  urldate = {2022-07-25},
  isbn = {978-3-540-88692-1 978-3-540-88693-8},
  langid = {english},
  file = {../../Bibliography/Vedaldi_2008_Quick Shift and Kernel Methods for Mode Seeking.pdf}
}

@article{vemuri_2011_TotalBregmanDivergence,
  title = {Total {{Bregman Divergence}} and {{Its Applications}} to {{DTI Analysis}}},
  author = {Vemuri, B C and {Meizhu Liu} and Amari, Shun-Ichi and Nielsen, F},
  year = {2011},
  month = feb,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {30},
  number = {2},
  pages = {475--483},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2010.2086464},
  urldate = {2022-07-25},
  file = {../../Bibliography/Vemuri_2011_Total Bregman Divergence and Its Applications to DTI Analysis.pdf}
}

@article{veneziano_2021_NovelStrategiesCharacterization,
  title = {Novel Strategies for the Characterization of Cancellous Bone Morphology: {{Virtual}} Isolation and Analysis},
  shorttitle = {Novel Strategies for the Characterization of Cancellous Bone Morphology},
  author = {Veneziano, Alessio and Cazenave, Marine and Alfieri, Fabio and Panetta, Daniele and Marchi, Damiano},
  year = {2021},
  month = aug,
  journal = {American Journal of Physical Anthropology},
  volume = {175},
  number = {4},
  pages = {920--930},
  issn = {0002-9483, 1096-8644},
  doi = {10.1002/ajpa.24272},
  urldate = {2022-08-04},
  langid = {english},
  file = {../../Bibliography/Veneziano_2021_Novel strategies for the characterization of cancellous bone morphology.pdf}
}

@article{vidal_2014_LowRankSubspace,
  title = {Low Rank Subspace Clustering ({{LRSC}})},
  author = {Vidal, Ren{\'e} and Favaro, Paolo},
  year = {2014},
  month = jul,
  journal = {Pattern Recognition Letters},
  volume = {43},
  pages = {47--61},
  issn = {01678655},
  doi = {10.1016/j.patrec.2013.08.006},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Vidal_2014_Low rank subspace clustering (LRSC).pdf}
}

@book{villani_2003_TopicsOptimalTransportation,
  title = {Topics in {{Optimal Transportation}}},
  author = {Villani, C{\'e}dric},
  year = {2003},
  series = {Graduate {{Studies}} in {{Mathematics}}},
  volume = {58},
  publisher = {American Mathematical Society},
  address = {S.l.},
  isbn = {978-0-8218-3312-4},
  langid = {english},
  annotation = {OCLC: 1282601012}
}

@book{villani_2009_OptimalTransportOld,
  title = {Optimal Transport: Old and New},
  shorttitle = {Optimal Transport},
  author = {Villani, C{\'e}dric},
  year = {2009},
  series = {Grundlehren Der Mathematischen {{Wissenschaften}}},
  number = {338},
  publisher = {Springer},
  address = {Berlin},
  isbn = {978-3-540-71049-3},
  lccn = {QA402.5 .V538 2009},
  keywords = {Dynamics,Dynamique,Geometrie differentielle,Geometry Differential,Mathematical optimization,Optimisation mathematique,Probabilites,Probabilities,Problemes de transport (Programmation),Transportation problems (Programming)},
  annotation = {OCLC: ocn244421231}
}

@inproceedings{vinh_2009_NovelApproachAutomatic,
  title = {A {{Novel Approach}} for {{Automatic Number}} of {{Clusters Detection}} in {{Microarray Data Based}} on {{Consensus Clustering}}},
  booktitle = {2009 {{Ninth IEEE International Conference}} on {{Bioinformatics}} and {{BioEngineering}}},
  author = {Vinh, Nguyen Xuan and Epps, Julien},
  year = {2009},
  month = jun,
  pages = {84--91},
  publisher = {IEEE},
  address = {Taichung, Taiwan},
  doi = {10.1109/BIBE.2009.19},
  urldate = {2021-09-20},
  isbn = {978-0-7695-3656-9},
  file = {../../Bibliography/Vinh_2009_A Novel Approach for Automatic Number of Clusters Detection in Microarray Data.pdf}
}

@article{vishwanathan_2010_GraphKernels,
  title = {Graph Kernels},
  author = {Vishwanathan, S.V.N. and Schraudolph, Nicol N. and Kondor, Risi and Borgwardt, Karsten M.},
  year = {2010},
  journal = {Journal of Machine Learning Research},
  volume = {11},
  number = {40},
  pages = {1201--1242},
  file = {../../Bibliography/Vishwanathan_2010_Graph kernels.pdf}
}

@article{volkow_2019_NeuroscienceDrugReward,
  title = {The {{Neuroscience}} of {{Drug Reward}} and {{Addiction}}},
  author = {Volkow, Nora D. and Michaelides, Michael and Baler, Ruben},
  year = {2019},
  month = oct,
  journal = {Physiological Reviews},
  volume = {99},
  number = {4},
  pages = {2115--2140},
  issn = {0031-9333, 1522-1210},
  doi = {10.1152/physrev.00014.2018},
  urldate = {2023-12-14},
  abstract = {Drug consumption is driven by a drug's pharmacological effects, which are experienced as rewarding, and is influenced by genetic, developmental, and psychosocial factors that mediate drug accessibility, norms, and social support systems or lack thereof. The reinforcing effects of drugs mostly depend on dopamine signaling in the nucleus accumbens, and chronic drug exposure triggers glutamatergic-mediated neuroadaptations in dopamine striato-thalamo-cortical (predominantly in prefrontal cortical regions including orbitofrontal cortex and anterior cingulate cortex) and limbic pathways (amygdala and hippocampus) that, in vulnerable individuals, can result in addiction. In parallel, changes in the extended amygdala result in negative emotional states that perpetuate drug taking as an attempt to temporarily alleviate them. Counterintuitively, in the addicted person, the actual drug consumption is associated with an attenuated dopamine increase in brain reward regions, which might contribute to drug-taking behavior to compensate for the difference between the magnitude of the expected reward triggered by the conditioning to drug cues and the actual experience of it. Combined, these effects result in an enhanced motivation to ``seek the drug'' (energized by dopamine increases triggered by drug cues) and an impaired prefrontal top-down self-regulation that favors compulsive drug-taking against the backdrop of negative emotionality and an enhanced interoceptive awareness of ``drug hunger.'' Treatment interventions intended to reverse these neuroadaptations show promise as therapeutic approaches for addiction.},
  langid = {english},
  file = {../../Bibliography/Volkow_2019_The Neuroscience of Drug Reward and Addiction.pdf}
}

@article{vonluxburg_2007_TutorialSpectralClustering,
  title = {A Tutorial on Spectral Clustering},
  author = {{von Luxburg}, Ulrike},
  year = {2007},
  month = dec,
  journal = {Statistics and Computing},
  volume = {17},
  number = {4},
  pages = {395--416},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-007-9033-z},
  urldate = {2021-10-02},
  langid = {english},
  file = {../../Bibliography/von Luxburg_2007_A tutorial on spectral clustering.pdf}
}

@inproceedings{vonluxburg_2010_GettingLostSpace,
  title = {Getting Lost in Space: Large Sample Analysis of the Commute Distance},
  booktitle = {Proceedings of the 23rd {{International Conference}} on {{Neural Information Processing Systems}} - {{Volume}} 2},
  author = {{von Luxburg}, Ulrike and Radl, Agnes and Hein, Matthias},
  year = {2010},
  series = {{{NIPS}}'10},
  pages = {2622--2630},
  publisher = {Curran Associates Inc.}
}

@book{wackerly_2008_MathematicalStatisticsApplications,
  title = {Mathematical Statistics with Applications},
  author = {Wackerly, Dennis D. and Mendenhall, William and Scheaffer, Richard L.},
  year = {2008},
  edition = {7th ed},
  publisher = {Thomson Brooks/Cole},
  address = {Belmont, CA},
  isbn = {978-0-495-11081-1},
  lccn = {QA276 .M426 2008},
  keywords = {Mathematical statistics}
}

@article{wade_2018_BayesianClusterAnalysis,
  title = {Bayesian {{Cluster Analysis}}: {{Point Estimation}} and {{Credible Balls}} (with {{Discussion}})},
  shorttitle = {Bayesian {{Cluster Analysis}}},
  author = {Wade, Sara and Ghahramani, Zoubin},
  year = {2018},
  month = jun,
  journal = {Bayesian Analysis},
  volume = {13},
  number = {2},
  issn = {1936-0975},
  doi = {10.1214/17-BA1073},
  urldate = {2022-07-25},
  file = {../../Bibliography/Wade_2018_Bayesian Cluster Analysis.pdf}
}

@book{wainwright_2019_HighDimensionalStatisticsNonAsymptotic,
  title = {High-{{Dimensional Statistics}}: {{A Non-Asymptotic Viewpoint}}},
  shorttitle = {High-{{Dimensional Statistics}}},
  author = {Wainwright, Martin J.},
  year = {2019},
  month = feb,
  edition = {1},
  publisher = {Cambridge University Press},
  doi = {10.1017/9781108627771},
  urldate = {2024-07-24},
  copyright = {https://www.cambridge.org/core/terms},
  isbn = {978-1-108-62777-1 978-1-108-49802-9}
}

@article{walter_2004_HMDSNewApproach,
  title = {H-{{MDS}}: A New Approach for Interactive Visualization with Multidimensional Scaling in the Hyperbolic Space},
  shorttitle = {H-{{MDS}}},
  author = {Walter, J{\"o}rg A},
  year = {2004},
  month = jun,
  journal = {Information Systems},
  volume = {29},
  number = {4},
  pages = {273--292},
  issn = {03064379},
  doi = {10.1016/j.is.2003.10.002},
  urldate = {2023-03-24},
  langid = {english},
  file = {../../Bibliography/Walter_2004_H-MDS.pdf}
}

@article{wang_2004_ConstrainedVariationalPrinciple,
  title = {A {{Constrained Variational Principle}} for {{Direct Estimation}} and {{Smoothing}} of the {{Diffusion Tensor Field From Complex DWI}}},
  author = {Wang, Z. and Vemuri, B.C. and Chen, Y. and Mareci, T.H.},
  year = {2004},
  month = aug,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {23},
  number = {8},
  pages = {930--939},
  issn = {0278-0062},
  doi = {10.1109/TMI.2004.831218},
  urldate = {2022-06-21},
  langid = {english},
  file = {../../Bibliography/Wang_2004_A Constrained Variational Principle for Direct Estimation and Smoothing of the.pdf}
}

@article{wang_2007_CLUESNonparametricClustering,
  title = {{{CLUES}}: {{A}} Non-Parametric Clustering Method Based on Local Shrinking},
  shorttitle = {{{CLUES}}},
  author = {Wang, Xiaogang and Qiu, Weiliang and Zamar, Ruben H.},
  year = {2007},
  month = sep,
  journal = {Computational Statistics \& Data Analysis},
  volume = {52},
  number = {1},
  pages = {286--298},
  issn = {01679473},
  doi = {10.1016/j.csda.2006.12.016},
  urldate = {2021-09-10},
  langid = {english},
  file = {../../Bibliography/Wang_2007_CLUES.pdf}
}

@inproceedings{wang_2007_TraceRatioVs,
  title = {Trace {{Ratio}} vs. {{Ratio Trace}} for {{Dimensionality Reduction}}},
  booktitle = {2007 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Wang, Huan and Yan, Shuicheng and Xu, Dong and Tang, Xiaoou and Huang, Thomas},
  year = {2007},
  month = jun,
  pages = {1--8},
  publisher = {IEEE},
  address = {Minneapolis, MN},
  doi = {10.1109/CVPR.2007.382983},
  urldate = {2021-11-13},
  isbn = {978-1-4244-1179-5},
  file = {../../Bibliography/Wang_2007_Trace Ratio vs.pdf}
}

@incollection{wang_2009_ClosedFormJensenRenyiDivergence,
  title = {Closed-{{Form Jensen-Renyi Divergence}} for {{Mixture}} of {{Gaussians}} and {{Applications}} to {{Group-Wise Shape Registration}}},
  booktitle = {Medical {{Image Computing}} and {{Computer-Assisted Intervention}} -- {{MICCAI}} 2009},
  author = {Wang, Fei and {Syeda-Mahmood}, Tanveer and Vemuri, Baba C. and Beymer, David and Rangarajan, Anand},
  editor = {Yang, Guang-Zhong and Hawkes, David and Rueckert, Daniel and Noble, Alison and Taylor, Chris},
  year = {2009},
  volume = {5761},
  pages = {648--655},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-04268-3_80},
  urldate = {2022-07-25},
  isbn = {978-3-642-04267-6 978-3-642-04268-3},
  file = {../../Bibliography/Wang_2009_Closed-Form Jensen-Renyi Divergence for Mixture of Gaussians and Applications.pdf}
}

@incollection{wang_2010_GeometricMedianShiftRiemannian,
  title = {Geometric {{Median-Shift}} over {{Riemannian Manifolds}}},
  booktitle = {{{PRICAI}} 2010: {{Trends}} in {{Artificial Intelligence}}},
  author = {Wang, Yang and Huang, Xiaodi},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Zhang, Byoung-Tak and Orgun, Mehmet A.},
  year = {2010},
  volume = {6230},
  pages = {268--279},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-15246-7_26},
  urldate = {2022-07-25},
  isbn = {978-3-642-15245-0 978-3-642-15246-7},
  file = {../../Bibliography/Wang_2010_Geometric Median-Shift over Riemannian Manifolds.pdf}
}

@article{wang_2019_ImprovementSpectralClustering,
  title = {An {{Improvement}} of {{Spectral Clustering}} via {{Message Passing}} and {{Density Sensitive Similarity}}},
  author = {Wang, Lijuan and Ding, Shifei and Jia, Hongjie},
  year = {2019},
  journal = {IEEE Access},
  volume = {7},
  pages = {101054--101062},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2929948},
  urldate = {2022-07-25},
  file = {../../Bibliography/Wang_2019_An Improvement of Spectral Clustering via Message Passing and Density Sensitive.pdf}
}

@article{wartenberg_1985_MultivariateSpatialCorrelation,
  title = {Multivariate {{Spatial Correlation}}: {{A Method}} for {{Exploratory Geographical Analysis}}},
  shorttitle = {Multivariate {{Spatial Correlation}}},
  author = {Wartenberg, Daniel},
  year = {1985},
  journal = {Geographical Analysis},
  volume = {17},
  number = {4},
  pages = {263--283},
  issn = {00167363},
  doi = {10.1111/j.1538-4632.1985.tb00849.x},
  urldate = {2022-07-27},
  langid = {english},
  file = {../../Bibliography/Wartenberg_1985_Multivariate Spatial Correlation.pdf}
}

@article{wasserman_1969_EquivariantDifferentialTopology,
  title = {Equivariant Differential Topology},
  author = {Wasserman, Arthur G.},
  year = {1969},
  month = apr,
  journal = {Topology},
  volume = {8},
  number = {2},
  pages = {127--150},
  issn = {00409383},
  doi = {10.1016/0040-9383(69)90005-6},
  urldate = {2022-08-16},
  langid = {english},
  file = {../../Bibliography/Wasserman_1969_Equivariant differential topology.pdf}
}

@article{watson_1964_SmoothRegressionAnalysis,
  title = {Smooth Regression Analysis},
  author = {Watson, Geoffrey S.},
  year = {1964},
  journal = {Sankhy{\=a}: The Indian Journal of Statistics, Series A (1961-2002)},
  volume = {26},
  number = {4},
  eprint = {25049340},
  eprinttype = {jstor},
  pages = {359--372},
  publisher = {Springer},
  issn = {0581572X},
  urldate = {2023-12-14}
}

@article{wei_2007_FeatureSubsetSelection,
  title = {Feature {{Subset Selection}} and {{Ranking}} for {{Data Dimensionality Reduction}}},
  author = {Wei, Hua-liang and Billings, Stephen},
  year = {2007},
  month = jan,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {29},
  number = {1},
  pages = {162--166},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2007.250607},
  urldate = {2022-07-04},
  file = {../../Bibliography/Wei_2007_Feature Subset Selection and Ranking for Data Dimensionality Reduction.pdf}
}

@article{weinberg_2012_ComputingBayesFactor,
  title = {Computing the {{Bayes Factor}} from a {{Markov Chain Monte Carlo Simulation}} of the {{Posterior Distribution}}},
  author = {Weinberg, Martin D.},
  year = {2012},
  month = sep,
  journal = {Bayesian Analysis},
  volume = {7},
  number = {3},
  issn = {1936-0975},
  doi = {10.1214/12-BA725},
  urldate = {2024-01-10},
  file = {../../Bibliography/Weinberg_2012_Computing the Bayes Factor from a Markov Chain Monte Carlo Simulation of the.pdf}
}

@article{weiszfeld_1937_PointPourLequel,
  title = {Sur Le Point Pour Lequel La {{Somme}} Des Distances de n Points Donnes Est Minimum},
  author = {Weiszfeld, Endre},
  year = {1937},
  journal = {Tohoku Mathematical Journal, First Series},
  volume = {43},
  pages = {355--386}
}

@article{weiszfeld_2009_PointWhichSum,
  title = {On the Point for Which the Sum of the Distances to n given Points Is Minimum},
  author = {Weiszfeld, Endre and Plastria, Frank},
  year = {2009},
  month = mar,
  journal = {Annals of Operations Research},
  volume = {167},
  number = {1},
  pages = {7--41},
  issn = {0254-5330, 1572-9338},
  doi = {10.1007/s10479-008-0352-z},
  urldate = {2021-10-02},
  langid = {english},
  file = {../../Bibliography/Weiszfeld_2009_On the point for which the sum of the distances to n given points is minimum.pdf}
}

@article{wen_2010_AlternatingDirectionAugmented,
  title = {Alternating Direction Augmented {{Lagrangian}} Methods for Semidefinite Programming},
  author = {Wen, Zaiwen and Goldfarb, Donald and Yin, Wotao},
  year = {2010},
  month = dec,
  journal = {Mathematical Programming Computation},
  volume = {2},
  number = {3-4},
  pages = {203--230},
  issn = {1867-2949, 1867-2957},
  doi = {10.1007/s12532-010-0017-1},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Wen_2010_Alternating direction augmented Lagrangian methods for semidefinite programming.pdf}
}

@article{west_1993_ApproximatingPosteriorDistributions,
  title = {Approximating {{Posterior Distributions}} by {{Mixtures}}},
  author = {West, Mike},
  year = {1993},
  month = jan,
  journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {55},
  number = {2},
  pages = {409--422},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/j.2517-6161.1993.tb01911.x},
  urldate = {2025-01-05},
  abstract = {SUMMARY             Kernel density estimation techniques are used to smooth simulated samples from importance sampling function approximations to posterior distributions, resulting in revised approximations that are mixtures of standard parametric forms, usually multivariate normal or T-distributions. Adaptive refinement of such mixture approximations involves repeating this process to home-in successively on the posterior. In fairly low dimensional problems, this provides a general and automatic method of approximating posteriors by mixtures, so that marginal densities and other summaries may be easily computed. This is discussed and illustrated, with comment on variations and extensions suited to sequential Bayesian updating of Monte Carlo approximations, an area in which existing and alternative numerical methods are difficult to apply.},
  copyright = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
  langid = {english},
  file = {../../Bibliography/west_1993_approximating posterior distributions by mixtures.pdf}
}

@article{whi_2022_HyperbolicDiscEmbedding,
  title = {Hyperbolic Disc Embedding of Functional Human Brain Connectomes Using Resting-State {{fMRI}}},
  author = {Whi, Wonseok and Ha, Seunggyun and Kang, Hyejin and Lee, Dong Soo},
  year = {2022},
  month = jul,
  journal = {Network Neuroscience},
  volume = {6},
  number = {3},
  pages = {745--764},
  issn = {2472-1751},
  doi = {10.1162/netn_a_00243},
  urldate = {2023-05-11},
  abstract = {Abstract             The brain presents a real complex network of modular, small-world, and hierarchical nature, which are features of non-Euclidean geometry. Using resting-state functional magnetic resonance imaging, we constructed a scale-free binary graph for each subject, using internodal time series correlation of regions of interest as a proximity measure. The resulting network could be embedded onto manifolds of various curvatures and dimensions. While maintaining the fidelity of embedding (low distortion, high mean average precision), functional brain networks were found to be best represented in the hyperbolic disc. Using the {$\mathbb{S}$}1/{$\mathbb{H}$}2 model, we reduced the dimension of the network into two-dimensional hyperbolic space and were able to efficiently visualize the internodal connections of the brain, preserving proximity as distances and angles on the hyperbolic discs. Each individual disc revealed relevance with its anatomic counterpart and absence of center-spaced node. Using the hyperbolic distance on the {$\mathbb{S}$}1/{$\mathbb{H}$}2 model, we could detect the anomaly of network in autism spectrum disorder subjects. This procedure of embedding grants us a reliable new framework for studying functional brain networks and the possibility of detecting anomalies of the network in the hyperbolic disc on an individual scale.},
  langid = {english},
  file = {../../Bibliography/Whi_2022_Hyperbolic disc embedding of functional human brain connectomes using.pdf}
}

@phdthesis{williams_2003_GaussianMixtureReduction,
  title = {Gaussian Mixture Reduction for Tracking Multiple Maneuvering Targets in Clutter},
  author = {Williams, Jason},
  year = {2003},
  address = {Wright-Patterson Air Force Base, OH},
  school = {Air Force Institute of Technology}
}

@inproceedings{williams_2021_GeneralizedShapeMetrics,
  title = {Generalized Shape Metrics on Neural Representations},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Williams, Alex H and Kunz, Erin and Kornblith, Simon and Linderman, Scott},
  editor = {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P.S. and Vaughan, J. Wortman},
  year = {2021},
  volume = {34},
  pages = {4738--4750},
  publisher = {Curran Associates, Inc.},
  file = {../../Bibliography/Williams_2021_Generalized shape metrics on neural representations.pdf}
}

@article{wilson_2008_StudyGraphSpectra,
  title = {A Study of Graph Spectra for Comparing Graphs and Trees},
  author = {Wilson, Richard C. and Zhu, Ping},
  year = {2008},
  month = sep,
  journal = {Pattern Recognition},
  volume = {41},
  number = {9},
  pages = {2833--2841},
  issn = {00313203},
  doi = {10.1016/j.patcog.2008.03.011},
  urldate = {2022-08-28},
  langid = {english},
  file = {../../Bibliography/Wilson_2008_A study of graph spectra for comparing graphs and trees.pdf}
}

@misc{wilson_2018_GradientDescentHyperbolic,
  title = {Gradient Descent in Hyperbolic Space},
  author = {Wilson, Benjamin and Leimeister, Matthias},
  year = {2018},
  month = aug,
  number = {arXiv:1805.08207},
  eprint = {1805.08207},
  primaryclass = {math},
  publisher = {arXiv},
  urldate = {2023-12-20},
  abstract = {Gradient descent generalises naturally to Riemannian manifolds, and to hyperbolic \$n\$-space, in particular. Namely, having calculated the gradient at the point on the manifold representing the model parameters, the updated point is obtained by travelling along the geodesic passing in the direction of the gradient. Some recent works employing optimisation in hyperbolic space have not attempted this procedure, however, employing instead various approximations to avoid a calculation that was considered to be too complicated. In this tutorial, we demonstrate that in the hyperboloid model of hyperbolic space, the necessary calculations to perform gradient descent are in fact straight-forward. The advantages of the approach are then both illustrated and quantified for the optimisation problem of computing the Fr{\textbackslash}'echet mean (i.e. barycentre) of points in hyperbolic space.},
  archiveprefix = {arXiv},
  keywords = {I.2.0,Mathematics - Optimization and Control},
  file = {../../Bibliography/Wilson_2018_Gradient descent in hyperbolic space.pdf;../../../../../Zotero/storage/NECYSANC/1805.html}
}

@inproceedings{xie_2020_FastProximalPoint,
  title = {A Fast Proximal Point Method for Computing Exact Wasserstein Distance},
  booktitle = {Proceedings of the 35th Uncertainty in Artificial Intelligence Conference},
  author = {Xie, Yujia and Wang, Xiangfeng and Wang, Ruijia and Zha, Hongyuan},
  editor = {Adams, Ryan P. and Gogate, Vibhav},
  year = {2020-07-22/2020-07-25},
  series = {Proceedings of Machine Learning Research},
  volume = {115},
  pages = {433--453},
  publisher = {PMLR},
  pdf = {http://proceedings.mlr.press/v115/xie20b/xie20b.pdf},
  file = {../../Bibliography/Xie_2020_A fast proximal point method for computing exact wasserstein distance.pdf}
}

@article{yadav_2015_EfficientSVDShrinkage,
  title = {An {{Efficient SVD Shrinkage}} for {{Rank Estimation}}},
  author = {Yadav, S. K. and Sinha, R. and Bora, P. K.},
  year = {2015},
  month = dec,
  journal = {IEEE Signal Processing Letters},
  volume = {22},
  number = {12},
  pages = {2406--2410},
  issn = {1070-9908, 1558-2361},
  doi = {10.1109/LSP.2015.2487600},
  urldate = {2022-07-25},
  file = {../../Bibliography/Yadav_2015_An Efficient SVD Shrinkage for Rank Estimation.pdf}
}

@article{yahata_2016_SmallNumberAbnormal,
  title = {A Small Number of Abnormal Brain Connections Predicts Adult Autism Spectrum Disorder},
  author = {Yahata, Noriaki and Morimoto, Jun and Hashimoto, Ryuichiro and Lisi, Giuseppe and Shibata, Kazuhisa and Kawakubo, Yuki and Kuwabara, Hitoshi and Kuroda, Miho and Yamada, Takashi and Megumi, Fukuda and Imamizu, Hiroshi and N{\'a}{\~n}ez Sr, Jos{\'e} E. and Takahashi, Hidehiko and Okamoto, Yasumasa and Kasai, Kiyoto and Kato, Nobumasa and Sasaki, Yuka and Watanabe, Takeo and Kawato, Mitsuo},
  year = {2016},
  month = sep,
  journal = {Nature Communications},
  volume = {7},
  number = {1},
  pages = {11254},
  issn = {2041-1723},
  doi = {10.1038/ncomms11254},
  urldate = {2021-10-04},
  langid = {english},
  file = {../../Bibliography/Yahata_2016_A small number of abnormal brain connections predicts adult autism spectrum.pdf}
}

@article{yair_2019_ParallelTransportCone,
  title = {Parallel {{Transport}} on the {{Cone Manifold}} of {{SPD Matrices}} for {{Domain Adaptation}}},
  author = {Yair, Or and {Ben-Chen}, Mirela and Talmon, Ronen},
  year = {2019},
  month = apr,
  journal = {IEEE Transactions on Signal Processing},
  volume = {67},
  number = {7},
  pages = {1797--1811},
  issn = {1053-587X, 1941-0476},
  doi = {10.1109/TSP.2019.2894801},
  urldate = {2024-01-05},
  file = {../../Bibliography/Yair_2019_Parallel Transport on the Cone Manifold of SPD Matrices for Domain Adaptation.pdf}
}

@misc{yair_2020_DomainAdaptationOptimal,
  title = {Domain {{Adaptation}} with {{Optimal Transport}} on the {{Manifold}} of {{SPD}} Matrices},
  author = {Yair, Or and Dietrich, Felix and Talmon, Ronen and Kevrekidis, Ioannis G.},
  year = {2020},
  month = jul,
  number = {arXiv:1906.00616},
  eprint = {1906.00616},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-01-06},
  abstract = {In this paper, we address the problem of Domain Adaptation (DA) using Optimal Transport (OT) on Riemannian manifolds. We model the difference between two domains by a diffeomorphism and use the polar factorization theorem to claim that OT is indeed optimal for DA in a well-defined sense, up to a volume preserving map. We then focus on the manifold of Symmetric and Positive-Definite (SPD) matrices, whose structure provided a useful context in recent applications. We demonstrate the polar factorization theorem on this manifold. Due to the uniqueness of the weighted Riemannian mean, and by exploiting existing regularized OT algorithms, we formulate a simple algorithm that maps the source domain to the target domain. We test our algorithm on two Brain-Computer Interface (BCI) data sets and observe state of the art performance.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {../../Bibliography/Yair_2020_Domain Adaptation with Optimal Transport on the Manifold of SPD matrices.pdf;../../../../../Zotero/storage/L9XJG67Q/1906.html}
}

@inproceedings{yamin_2019_ComparisonBrainConnectomes,
  title = {Comparison {{Of Brain Connectomes Using Geodesic Distance On Manifold}}: {{A Twins Study}}},
  shorttitle = {Comparison {{Of Brain Connectomes Using Geodesic Distance On Manifold}}},
  booktitle = {2019 {{IEEE}} 16th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}} 2019)},
  author = {Yamin, A. and Dayan, M. and Squarcina, L. and Brambilla, P. and Murino, V. and Diwadkar, V. and Sona, D.},
  year = {2019},
  month = apr,
  pages = {1797--1800},
  publisher = {IEEE},
  address = {Venice, Italy},
  doi = {10.1109/ISBI.2019.8759407},
  urldate = {2021-10-04},
  isbn = {978-1-5386-3641-1},
  file = {../../Bibliography/Yamin_2019_Comparison Of Brain Connectomes Using Geodesic Distance On Manifold.pdf}
}

@inproceedings{yan_2009_FastApproximateSpectral,
  title = {Fast Approximate Spectral Clustering},
  booktitle = {Proceedings of the 15th {{ACM SIGKDD}} International Conference on Knowledge Discovery and Data Mining},
  author = {Yan, Donghui and Huang, Ling and Jordan, Michael I.},
  year = {2009},
  series = {{{KDD}} '09},
  pages = {907--916},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1557019.1557118},
  isbn = {978-1-60558-495-9},
  keywords = {data quantization,spectral clustering,unsupervised learning},
  file = {../../Bibliography/Yan_2009_Fast approximate spectral clustering.pdf}
}

@article{yang_2010_RiemannianMedianIts,
  title = {Riemannian Median and Its Estimation},
  author = {Yang, Le},
  year = {2010},
  month = dec,
  journal = {LMS Journal of Computation and Mathematics},
  volume = {13},
  pages = {461--479},
  issn = {1461-1570},
  doi = {10.1112/S1461157020090531},
  urldate = {2022-02-21},
  abstract = {Abstract                            In this paper, we define the geometric median for a probability measure on a Riemannian manifold, give its characterization and a natural condition to ensure its uniqueness. In order to compute the geometric median in practical cases, we also propose a subgradient algorithm and prove its convergence as well as estimating the error of approximation and the rate of convergence. The convergence property of this subgradient algorithm, which is a generalization of the classical Weiszfeld algorithm in Euclidean spaces to the context of Riemannian manifolds, also improves a recent result of P.~T. Fletcher               et al               .~[               NeuroImage               45 (2009) S143--S152].},
  langid = {english},
  file = {../../Bibliography/Yang_2010_Riemannian median and its estimation.pdf}
}

@article{yang_2011_SpectralClusteringDensity,
  title = {Spectral Clustering with Density Sensitive Similarity Function},
  author = {Yang, Peng and Zhu, Qingsheng and Huang, Biao},
  year = {2011},
  month = jul,
  journal = {Knowledge-Based Systems},
  volume = {24},
  number = {5},
  pages = {621--628},
  issn = {09507051},
  doi = {10.1016/j.knosys.2011.01.009},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Yang_2011_Spectral clustering with density sensitive similarity function.pdf}
}

@article{yang_2017_MultivariateTestsUniformity,
  title = {Multivariate Tests of Uniformity},
  author = {Yang, Mengta and Modarres, Reza},
  year = {2017},
  month = sep,
  journal = {Statistical Papers},
  volume = {58},
  number = {3},
  pages = {627--639},
  issn = {0932-5026, 1613-9798},
  doi = {10.1007/s00362-015-0715-x},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Yang_2017_Multivariate tests of uniformity.pdf}
}

@article{yang_2022_LargeLanguageModel,
  title = {A Large Language Model for Electronic Health Records},
  author = {Yang, Xi and Chen, Aokun and PourNejatian, Nima and Shin, Hoo Chang and Smith, Kaleb E. and Parisien, Christopher and Compas, Colin and Martin, Cheryl and Costa, Anthony B. and Flores, Mona G. and Zhang, Ying and Magoc, Tanja and Harle, Christopher A. and Lipori, Gloria and Mitchell, Duane A. and Hogan, William R. and Shenkman, Elizabeth A. and Bian, Jiang and Wu, Yonghui},
  year = {2022},
  month = dec,
  journal = {npj Digital Medicine},
  volume = {5},
  number = {1},
  pages = {194},
  issn = {2398-6352},
  doi = {10.1038/s41746-022-00742-2},
  urldate = {2024-10-10},
  abstract = {Abstract                            There is an increasing interest in developing artificial intelligence (AI) systems to process and interpret electronic health records (EHRs). Natural language processing (NLP) powered by pretrained language models is the key technology for medical AI systems utilizing clinical narratives. However, there are few clinical language models, the largest of which trained in the clinical domain is comparatively small at 110 million parameters (compared with billions of parameters in the general domain). It is not clear how large clinical language models with billions of parameters can help medical AI systems utilize unstructured EHRs. In this study, we develop from scratch a large clinical language model---GatorTron---using {$>$}90 billion words of text (including {$>$}82 billion words of de-identified clinical text) and systematically evaluate it on five clinical NLP tasks including clinical concept extraction, medical relation extraction, semantic textual similarity, natural language inference (NLI), and medical question answering (MQA). We examine how (1) scaling up the number of parameters and (2) scaling up the size of the training data could benefit these NLP tasks. GatorTron models scale up the clinical language model from 110 million to 8.9 billion parameters and improve five clinical NLP tasks (e.g., 9.6\% and 9.5\% improvement in accuracy for NLI and MQA), which can be applied to medical AI systems to improve healthcare delivery. The GatorTron models are publicly available at:               https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/gatortron\_og               .},
  langid = {english},
  file = {../../Bibliography/Yang_2022_A large language model for electronic health records.pdf}
}

@article{yang_2023_TdistributedSphericalFeature,
  title = {T-Distributed {{Spherical Feature Representation}} for {{Imbalanced Classification}}},
  author = {Yang, Xiaoyu and Chen, Yufei and Yue, Xiaodong and Xu, Shaoxun and Ma, Chao},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {9},
  pages = {10825--10833},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v37i9.26284},
  urldate = {2024-04-23},
  abstract = {Real-world classification tasks often show an extremely imbalanced problem. The extreme imbalance will cause a strong bias that the decision boundary of the classifier is completely dominated by the categories with abundant samples, which are also called the head categories. Current methods have alleviated the imbalanced impact from mainly three aspects: class re-balance, decoupling and domain adaptation. However, the existing criterion with the winner-take-all strategy still leads to the crowding problem in the eigenspace. The head categories with many samples can extract features more accurately, but occupy most of the eigenspace. The tail categories sharing the rest of the narrow eigenspace are too crowded together to accurately extract features. Above these issues, we propose a novel T-distributed spherical metric for equalized eigenspace in the imbalanced classification, which has the following innovations: 1) We design the T-distributed spherical metric, which has the characteristics of high kurtosis. Instead of the winner-take-all strategy, the T-distributed spherical metric produces a high logit only when the extracted feature is close enough to the category center, without a strong bias against other categories. 2) The T-distributed spherical metric is integrated into the classifier, which is able to equalize the eigenspace for alleviating the crowding issue in the imbalanced problem. The equalized eigenspace by the T-distributed spherical classifier is capable of improving the accuracy of the tail categories while maintaining the accuracy of the head, which significantly promotes the intraclass compactness and interclass separability of features. Extensive experiments on large-scale imbalanced datasets verify our method, which shows superior results in the long-tailed CIFAR-100/-10 with the imbalanced ratio IR = 100/50. Our method also achieves excellent results on the large-scale ImageNet-LT dataset and the iNaturalist dataset with various backbones. In addition, we provide a case study of the real clinical classification of pancreatic tumor subtypes with 6 categories. Among them, the largest number of PDAC accounts for 315 cases, and the least CP has only 8 cases. After 4-fold cross-validation, we achieved a top-1 accuracy of 69.04\%.},
  file = {../../Bibliography/Yang_2023_T-distributed Spherical Feature Representation for Imbalanced Classification.pdf}
}

@article{ye_2016_SchubertVarietiesDistances,
  title = {Schubert {{Varieties}} and {{Distances}} between {{Subspaces}} of {{Different Dimensions}}},
  author = {Ye, Ke and Lim, Lek-Heng},
  year = {2016},
  month = jan,
  journal = {SIAM Journal on Matrix Analysis and Applications},
  volume = {37},
  number = {3},
  pages = {1176--1197},
  issn = {0895-4798, 1095-7162},
  doi = {10.1137/15M1054201},
  urldate = {2023-04-10},
  langid = {english},
  file = {../../Bibliography/Ye_2016_Schubert Varieties and Distances between Subspaces of Different Dimensions.pdf}
}

@article{yi_2013_SUREtunedTaperingEstimation,
  title = {{{SURE-tuned}} Tapering Estimation of Large Covariance Matrices},
  author = {Yi, Feng and Zou, Hui},
  year = {2013},
  month = feb,
  journal = {Computational Statistics \& Data Analysis},
  volume = {58},
  pages = {339--351},
  issn = {01679473},
  doi = {10.1016/j.csda.2012.09.007},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Yi_2013_SURE-tuned tapering estimation of large covariance matrices.pdf}
}

@inproceedings{yoshida_2016_NonlinearLaplacianDigraphs,
  title = {Nonlinear {{Laplacian}} for {{Digraphs}} and Its {{Applications}} to {{Network Analysis}}},
  booktitle = {Proceedings of the {{Ninth ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Yoshida, Yuichi},
  year = {2016},
  month = feb,
  pages = {483--492},
  publisher = {ACM},
  address = {San Francisco California USA},
  doi = {10.1145/2835776.2835785},
  urldate = {2022-07-26},
  isbn = {978-1-4503-3716-8},
  langid = {english}
}

@article{you_2021_RevisitingRiemannianGeometry,
  title = {Re-Visiting {{Riemannian}} Geometry of Symmetric Positive Definite Matrices for the Analysis of Functional Connectivity},
  author = {You, Kisung and Park, Hae-Jeong},
  year = {2021},
  month = jan,
  journal = {NeuroImage},
  volume = {225},
  pages = {117464},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2020.117464},
  urldate = {2021-06-09},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/You_2021_Re-visiting Riemannian geometry of symmetric positive definite matrices for the.pdf}
}

@manual{you_2021_RiemannLearningData,
  type = {Manual},
  title = {Riemann: {{Learning}} with Data on Riemannian Manifolds},
  author = {You, Kisung},
  year = {2021}
}

@phdthesis{you_2021_TopicsGeometricTopological,
  title = {Topics in {{Geometric}} and {{Topological Data Analysis}}},
  author = {You, Kisung},
  year = {2021},
  journal = {ProQuest Dissertations and Theses},
  copyright = {All rights reserved},
  isbn = {9798534691610},
  langid = {english},
  keywords = {0463:Statistics,Accuracy,Algorithms,Clustering,Data analysis,Euclidean discrepancy,Euclidean space,Generalized linear models,Geometric data analysis,Geometry,Hypotheses,Medical research,Mises-Fisher distribution,Normal distribution,Optimization,Parameter estimation,Principal components analysis,Probability distribution,Random variables,Spherical normal distribution,Statistics,Topological data analysis,Visualization}
}

@article{you_2022_ComparingMultipleLatent,
  title = {Comparing Multiple Latent Space Embeddings Using Topological Analysis},
  author = {You, Kisung and Kim, Ilmun and Jin, Ick Hoon and Jeon, Minjeong and Shung, Dennis},
  year = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2208.12435},
  urldate = {2022-09-15},
  abstract = {The latent space model is one of the well-known methods for statistical inference of network data. While the model has been much studied for a single network, it has not attracted much attention to analyze collectively when multiple networks and their latent embeddings are present. We adopt a topology-based representation of latent space embeddings to learn over a population of network model fits, which allows us to compare networks of potentially varying sizes in an invariant manner to label permutation and rigid motion. This approach enables us to propose algorithms for clustering and multi-sample hypothesis tests by adopting well-established theories for Hilbert space-valued analysis. After the proposed method is validated via simulated examples, we apply the framework to analyze educational survey data from Korean innovative school reform.},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  keywords = {Applications (stat.AP),FOS: Computer and information sciences,Methodology (stat.ME)},
  file = {../../Bibliography/You_2022_Comparing multiple latent space embeddings using topological analysis.pdf}
}

@article{you_2022_GeometricLearningFunctional,
  title = {Geometric Learning of Functional Brain Network on the Correlation Manifold},
  author = {You, Kisung and Park, Hae-Jeong},
  year = {2022},
  month = oct,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {17752},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-21376-0},
  urldate = {2022-10-22},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/You_2022_Geometric learning of functional brain network on the correlation manifold.pdf}
}

@article{you_2022_ParameterEstimationModelbased,
  title = {Parameter Estimation and Model-Based Clustering with Spherical Normal Distribution on the Unit Hypersphere},
  author = {You, Kisung and Suh, Changhee},
  year = {2022},
  month = jul,
  journal = {Computational Statistics \& Data Analysis},
  volume = {171},
  pages = {107457},
  issn = {01679473},
  doi = {10.1016/j.csda.2022.107457},
  urldate = {2022-03-03},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/You_2022_Parameter estimation and model-based clustering with spherical normal.pdf}
}

@article{you_2022_RdimtoolsPackageDimension,
  title = {Rdimtools: {{An R}} Package for Dimension Reduction and Intrinsic Dimension Estimation},
  shorttitle = {Rdimtools},
  author = {You, Kisung and Shung, Dennis},
  year = {2022},
  month = nov,
  journal = {Software Impacts},
  volume = {14},
  pages = {100414},
  issn = {26659638},
  doi = {10.1016/j.simpa.2022.100414},
  urldate = {2022-09-10},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/You_2022_Rdimtools.pdf}
}

@article{you_2022_SphericalLaplaceDistribution,
  title = {On the Spherical {{Laplace}} Distribution},
  author = {You, Kisung and Shung, Dennis},
  year = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2208.11929},
  urldate = {2022-09-15},
  abstract = {The von Mises-Fisher (vMF) distribution has long been a mainstay for inference with data on the unit hypersphere in directional statistics. The performance of statistical inference based on the vMF distribution, however, may suffer when there are significant outliers and noise in the data. Based on an analogy of the median as a robust measure of central tendency and its relationship to the Laplace distribution, we proposed the spherical Laplace (SL) distribution, a novel probability measure for modelling directional data. We present a sampling scheme and theoretical results on maximum likelihood estimation. We derive efficient numerical routines for parameter estimation in the absence of closed-form formula. An application of model-based clustering is considered under the finite mixture model framework. Our numerical methods for parameter estimation and clustering are validated using simulated and real data experiments.},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  keywords = {62F10 62H11 62H12 62H30 62R30,FOS: Computer and information sciences,Methodology (stat.ME)},
  file = {../../Bibliography/You_2022_On the spherical Laplace distribution.pdf}
}

@inproceedings{you_2023_SphericalLaplaceDistribution,
  title = {On the {{Spherical Laplace Distribution}}},
  booktitle = {2023 26th {{International Conference}} on {{Information Fusion}} ({{FUSION}})},
  author = {You, Kisung and Shung, Dennis},
  year = {2023},
  month = jun,
  pages = {1--8},
  publisher = {IEEE},
  address = {Charleston, SC, USA},
  doi = {10.23919/FUSION52260.2023.10224108},
  urldate = {2023-08-29},
  copyright = {All rights reserved},
  isbn = {9798890344854},
  file = {../../Bibliography/You_2023_On the Spherical Laplace Distribution.pdf}
}

@article{you_2024_WassersteinMedianProbability,
  title = {On the {{Wasserstein Median}} of {{Probability Measures}}},
  author = {You, Kisung and Shung, Dennis and Giuffr{\`e}, Mauro},
  year = {2024},
  month = jul,
  journal = {Journal of Computational and Graphical Statistics},
  pages = {1--25},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2024.2374580},
  urldate = {2024-07-10},
  copyright = {All rights reserved},
  langid = {english},
  file = {../../Bibliography/you_2024_on the wasserstein median of probability measures.pdf}
}

@inproceedings{young_2010_RobustnessNoisyConsensus,
  title = {Robustness of Noisy Consensus Dynamics with Directed Communication},
  booktitle = {Proceedings of the 2010 {{American Control Conference}}},
  author = {Young, George Forrest and Scardovi, Luca and Leonard, Naomi Ehrich},
  year = {2010},
  month = jun,
  pages = {6312--6317},
  publisher = {IEEE},
  address = {Baltimore, MD},
  doi = {10.1109/ACC.2010.5531506},
  urldate = {2024-08-30},
  isbn = {978-1-4244-7427-1 978-1-4244-7426-4 978-1-4244-7425-7}
}

@article{young_2016_NewNotionEffective,
  title = {A {{New Notion}} of {{Effective Resistance}} for {{Directed Graphs}}---{{Part I}}: {{Definition}} and {{Properties}}},
  shorttitle = {A {{New Notion}} of {{Effective Resistance}} for {{Directed Graphs}}---{{Part I}}},
  author = {Young, George Forrest and Scardovi, Luca and Leonard, Naomi Ehrich},
  year = {2016},
  month = jul,
  journal = {IEEE Transactions on Automatic Control},
  volume = {61},
  number = {7},
  pages = {1727--1736},
  issn = {0018-9286, 1558-2523},
  doi = {10.1109/TAC.2015.2481978},
  urldate = {2021-09-08},
  file = {../../Bibliography/Young_2016_A New Notion of Effective Resistance for Directed Graphs—Part I.pdf}
}

@article{young_2016_NewNotionEffectivea,
  title = {A {{New Notion}} of {{Effective Resistance}} for {{Directed Graphs}}---{{Part II}}: {{Computing Resistances}}},
  shorttitle = {A {{New Notion}} of {{Effective Resistance}} for {{Directed Graphs}}---{{Part II}}},
  author = {Young, George Forrest and Scardovi, Luca and Leonard, Naomi Ehrich},
  year = {2016},
  month = jul,
  journal = {IEEE Transactions on Automatic Control},
  volume = {61},
  number = {7},
  pages = {1737--1752},
  issn = {0018-9286, 1558-2523},
  doi = {10.1109/TAC.2015.2481839},
  urldate = {2021-09-08},
  file = {../../Bibliography/Young_2016_A New Notion of Effective Resistance for Directed Graphs—Part II.pdf}
}

@article{ypma_1995_HistoricalDevelopmentNewton,
  title = {Historical {{Development}} of the {{Newton}}--{{Raphson Method}}},
  author = {Ypma, Tjalling J.},
  year = {1995},
  month = dec,
  journal = {SIAM Review},
  volume = {37},
  number = {4},
  pages = {531--551},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/1037125},
  urldate = {2022-02-21},
  langid = {english},
  file = {../../Bibliography/Ypma_1995_Historical Development of the Newton–Raphson Method.pdf}
}

@article{yu_2019_DensityPreservingHierarchicalEM,
  title = {Density-{{Preserving Hierarchical EM Algorithm}}: {{Simplifying Gaussian Mixture Models}} for {{Approximate Inference}}},
  shorttitle = {Density-{{Preserving Hierarchical EM Algorithm}}},
  author = {Yu, Lei and Yang, Tianyu and Chan, Antoni B.},
  year = {2019},
  month = jun,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {41},
  number = {6},
  pages = {1323--1337},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/TPAMI.2018.2845371},
  urldate = {2025-01-05},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  file = {../../Bibliography/yu_2019_density-preserving hierarchical em algorithm.pdf}
}

@article{yu_2021_ShapePreservingDimensionalityReduction,
  title = {Shape-{{Preserving Dimensionality Reduction}} : {{An Algorithm}} and {{Measures}} of {{Topological Equivalence}}},
  shorttitle = {Shape-{{Preserving Dimensionality Reduction}}},
  author = {Yu, Byeongsu and You, Kisung},
  year = {2021},
  month = jun,
  journal = {arXiv:2106.02096 [cs, stat]},
  eprint = {2106.02096},
  primaryclass = {cs, stat},
  urldate = {2021-11-18},
  archiveprefix = {arXiv},
  copyright = {All rights reserved},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {../../Bibliography/Yu_2021_Shape-Preserving Dimensionality Reduction.pdf}
}

@inproceedings{zelnik-manor_2004_SelftuningSpectralClustering,
  title = {Self-Tuning Spectral Clustering},
  booktitle = {Advances in Neural Information Processing Systems 17},
  author = {{Zelnik-manor}, Lihi and Perona, Pietro},
  editor = {Saul, Lawrence K. and Weiss, Yair and Bottou, Leon},
  year = {2004},
  pages = {1601--1608},
  publisher = {MIT Press},
  file = {../../Bibliography/Zelnik-manor_2004_Self-tuning spectral clustering.pdf}
}

@inproceedings{zhang_2006_SimplifyingMixtureModels,
  title = {Simplifying Mixture Models through Function Approximation},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Zhang, Kai and Kwok, James},
  editor = {Sch{\"o}lkopf, B. and Platt, J. and Hoffman, T.},
  year = {2006},
  volume = {19},
  publisher = {MIT Press},
  file = {../../Bibliography/zhang_2006_simplifying mixture models through function approximation.pdf}
}

@article{zhang_2008_ConstraintScoreNew,
  title = {Constraint {{Score}}: {{A}} New Filter Method for Feature Selection with Pairwise Constraints},
  shorttitle = {Constraint {{Score}}},
  author = {Zhang, Daoqiang and Chen, Songcan and Zhou, Zhi-Hua},
  year = {2008},
  month = may,
  journal = {Pattern Recognition},
  volume = {41},
  number = {5},
  pages = {1440--1451},
  issn = {00313203},
  doi = {10.1016/j.patcog.2007.10.009},
  urldate = {2022-06-27},
  langid = {english},
  file = {../../Bibliography/Zhang_2008_Constraint Score.pdf}
}

@article{zhang_2009_KsampleBehrensFisherProblem,
  title = {On the K-Sample {{Behrens-Fisher}} Problem for High-Dimensional Data},
  author = {Zhang, JinTing and Xu, JinFeng},
  year = {2009},
  month = jun,
  journal = {Science in China Series A: Mathematics},
  volume = {52},
  number = {6},
  pages = {1285--1304},
  issn = {1006-9283, 1862-2763},
  doi = {10.1007/s11425-009-0091-x},
  urldate = {2022-07-26},
  langid = {english},
  file = {../../Bibliography/Zhang_2009_On the k-sample Behrens-Fisher problem for high-dimensional data.pdf}
}

@article{zhang_2009_MultiinstanceClusteringApplications,
  title = {Multi-Instance Clustering with Applications to Multi-Instance Prediction},
  author = {Zhang, Min-Ling and Zhou, Zhi-Hua},
  year = {2009},
  month = aug,
  journal = {Applied Intelligence},
  volume = {31},
  number = {1},
  pages = {47--68},
  issn = {0924-669X, 1573-7497},
  doi = {10.1007/s10489-007-0111-x},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Zhang_2009_Multi-instance clustering with applications to multi-instance prediction.pdf}
}

@inproceedings{zhang_2010_SpectralClusteringAlgorithm,
  title = {Spectral Clustering Algorithm Based on Adaptive Neighbor Distance Sort Order},
  booktitle = {The 3rd {{International Conference}} on {{Information Sciences}} and {{Interaction Sciences}}},
  author = {Zhang, Yifei and Zhou, Junlin and Fu, Yan},
  year = {2010},
  month = jun,
  pages = {444--447},
  publisher = {IEEE},
  address = {Chengdu, China},
  doi = {10.1109/ICICIS.2010.5534786},
  urldate = {2022-07-25},
  isbn = {978-1-4244-7384-7},
  file = {../../Bibliography/Zhang_2010_Spectral clustering algorithm based on adaptive neighbor distance sort order.pdf}
}

@article{zhang_2011_ImprovedSpectralClustering,
  title = {An Improved Spectral Clustering Algorithm Based on Random Walk},
  author = {Zhang, Xianchao and You, Quanzeng},
  year = {2011},
  month = sep,
  journal = {Frontiers of Computer Science in China},
  volume = {5},
  number = {3},
  pages = {268--278},
  issn = {1673-7350, 1673-7466},
  doi = {10.1007/s11704-011-0023-0},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Zhang_2011_An improved spectral clustering algorithm based on random walk.pdf}
}

@article{zhang_2011_LocalDensityAdaptive,
  title = {Local Density Adaptive Similarity Measurement for Spectral Clustering},
  author = {Zhang, Xianchao and Li, Jingwei and Yu, Hong},
  year = {2011},
  month = jan,
  journal = {Pattern Recognition Letters},
  volume = {32},
  number = {2},
  pages = {352--358},
  issn = {01678655},
  doi = {10.1016/j.patrec.2010.09.014},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Zhang_2011_Local density adaptive similarity measurement for spectral clustering.pdf}
}

@article{zhang_2012_ExactLikelihoodRatio,
  title = {The {{Exact Likelihood Ratio Test}} for {{Equality}} of {{Two Normal Populations}}},
  author = {Zhang, Lingyun and Xu, Xinzhong and Chen, Gemai},
  year = {2012},
  month = aug,
  journal = {The American Statistician},
  volume = {66},
  number = {3},
  pages = {180--184},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.2012.707083},
  urldate = {2022-07-25},
  langid = {english},
  file = {../../Bibliography/Zhang_2012_The Exact Likelihood Ratio Test for Equality of Two Normal Populations.pdf}
}

@article{zhang_2013_NonparametricInformationGeometry,
  title = {Nonparametric {{Information Geometry}}: {{From Divergence Function}} to {{Referential-Representational Biduality}} on {{Statistical Manifolds}}},
  shorttitle = {Nonparametric {{Information Geometry}}},
  author = {Zhang, Jun},
  year = {2013},
  month = dec,
  journal = {Entropy},
  volume = {15},
  number = {12},
  pages = {5384--5418},
  issn = {1099-4300},
  doi = {10.3390/e15125384},
  urldate = {2022-02-17},
  langid = {english},
  file = {../../Bibliography/Zhang_2013_Nonparametric Information Geometry.pdf}
}

@article{zhang_2024_GaussianMixtureReduction,
  title = {Gaussian {{Mixture Reduction With Composite Transportation Divergence}}},
  author = {Zhang, Qiong and Zhang, Archer Gong and Chen, Jiahua},
  year = {2024},
  month = jul,
  journal = {IEEE Transactions on Information Theory},
  volume = {70},
  number = {7},
  pages = {5191--5212},
  issn = {0018-9448, 1557-9654},
  doi = {10.1109/TIT.2023.3323346},
  urldate = {2025-01-05},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  file = {../../../../../Zotero/storage/SN6PNIT7/Zhang et al. - 2024 - Gaussian Mixture Reduction With Composite Transpor.pdf}
}

@inproceedings{zhao_2007_SpectralFeatureSelection,
  title = {Spectral Feature Selection for Supervised and Unsupervised Learning},
  booktitle = {Proceedings of the 24th International Conference on {{Machine}} Learning - {{ICML}} '07},
  author = {Zhao, Zheng and Liu, Huan},
  year = {2007},
  pages = {1151--1157},
  publisher = {ACM Press},
  address = {Corvalis, Oregon},
  doi = {10.1145/1273496.1273641},
  urldate = {2022-07-26},
  isbn = {978-1-59593-793-3},
  langid = {english},
  file = {../../Bibliography/Zhao_2007_Spectral feature selection for supervised and unsupervised learning.pdf}
}

@article{zheng_2024_DetectionGastrointestinalBleeding,
  title = {Detection of {{Gastrointestinal Bleeding}} with {{Large Language Models}} to {{Aid Quality Improvement}} and {{Appropriate Reimbursement}}},
  author = {Zheng, Neil S. and Keloth, Vipina K. and You, Kisung and Kats, Daniel and Li, Darrick K. and Deshpande, Ohm and Sachar, Hamita and Xu, Hua and Laine, Loren and Shung, Dennis L.},
  year = {2024},
  month = sep,
  journal = {Gastroenterology},
  pages = {S0016508524054672},
  issn = {00165085},
  doi = {10.1053/j.gastro.2024.09.014},
  urldate = {2024-10-10},
  langid = {english},
  file = {../../Bibliography/Zheng_2024_Detection of Gastrointestinal Bleeding with Large Language Models to Aid.pdf}
}

@article{zhu_2006_AutomaticDimensionalitySelection,
  title = {Automatic Dimensionality Selection from the Scree Plot via the Use of Profile Likelihood},
  author = {Zhu, Mu and Ghodsi, Ali},
  year = {2006},
  month = nov,
  journal = {Computational Statistics \& Data Analysis},
  volume = {51},
  number = {2},
  pages = {918--930},
  issn = {01679473},
  doi = {10.1016/j.csda.2005.09.010},
  urldate = {2022-08-05},
  langid = {english},
  file = {../../Bibliography/Zhu_2006_Automatic dimensionality selection from the scree plot via the use of profile.pdf}
}
